{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,DepthwiseConv2D, MaxPooling2D, AvgPool2D, GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    " \n",
    "# Import the necessary MLTK APIs\n",
    "from mltk.core import view_model, summarize_model, profile_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "#import deeplake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Confirm that TensorFlow can access GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Tensorboard session\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['WANDB_NOTEBOOK_NAME'] = 'Experiment Workbench'\n",
    "\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "#LOGGING_STEPS = 64\n",
    "LR = 0.0001\n",
    "DROPOUT = 0.2\n",
    "\n",
    "PROJECT = \"Tiny CNN\"\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED) # global seed for tensorflow random parts, like dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Lemon Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 32\n",
    "#img_height = 92\n",
    "#img_width = 92\n",
    "shuffle_seed = 42\n",
    "\n",
    "def get_lemon_quality_dataset(dataset_path, img_width, img_height, batch_size, normalize=True):\n",
    "    \"\"\" Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "    Args: \n",
    "        dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "        normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "    Returns:\n",
    "        (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "    \n",
    "    \"\"\"\n",
    "    if dataset_path.exists():\n",
    "        try:\n",
    "            train_dir = dataset_path.joinpath(\"train\")\n",
    "            val_dir = dataset_path.joinpath( \"val\")\n",
    "            test_dir = dataset_path.joinpath( \"test\")\n",
    "        except:\n",
    "            print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "            raise\n",
    "\n",
    "    print(\"Preparing training dataset...\")        \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "\n",
    "    print(\"Preparing validation dataset...\")    \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    print(\"Preparing test dataset...\")    \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "    \n",
    "    # Normalize the data to the range [0, 1]\n",
    "    if normalize:\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "        train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print (f\"Class names: {class_names}\")\n",
    "    print(train_ds.element_spec)\n",
    "    print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "dataset_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training dataset...\n",
      "Found 2021 files belonging to 3 classes.\n",
      "Preparing validation dataset...\n",
      "Found 252 files belonging to 3 classes.\n",
      "Preparing test dataset...\n",
      "Found 255 files belonging to 3 classes.\n",
      "Class names: ['bad_quality', 'empty_background', 'good_quality']\n",
      "(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "Normalize: True\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 3 classes.\n"
     ]
    }
   ],
   "source": [
    "classes = len(labels)\n",
    "print(f\"The dataset contains {classes } classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = list(train_ds.as_numpy_iterator())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 96, 96, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
    "    input_shape=(96,96,3),\n",
    "    alpha=0.25,\n",
    "    depth_multiplier=1,\n",
    "    dropout=DROPOUT,\n",
    "    include_top=True,\n",
    "    weights= None, #'imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation='softmax',\n",
    "    #**kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_0.25_96\n"
     ]
    }
   ],
   "source": [
    "MODELNAME = mobilenet.name\n",
    "print(MODELNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", MODELNAME, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "root_logdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the data flow\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "def train_model():\n",
    "        # solve issue from: https://github.com/wandb/wandb/issues/3536\n",
    "        if len(wandb.patched[\"tensorboard\"]) > 0:\n",
    "                wandb.tensorboard.unpatch()\n",
    "                \n",
    "        # Configure Tensorboard root log directory to read the debugging information\n",
    "        \n",
    "        wandb.tensorboard.patch(root_logdir=root_logdir)\n",
    "        # wandb.tensorboard.patch(root_logdir=\"wandb.run.dir\")\n",
    "        \n",
    "        wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT, \n",
    "                # Track hyperparameters and run metadata\n",
    "                #config={\n",
    "                #\"learning_rate\": LR,\n",
    "                #\"epochs\": EPOCHS,\n",
    "                #},\n",
    "                sync_tensorboard=True\n",
    "                )\n",
    "\n",
    "\n",
    "        config = wandb.config\n",
    "        # Specify the configuration variables\n",
    "        config.batch_size = BATCH_SIZE\n",
    "        config.dropout =DROPOUT\n",
    "        config.learn_rate = LR\n",
    "        #config.decay = 1e-6\n",
    "        #config.momentum = 0.9\n",
    "        config.epochs = EPOCHS\n",
    "        config.classes = classes\n",
    "\n",
    "        # enable Tensorflow Debugging\n",
    "        #tf.debugging.experimental.enable_dump_debug_info(\"./logs/debug\", \n",
    "        #        tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "        model = mobilenet\n",
    "        model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= wandb.run.dir, histogram_freq=10, update_freq=\"epoch\") #, profile_batch=\"10, 20\")\n",
    "        #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= logdir, histogram_freq=1)\n",
    "        wandb_callback = WandbCallback(input_type=\"image\", labels=labels, validation_data = val_ds.as_numpy_iterator())\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=50)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n",
    "\n",
    "        history = model.fit(train_ds,\n",
    "                epochs=EPOCHS, \n",
    "                validation_data=val_ds, \n",
    "                callbacks=[tensorboard_callback,\n",
    "                #wandb_callback, \n",
    "                checkpoint, \n",
    "                early_stopping]\n",
    "        )\n",
    "\n",
    "        wandb.log({\n",
    "                \"loss\": history.history[\"loss\"],\n",
    "                \"accuracy\": history.history[\"accuracy\"],\n",
    "                \"val_loss\": history.history[\"val_loss\"],\n",
    "                \"val_accuracy\": history.history[\"val_accuracy\"],                                \n",
    "        })\n",
    "        \n",
    "        wandb.finish()\n",
    "        return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>i:\\tinyml\\tiny_cnn\\wandb\\run-20221119_111221-1cfth6f1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/1cfth6f1\" target=\"_blank\">misty-wood-80</a></strong> to <a href=\"https://wandb.ai/susbrock/Tiny%20CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - 38s 167ms/step - loss: 1.0400 - accuracy: 0.4488 - val_loss: 1.0486 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.7112 - accuracy: 0.6729 - val_loss: 1.0389 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.5200 - accuracy: 0.7818 - val_loss: 1.0997 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 7s 101ms/step - loss: 0.3889 - accuracy: 0.8362 - val_loss: 1.1181 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.3143 - accuracy: 0.8768 - val_loss: 1.1316 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 0.2672 - accuracy: 0.8966 - val_loss: 1.0827 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 0.2139 - accuracy: 0.9189 - val_loss: 1.0739 - val_accuracy: 0.4444\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 0.2338 - accuracy: 0.9090 - val_loss: 0.9292 - val_accuracy: 0.5476\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 4s 62ms/step - loss: 0.1902 - accuracy: 0.9268 - val_loss: 0.9636 - val_accuracy: 0.6190\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 0.1635 - accuracy: 0.9372 - val_loss: 0.3450 - val_accuracy: 0.8611\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 0.1675 - accuracy: 0.9322 - val_loss: 0.4241 - val_accuracy: 0.8135\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.1340 - accuracy: 0.9525 - val_loss: 0.2529 - val_accuracy: 0.9008\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 0.1060 - accuracy: 0.9579 - val_loss: 0.3988 - val_accuracy: 0.8611\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.1365 - accuracy: 0.9476 - val_loss: 0.2585 - val_accuracy: 0.9206\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 5s 79ms/step - loss: 0.1187 - accuracy: 0.9579 - val_loss: 0.2137 - val_accuracy: 0.9206\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 0.1054 - accuracy: 0.9629 - val_loss: 0.2848 - val_accuracy: 0.8929\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0979 - accuracy: 0.9629 - val_loss: 0.4340 - val_accuracy: 0.8571\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 5s 83ms/step - loss: 0.1041 - accuracy: 0.9599 - val_loss: 0.2379 - val_accuracy: 0.9206\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.1138 - accuracy: 0.9565 - val_loss: 0.2254 - val_accuracy: 0.9206\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 0.0972 - accuracy: 0.9604 - val_loss: 0.2643 - val_accuracy: 0.9206\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 7s 110ms/step - loss: 0.0860 - accuracy: 0.9683 - val_loss: 0.2679 - val_accuracy: 0.8849\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 23s 294ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.2774 - val_accuracy: 0.9127\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 6s 85ms/step - loss: 0.0553 - accuracy: 0.9802 - val_loss: 0.2406 - val_accuracy: 0.9206\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 5s 84ms/step - loss: 0.0457 - accuracy: 0.9861 - val_loss: 0.9802 - val_accuracy: 0.7619\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0416 - accuracy: 0.9852 - val_loss: 0.3874 - val_accuracy: 0.8849\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.0961 - val_accuracy: 0.9563\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 4s 69ms/step - loss: 0.1648 - accuracy: 0.9426 - val_loss: 0.3122 - val_accuracy: 0.9048\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.0816 - accuracy: 0.9673 - val_loss: 1.0634 - val_accuracy: 0.7619\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0604 - accuracy: 0.9738 - val_loss: 0.2109 - val_accuracy: 0.9325\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0443 - accuracy: 0.9812 - val_loss: 0.2051 - val_accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 7s 103ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.3300 - val_accuracy: 0.9048\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.1906 - val_accuracy: 0.9444\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 6s 95ms/step - loss: 0.0681 - accuracy: 0.9738 - val_loss: 0.3550 - val_accuracy: 0.8889\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 7s 101ms/step - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.3306 - val_accuracy: 0.9127\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 4s 55ms/step - loss: 0.0613 - accuracy: 0.9782 - val_loss: 0.0823 - val_accuracy: 0.9603\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0856 - accuracy: 0.9703 - val_loss: 0.3353 - val_accuracy: 0.8968\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 0.0393 - accuracy: 0.9857 - val_loss: 0.4493 - val_accuracy: 0.8968\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.3589 - val_accuracy: 0.9246\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0902 - accuracy: 0.9673 - val_loss: 0.3192 - val_accuracy: 0.9008\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 21s 283ms/step - loss: 0.0547 - accuracy: 0.9812 - val_loss: 0.3470 - val_accuracy: 0.9246\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 9s 110ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.1669 - val_accuracy: 0.9484\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.1935 - val_accuracy: 0.9365\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.1385 - val_accuracy: 0.9603\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 1.9640 - val_accuracy: 0.6587\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 5s 69ms/step - loss: 0.1142 - accuracy: 0.9668 - val_loss: 1.0373 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.0656 - accuracy: 0.9762 - val_loss: 0.9737 - val_accuracy: 0.8254\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 6s 95ms/step - loss: 0.0413 - accuracy: 0.9832 - val_loss: 0.0982 - val_accuracy: 0.9603\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 5s 72ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.5759 - val_accuracy: 0.8651\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 6s 86ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 1.3989 - val_accuracy: 0.7738\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 6s 84ms/step - loss: 0.0275 - accuracy: 0.9881 - val_loss: 0.4225 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misty-wood-80</strong>: <a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/1cfth6f1\" target=\"_blank\">https://wandb.ai/susbrock/Tiny%20CNN/runs/1cfth6f1</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221119_111221-1cfth6f1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "history, model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#history.history[\"loss\"]\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 50, 'steps': 64}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn",
   "language": "python",
   "name": "tiny_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
