{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Confirm that TensorFlow can access GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Tensorboard session\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Experiment Workbench'\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "LOGGING_STEPS = 10\n",
    "LR = 0.001\n",
    "\n",
    "PROJECT = \"Tiny CNN\"\n",
    "MODELNAME = \"Simple_Net\"\n",
    "EXPERIMENT = \"MNIST\"\n",
    "RUN_NAME = \"Run_8\"\n",
    "\n",
    "logdir = os.path.join(\"logs\", MODELNAME, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "root_logdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "#y_train = keras.utils.to_categorical(y_train, 10)\n",
    "#y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "classes = 10\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(image, label):\n",
    "    # this function can be extended if any pre-processing or augmentation is needed\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a tf.data pipeline of augmented images (and their labels)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "#train_dataset = train_dataset.batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(x), y))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).map(data_preprocessing).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "#train_dataset = train_dataset.batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(x), y))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).map(data_preprocessing).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, classes):\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    #tf.keras.layers.Rescaling(1.0 / 255),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(classes, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\n",
    "        # solve issue from: https://github.com/wandb/wandb/issues/3536\n",
    "        if len(wandb.patched[\"tensorboard\"]) > 0:\n",
    "                wandb.tensorboard.unpatch()\n",
    "                \n",
    "        # Configure Tensorboard root log directory to read the debugging information\n",
    "        \n",
    "        wandb.tensorboard.patch(root_logdir=root_logdir)\n",
    "        # wandb.tensorboard.patch(root_logdir=\"wandb.run.dir\")\n",
    "        \n",
    "        wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT, \n",
    "                # Track hyperparameters and run metadata\n",
    "                #config={\n",
    "                #\"learning_rate\": LR,\n",
    "                #\"epochs\": EPOCHS,\n",
    "                #},\n",
    "                sync_tensorboard=True\n",
    "                )\n",
    "\n",
    "\n",
    "        config = wandb.config\n",
    "        # Specify the configuration variables\n",
    "        config.dropout = 0.2\n",
    "        #config.hidden_layer_size = 128\n",
    "        #config.layer_1_size  = 16\n",
    "        #config.layer_2_size = 32\n",
    "        config.learn_rate = LR\n",
    "        #config.decay = 1e-6\n",
    "        #config.momentum = 0.9\n",
    "        config.epochs = EPOCHS\n",
    "        config.classes = classes\n",
    "\n",
    "        # enable Tensorflow Debugging\n",
    "        #tf.debugging.experimental.enable_dump_debug_info(\"./logs/debug\", \n",
    "        #        tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "        \n",
    "        model = create_model(input_shape, classes)\n",
    "        model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= wandb.run.dir, histogram_freq=1, profile_batch=\"10, 20\")\n",
    "        #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= logdir, histogram_freq=1)\n",
    "        wandb_callback = WandbCallback(input_type=\"image\", labels=labels)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=3)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n",
    "        history = model.fit(train_dataset,\n",
    "                epochs=config.epochs, \n",
    "                validation_data=val_dataset, \n",
    "                callbacks=[tensorboard_callback, wandb_callback, checkpoint, early_stopping])\n",
    "\n",
    "        wandb.finish()\n",
    "        return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find Experiment Workbench.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/2eukd0t9\" target=\"_blank\">quiet-shape-24</a></strong> to <a href=\"https://wandb.ai/susbrock/Tiny%20CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/391 [..............................] - ETA: 9:02 - loss: 2.5742 - accuracy: 0.0703WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0222s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9843 - accuracy: 0.29\n",
      "INFO:tensorflow:Assets written to: i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 9s 21ms/step - loss: 1.9813 - accuracy: 0.2957 - val_loss: 1.8022 - val_accuracy: 0.3601\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7980 - accuracy: 0.35\n",
      "INFO:tensorflow:Assets written to: i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 1.7980 - accuracy: 0.3564 - val_loss: 1.7177 - val_accuracy: 0.3899\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7452 - accuracy: 0.37\n",
      "INFO:tensorflow:Assets written to: i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 14ms/step - loss: 1.7455 - accuracy: 0.3757 - val_loss: 1.6668 - val_accuracy: 0.4130\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7082 - accuracy: 0.38\n",
      "INFO:tensorflow:Assets written to: i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 1.7082 - accuracy: 0.3874 - val_loss: 1.6175 - val_accuracy: 0.4250\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6768 - accuracy: 0.40\n",
      "INFO:tensorflow:Assets written to: i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (i:\\tinyml\\tiny_cnn\\wandb\\run-20221023_192354-2eukd0t9\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 1.6767 - accuracy: 0.4004 - val_loss: 1.6156 - val_accuracy: 0.4194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▇█▇</td></tr><tr><td>val_loss</td><td>█▅▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.40038</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>1.61559</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>1.67666</td></tr><tr><td>val_accuracy</td><td>0.4194</td></tr><tr><td>val_loss</td><td>1.61559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-shape-24</strong>: <a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/2eukd0t9\" target=\"_blank\">https://wandb.ai/susbrock/Tiny%20CNN/runs/2eukd0t9</a><br/>Synced 6 W&B file(s), 181 media file(s), 16 artifact file(s) and 11 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221023_192354-2eukd0t9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history, model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_training_runs(epochs, lrs):\n",
    "    for epoch in epochs:\n",
    "        for lr in lrs:\n",
    "            run_training_run(epoch, lr)\n",
    "\n",
    "# Try different values for the learning rate\n",
    "epochs = [100, 120, 140]\n",
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "run_multiple_training_runs(epochs, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn",
   "language": "python",
   "name": "tiny_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
