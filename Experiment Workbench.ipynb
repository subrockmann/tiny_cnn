{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\tiny_cnn_6\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.2.6) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "#from tensorflow import keras\n",
    "keras = tf.keras\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D,DepthwiseConv2D, MaxPooling2D, AvgPool2D, GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    " # Import the necessary MLTK APIs\n",
    "#from mltk.core import view_model,  profile_model # summarize_model\n",
    "\n",
    "# import workbench.config.config\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths\n",
    "from workbench.utils.utils import parse_model_name\n",
    "from workbench.data.data import get_vvw_dataset, get_lemon_quality_dataset\n",
    "from workbench.tensorflow import set_batchnorm_momentum, set_dropout\n",
    "\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import deeplake\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Confirm that TensorFlow can access GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "global model_name\n",
    "#model_name = \"efficientNetB0_1_96_c3_o3_keras\"\n",
    "#model_name = \"shufflenetv2tinys_0.2_96_c3_o3_f4l1024\"2\n",
    "model_name = \"mobilenetv1_0.25_96_c3_o2_l3\"\n",
    "#model_name = \"mobilenetv1vvw_0.25_96_c3_o2_vvw\"\n",
    "#model_name = \"mobilenetv2_0.35_96_c3_o2_keras\"\n",
    "#model_name = \"MobilenetV3small_1_96_c3_o3_keras\"\n",
    "#model_name = \"mobilenetvme_0.35_96_c3_o3_l5\"\n",
    "#model_name = \"shufflenetv2tiny_0.2_96_c3_o3_f4l1024\"\n",
    "#model_name = \"MobilenetV3small_1_96_c3_o3_keras\"#, \"MobilenetV3large_1_224_c3_o3_keras\"# ,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# DANGER ZONE: Disable warning messages\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/random/set_seed  \n",
    "\n",
    "Operations that rely on a random seed actually derive it from two seeds: the global and operation-level seeds. This sets the global seed.\n",
    "\n",
    "Its interactions with operation-level seeds is as follows:\n",
    "\n",
    "1. If neither the global seed nor the operation seed is set: A randomly picked seed is used for this op.  \n",
    "2. If the global seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the global seed so that it gets a unique random sequence. Within the same version of tensorflow and user code, this sequence is deterministic. However across different versions, this sequence might change. If the code depends on particular seeds to work, specify both global and operation-level seeds explicitly.  \n",
    "3. If the operation seed is set, but the global seed is not set: A default global seed and the specified operation seed are used to determine the random sequence.  \n",
    "4. If both the global and the operation seed are set: Both seeds are used in conjunction to determine the random sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_1 = 1\n",
    "seed_2 = 15\n",
    "seed_3 = 30\n",
    "seed_4 = 42\n",
    "seed_5 = 75\n",
    "\n",
    "seed = seed_2\n",
    "\n",
    "# set the random seeds\n",
    "#os.environ[\"TF_CUDNN_DETERMINISTIC\"]= \"1\"\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.random.set_seed(seed) # setting tensorflow global seed\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "#tf.config.experimental.enable_op_determinism() \n",
    "\n",
    "# Node: 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/UnsortedSegmentSum'\n",
    "#Deterministic GPU implementation of unsorted segment reduction op not available.\n",
    "#\t [[{{node gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/UnsortedSegmentSum}}]] [Op:__inference_train_function_10280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting datasets from deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = deeplake.load('hub://activeloop/plantvillage-without-augmentation')#   61486 images, 39 different plant diseases\n",
    "# len_plants  = 61486\n",
    "# plant_classes = 39\n",
    "#ds = deeplake.load(\"hub://activeloop/places205\") # this dataset is huge! 2.5Mio Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_tensorflow = ds.tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #deeplake.__version__\n",
    "# image_count = len_plants\n",
    "# train_size = int(0.8 * image_count)\n",
    "# val_size = int(0.1 * image_count)\n",
    "# test_size = int(0.1 * image_count)\n",
    "\n",
    "# ds_tensorflow = ds_tensorflow.shuffle(image_count)\n",
    "# test_ds = ds_tensorflow.take(test_size)\n",
    "# train_ds = ds_tensorflow.skip(test_size)\n",
    "# val_ds = ds_tensorflow.take(val_size)\n",
    "# train_ds = ds_tensorflow.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in train_ds.as_numpy_iterator():\n",
    "#     print(sample)\n",
    "#     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = train_ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for element in train_ds:\n",
    "#     print(element)\n",
    "#     break\n",
    "# element[\"images\"].numpy() # image numpy array\n",
    "# element[\"labels\"].numpy() # labels numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for elem in ds_tensorflow: \n",
    "#   i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_iter = iter(train_ds)\n",
    "# next(train_ds_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(train_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Wake Words dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vvw_path = Path.cwd().parent.joinpath(\"person_detection\",\"datavisualwakewords\")\n",
    "vvw_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\tinyml\\tiny_cnn\\models\n"
     ]
    }
   ],
   "source": [
    "models_path, models_summary_path, models_image_path, models_layer_df_path, models_tf_path, models_tflite_path, models_tflite_opt_path = create_filepaths(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "global base_model_name\n",
    "global alpha\n",
    "global resolution\n",
    "global channels\n",
    "global classes\n",
    "global variation\n",
    "global early_stopping_patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name, alpha, resolution, channels, classes, variation = model_name.split(\"_\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#os.environ['WANDB_NOTEBOOK_NAME'] = 'Experiment Workbench'\n",
    "#dataset = \"lemon_quality\"\n",
    "#dataset = \"lemon_binary_datagen\"\n",
    "#dataset = \"vvw_minval\"\n",
    "#dataset = \"vvw_minval_datagen\"dataset = \"vvw_minval_fix\"\n",
    "dataset = \"vvw_minval_datagen_fix\"\n",
    "IMG_HEIGHT = resolution\n",
    "IMG_WIDTH = resolution\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "#LOGGING_STEPS = 64\n",
    "MOMENTUM = 0.9\n",
    "LR = 0.001\n",
    "DROPOUT = 0.2\n",
    "early_stopping_patience = 30\n",
    "\n",
    "# BatchNormalization parameters\n",
    "BATCH_NORM_MOMENTUM = 0.9\n",
    "BATCH_NORM_EPSILON = 0.001\n",
    "\n",
    "PROJECT = base_model_name\n",
    "ENTITY = \"susbrock\"\n",
    "WANDB_ONLINE = True\n",
    "\n",
    "shuffle_seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = float(alpha)\n",
    "resolution = int(resolution)\n",
    "classes = int(classes.strip(\"o\"))\n",
    "channels = int(channels.strip(\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = set_batchnorm_momentum(model, BATCH_NORM_MOMENTUM)\n",
    "variation = variation + \".BN\" + str(BATCH_NORM_MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = set_dropout(model, DROPOUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for layer in model.layers:\n",
    "#     if layer is isinstance(tf.keras.layers.Dropout(rate =DROPOUT)):\n",
    "#         print(layer.rate)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Tensorboard session\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Lemon Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemon_dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "lemon_dataset_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lemon_binary_datagen \n",
    "\n",
    "def get_lemon_binary_datagen(dataset_path, img_width, img_height, batch_size, channels, normalize=True):\n",
    "    lemon_binary_dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset_binary\")\n",
    "    TRAIN_DIR = lemon_binary_dataset_path.joinpath(\"train\")\n",
    "    VAL_DIR = lemon_binary_dataset_path.joinpath(\"val\")\n",
    "    TEST_DIR = lemon_binary_dataset_path.joinpath(\"test\")\n",
    "    #BASE_DIR_TEST = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96_test\")\n",
    "    #Path.exists(BASE_DIR)\n",
    "    validation_split = 0\n",
    "    color_mode = \"rgb\"\n",
    "\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=.1,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split,\n",
    "        rescale=1. / 255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='training',\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='training',\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    test_gen =  tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    test_generator = test_gen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE, # was 1\n",
    "        subset = \"training\",\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    #print (f\"Class names: {class_names}\")\n",
    "    #print(f\"Train: {train_generator.element_spec}\")\n",
    "    #print(f\"Normalize: {normalize}\")\n",
    "\n",
    "    class_names  = [\"bad_quality\", \"good_quality\"]\n",
    "    return (train_generator, val_generator, test_generator, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lemon_quality_dataset(dataset_path, img_width, img_height, batch_size, channels, normalize=True):\n",
    "#     \"\"\" Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "#     Args: \n",
    "#         dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "#         normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "#     Returns:\n",
    "#         (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     if dataset_path.exists():\n",
    "#         try:\n",
    "#             train_dir = dataset_path.joinpath(\"train\")\n",
    "#             val_dir = dataset_path.joinpath( \"val\")\n",
    "#             test_dir = dataset_path.joinpath( \"test\")\n",
    "#         except:\n",
    "#             print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "#             raise\n",
    "\n",
    "#     channels = int(channels.strip(\"c\"))\n",
    "#     if channels==1:\n",
    "#         color_mode = \"grayscale\"\n",
    "#     else:\n",
    "#         color_mode = \"rgb\" \n",
    "#     print(f\"Color mode: {color_mode}\")\n",
    "\n",
    "#     # create the labels list to avoid inclusion of .ipynb checkpoints\n",
    "#     #labels = [\"bad_quality\", \"empty_background\", \"good_quality\"]\n",
    "\n",
    "#     print(\"Preparing training dataset...\")        \n",
    "#     train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         train_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=((img_height, img_width)),\n",
    "#         #labels=labels,\n",
    "#         batch_size=batch_size,\n",
    "#         color_mode=color_mode,\n",
    "#         shuffle=True\n",
    "#         )\n",
    "    \n",
    "\n",
    "#     class_names = train_ds.class_names\n",
    "\n",
    "\n",
    "#     print(\"Preparing validation dataset...\")    \n",
    "#     val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         val_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         color_mode=color_mode,\n",
    "#         shuffle=True\n",
    "#         )\n",
    "    \n",
    "\n",
    "#     print(\"Preparing test dataset...\")    \n",
    "#     test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         test_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         batch_size=1,\n",
    "#         color_mode=color_mode,\n",
    "#         shuffle=False\n",
    "#         )\n",
    "    \n",
    "#     # Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "#     data_augmentation = keras.Sequential(\n",
    "#         [\n",
    "#             tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "#             tf.keras.layers.RandomRotation(0.1),\n",
    "#             tf.keras.layers.RandomZoom(0.1),\n",
    "#         ]\n",
    "#         )\n",
    "\n",
    "#     #train_ds= train_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE )\n",
    "\n",
    "    \n",
    "#     # Normalize the data to the range [0, 1]\n",
    "#     if normalize:\n",
    "#         normalization_layer = tf.keras.layers.Rescaling(1./255, offset=-1)\n",
    "\n",
    "#         train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#         val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#         test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y)) #, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "#     print (f\"Class names: {class_names}\")\n",
    "#     print(f\"Train: {train_ds.element_spec}\")\n",
    "#     print(f\"Normalize: {normalize}\")\n",
    "#     return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Wake Words minval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vvw_minval_dataset(dataset_path, img_width, img_height, batch_size, channels, normalize=True):\n",
    "    \n",
    "    BASE_DIR = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96\")\n",
    "    BASE_DIR_TEST = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96_test\")\n",
    "    Path.exists(BASE_DIR)\n",
    "    validation_split = 0.1\n",
    "    color_mode = \"rgb\"\n",
    "\n",
    "\n",
    "    print(\"Preparing vvw_minval_training dataset...\")        \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        BASE_DIR,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"training\",\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #labels=labels,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=color_mode,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    print(\"Preparing vvw_minval_validation dataset...\")        \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        BASE_DIR,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"validation\",\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #labels=labels,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=color_mode,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "    print(\"Preparing test dataset...\")        \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        BASE_DIR_TEST,\n",
    "        validation_split=None,\n",
    "        #subset=\"validation\",\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #labels=labels,\n",
    "        batch_size=1,\n",
    "        color_mode=color_mode,\n",
    "        shuffle=False\n",
    "        )\n",
    "\n",
    "\n",
    "    # Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "    data_augmentation = keras.Sequential([\n",
    "            tf.keras.layers.RandomRotation(10), #0.1\n",
    "            tf.keras.layers.RandomTranslation(\n",
    "                height_factor = 0.05,\n",
    "                width_factor = 0.05),\n",
    "            tf.keras.layers.RandomZoom(0.1),\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\")\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    train_ds= train_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE )\n",
    "    val_ds= val_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE )\n",
    "\n",
    "    # Normalize the data to the range [0, 1]\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255, offset=-1)\n",
    "\n",
    "    train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y)) #, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    labels = class_names\n",
    "    \n",
    "    print (f\"Class names: {class_names}\")\n",
    "    print(f\"Train: {train_ds.element_spec}\")\n",
    "    print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vvw_minval_dataset_fix(dataset_path, img_width, img_height, batch_size, channels, normalize=True):\n",
    "    \n",
    "    TRAIN_DIR = Path.cwd().joinpath(\"datasets\", \"visual_wake_words\", \"train\")\n",
    "    VAL_DIR = Path.cwd().joinpath(\"datasets\", \"visual_wake_words\", \"val\")\n",
    "    TEST_DIR = Path.cwd().joinpath(\"datasets\", \"visual_wake_words\", \"test\")\n",
    "    #Path.exists(BASE_DIR)\n",
    "    #validation_split = 0.1\n",
    "    color_mode = \"rgb\"\n",
    "\n",
    "\n",
    "    print(\"Preparing vvw_minval_training dataset...\")        \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        #validation_split=validation_split,\n",
    "        #subset=\"training\",\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #labels=labels,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=color_mode,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    print(\"Preparing vvw_minval_validation dataset...\")        \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        VAL_DIR,\n",
    "        #validation_split=validation_split,\n",
    "        #subset=\"validation\",\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #labels=labels,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=color_mode,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "    print(\"Preparing test dataset...\")        \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        TEST_DIR,\n",
    "        #validation_split=None,\n",
    "        #subset=\"validation\",\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #labels=labels,\n",
    "        batch_size=1,\n",
    "        color_mode=color_mode,\n",
    "        shuffle=False\n",
    "        )\n",
    "\n",
    "\n",
    "    # Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "    data_augmentation = keras.Sequential([\n",
    "            tf.keras.layers.RandomRotation(10), #0.1\n",
    "            tf.keras.layers.RandomTranslation(\n",
    "                height_factor = 0.05,\n",
    "                width_factor = 0.05),\n",
    "            tf.keras.layers.RandomZoom(0.1),\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\")\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    train_ds= train_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE )\n",
    "    val_ds= val_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE )\n",
    "\n",
    "    # Normalize the data to the range [0, 1]\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255, offset=-1)\n",
    "\n",
    "    train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y)) #, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    labels = class_names\n",
    "    \n",
    "    print (f\"Class names: {class_names}\")\n",
    "    print(f\"Train: {train_ds.element_spec}\")\n",
    "    print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96\")\n",
    "# BASE_DIR_TEST = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96_test\")\n",
    "# Path.exists(BASE_DIR)\n",
    "# validation_split = 0.1\n",
    "# color_mode = \"rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Preparing training dataset...\")        \n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     BASE_DIR,\n",
    "#     validation_split=validation_split,\n",
    "#     subset=\"training\",\n",
    "#     seed=shuffle_seed,\n",
    "#     image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#     #labels=labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     color_mode=color_mode,\n",
    "#     shuffle=True\n",
    "#     )\n",
    "\n",
    "# class_names = train_ds.class_names\n",
    "\n",
    "# print(\"Preparing validation dataset...\")        \n",
    "# val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     BASE_DIR,\n",
    "#     validation_split=validation_split,\n",
    "#     subset=\"validation\",\n",
    "#     seed=shuffle_seed,\n",
    "#     image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#     #labels=labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     color_mode=color_mode,\n",
    "#     shuffle=True\n",
    "#     )\n",
    "\n",
    "# print(\"Preparing test dataset...\")        \n",
    "# test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     BASE_DIR_TEST,\n",
    "#     validation_split=None,\n",
    "#     #subset=\"validation\",\n",
    "#     seed=shuffle_seed,\n",
    "#     image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#     #labels=labels,\n",
    "#     batch_size=1,\n",
    "#     color_mode=color_mode,\n",
    "#     shuffle=False\n",
    "#     )\n",
    "\n",
    "\n",
    "#     #   Preprocessing form Visual Wake Word Challenge:\n",
    "#     #   rotation_range=10,\n",
    "#     #   width_shift_range=0.05,\n",
    "#     #   height_shift_range=0.05,\n",
    "#     #   zoom_range=.1,\n",
    "#     #   horizontal_flip=True,\n",
    "# # Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "# data_augmentation = keras.Sequential([\n",
    "#         tf.keras.layers.RandomRotation(0.1), #0,1\n",
    "#         tf.keras.layers.RandomTranslation(\n",
    "#             height_factor = 0.05,\n",
    "#             width_factor = 0.05\n",
    "#         ),\n",
    "#         tf.keras.layers.RandomZoom(0.1),\n",
    "#         tf.keras.layers.RandomFlip(\"horizontal\")\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# train_ds= train_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE )\n",
    "\n",
    "\n",
    "# # Normalize the data to the range [0, 1]\n",
    "\n",
    "# normalization_layer = tf.keras.layers.Rescaling(1./255, offset=-1)\n",
    "\n",
    "# train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y)) #, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# labels = class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vvw_minval_datagen(dataset_path, img_width, img_height, batch_size, channels, normalize=True):\n",
    "    BASE_DIR = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96\")\n",
    "    BASE_DIR_TEST = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96_test\")\n",
    "    Path.exists(BASE_DIR)\n",
    "    validation_split = 0.1\n",
    "    color_mode = \"rgb\"\n",
    "\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=.1,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split,\n",
    "        rescale=1. / 255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        BASE_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='training',\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        BASE_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='validation',\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    test_gen =  tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    test_generator = test_gen.flow_from_directory(\n",
    "        BASE_DIR_TEST,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE, # was 1\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    #print (f\"Class names: {class_names}\")\n",
    "    #print(f\"Train: {train_generator.element_spec}\")\n",
    "    #print(f\"Normalize: {normalize}\")\n",
    "\n",
    "    class_names  = [\"non_person\", \"person\"]\n",
    "    return (train_generator, val_generator, test_generator, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vvw_minval_datagen_fix(dataset_path, img_width, img_height, batch_size, channels, normalize=True):\n",
    "    TRAIN_DIR = Path.cwd().joinpath(\"datasets\", \"visual_wake_words\", \"train\")\n",
    "    VAL_DIR = Path.cwd().joinpath(\"datasets\", \"visual_wake_words\", \"val\")\n",
    "    TEST_DIR = Path.cwd().joinpath(\"datasets\", \"visual_wake_words\", \"test\")\n",
    "    #Path.exists(BASE_DIR)\n",
    "    validation_split = 0\n",
    "    color_mode = \"rgb\"\n",
    "\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=.1,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split,\n",
    "        rescale=1. / 255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='training',\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='training',\n",
    "        color_mode=color_mode,\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    test_gen =  tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    test_generator = test_gen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=BATCH_SIZE, # was 1\n",
    "        color_mode=color_mode,\n",
    "        subset='training',\n",
    "        class_mode=\"sparse\")\n",
    "    \n",
    "    #print (f\"Class names: {class_names}\")\n",
    "    #print(f\"Train: {train_generator.element_spec}\")\n",
    "    #print(f\"Normalize: {normalize}\")\n",
    "\n",
    "    class_names  = [\"non_person\", \"person\"]\n",
    "    return (train_generator, val_generator, test_generator, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96\")\n",
    "# BASE_DIR_TEST = Path.cwd().parent.joinpath(\"tiny_mlperf\", \"vw_coco2014_96_test\")\n",
    "# Path.exists(BASE_DIR)\n",
    "# validation_split = 0.1\n",
    "# color_mode = \"rgb\"\n",
    "\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#       rotation_range=10,\n",
    "#       width_shift_range=0.05,\n",
    "#       height_shift_range=0.05,\n",
    "#       zoom_range=.1,\n",
    "#       horizontal_flip=True,\n",
    "#       validation_split=validation_split,\n",
    "#       rescale=1. / 255)\n",
    "# train_generator = datagen.flow_from_directory(\n",
    "#     BASE_DIR,\n",
    "#     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     subset='training',\n",
    "#     color_mode='rgb',\n",
    "#     class_mode=\"sparse\")\n",
    "# val_generator = datagen.flow_from_directory(\n",
    "#     BASE_DIR,\n",
    "#     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     subset='validation',\n",
    "#     color_mode='rgb',\n",
    "#     class_mode=\"sparse\")\n",
    "\n",
    "\n",
    "# print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_epochs(model, train_generator, val_generator, epoch_count,\n",
    "#                  learning_rate):\n",
    "#   model.compile(\n",
    "#       optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "#       #loss='categorical_crossentropy',\n",
    "#       loss='sparse_categorical_crossentropy',\n",
    "#       metrics=['accuracy'])\n",
    "#   history_fine = model.fit(\n",
    "#       train_generator,\n",
    "#       steps_per_epoch=len(train_generator),\n",
    "#       epochs=epoch_count,\n",
    "#       validation_data=val_generator,\n",
    "#       validation_steps=len(val_generator),\n",
    "#       batch_size=BATCH_SIZE)\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_epochs(model, train_generator, val_generator, 20, 0.001)\n",
    "# model = train_epochs(model, train_generator, val_generator, 10, 0.0005)\n",
    "# model = train_epochs(model, train_generator, val_generator, 20, 0.00025)\n",
    "# model.save(filepath=\"vvw_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape = (IMG_WIDTH, IMG_HEIGHT, channels)\n",
    "#train_ds, val_ds, test_ds, labels = get_vvw_dataset(input_shape, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     img = tf.keras.preprocessing.image.array_to_img(\n",
    "#                 images[0], scale=True\n",
    "#             )\n",
    "#     display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = labels\n",
    "# print(class_names)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# img = np.random.random(size=(100, 100, 3))\n",
    "# pil_img = tf.keras.utils.array_to_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_batch, labels_batch in train_ds:\n",
    "#     print(image_batch.shape)\n",
    "#     print(labels_batch.shape)\n",
    "#     print(labels_batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = len(labels)\n",
    "# print(f\"The dataset contains {classes } classes.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name, classes):\n",
    "    if name == \"lemon_quality\":\n",
    "        train_ds, val_ds, test_ds, class_names = get_lemon_quality_dataset(lemon_dataset_path, resolution, resolution, BATCH_SIZE, channels)\n",
    "        dataset_name = \"lemon_quality\"\n",
    "\n",
    "    elif name == \"lemon_binary_datagen\":\n",
    "        train_ds, val_ds, test_ds, class_names = get_lemon_binary_datagen(None, resolution, resolution, BATCH_SIZE, channels, normalize=True)\n",
    "        dataset_name = \"lemon_binary_datagen\"\n",
    "    elif name == \"vvw_minval\":\n",
    "        train_ds, val_ds, test_ds, class_names = get_vvw_minval_dataset(None, resolution, resolution, BATCH_SIZE, channels, normalize=True)\n",
    "        dataset_name = \"vvw_minval\"\n",
    "    elif name == \"vvw_minval_fix\":\n",
    "        train_ds, val_ds, test_ds, class_names = get_vvw_minval_dataset_fix(None, resolution, resolution, BATCH_SIZE, channels, normalize=True)\n",
    "        dataset_name = \"vvw_minval_fix\"\n",
    "\n",
    "\n",
    "    elif name == \"vvw_minval_datagen\":\n",
    "        train_ds, val_ds, test_ds, class_names = get_vvw_minval_datagen(None, resolution, resolution, BATCH_SIZE, channels, normalize=True)\n",
    "        dataset_name = \"vvw_minval_datagen\"  \n",
    "    elif name == \"vvw_minval_datagen_fix\":\n",
    "        train_ds, val_ds, test_ds, class_names = get_vvw_minval_datagen_fix(None, resolution, resolution, BATCH_SIZE, channels, normalize=True)\n",
    "        dataset_name = \"vvw_minval_datagen_fix\"  \n",
    "    else:\n",
    "        print(f\"Dataset {name} is not a valid dataset\")\n",
    "        train_ds, val_ds, test_ds, class_names, dataset_name = 0\n",
    "\n",
    "\n",
    "    if len(class_names) != classes:\n",
    "        print(f\"Incompatible dataset and model. \\n, \\\n",
    "            Model uses {classes} classes - dataset has {len(class_names)} classes!\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return train_ds, val_ds, test_ds, class_names, dataset_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_vvw_minval_dataset_fix(None, resolution, resolution, BATCH_SIZE, channels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = \"vvw_minval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1660 images belonging to 2 classes.\n",
      "Found 207 images belonging to 2 classes.\n",
      "Found 209 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds, class_names, dataset_name = get_dataset(dataset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", model_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "root_logdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name not in  [\"vvw_minval_datagen\", \"vvw_minval_datagen_fix\", \"lemon_binary_datagen\"]:\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # optimize the data flow\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    #train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "    train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api = wandb.Api()\n",
    "api = wandb.Api(timeout=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from https://www.tensorflow.org/guide/keras/custom_callback#examples_of_keras_callback_applications\n",
    "\n",
    "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "  Arguments:\n",
    "      patience: Number of epochs to wait after min has been hit. After this\n",
    "      number of no improvement, training stops.\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience=0):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingAtMaxValAccuracy(keras.callbacks.Callback):\n",
    "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "  Arguments:\n",
    "      patience: Number of epochs to wait after max has been hit. After this\n",
    "      number of no improvement, training stops.\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience=30):\n",
    "        super(EarlyStoppingAtMaxValAccuracy, self).__init__()\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = 0\n",
    "        self.best_epoch = 0\n",
    "        self.best_epoch_loss = np.Infinity\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_accuracy\")\n",
    "        if np.greater(current, self.best):\n",
    "            self.best = current\n",
    "            self.best_epoch = epoch\n",
    "            self.best_epoch_loss = logs.get(\"val_loss\")\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "        metrics = dict()\n",
    "        metrics[\"best_epoch\"] = self.best_epoch\n",
    "        metrics[\"best_val_accuracy\"] = self.best\n",
    "        metrics[\"best_epoch_loss\"] = self.best_epoch_loss\n",
    "\n",
    "        wandb.log(metrics)\n",
    "\n",
    "\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WANDB_ONLINE == True:\n",
    "    os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "else:\n",
    "    os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "    \n",
    "def train_model_wandb(model, train_ds, val_ds, test_ds):\n",
    "\n",
    "        # solve issue from: https://github.com/wandb/wandb/issues/3536\n",
    "        if len(wandb.patched[\"tensorboard\"]) > 0:\n",
    "                wandb.tensorboard.unpatch()\n",
    "                \n",
    "        # Configure Tensorboard root log directory to read the debugging information\n",
    "        wandb.tensorboard.patch(root_logdir=root_logdir)\n",
    "        # wandb.tensorboard.patch(root_logdir=\"wandb.run.dir\")\n",
    "        \n",
    "        # Generate run ids\n",
    "        id = wandb.sdk.lib.runid.generate_id()\n",
    "\n",
    "        run = wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT,\n",
    "                name = model_name,\n",
    "                id = id, \n",
    "                resume=True,\n",
    "                sync_tensorboard=True\n",
    "                )\n",
    "\n",
    "        global BATCH_SIZE\n",
    "        # Specify the configuration variables\n",
    "        config = wandb.config\n",
    "        \n",
    "        config.batch_size = BATCH_SIZE\n",
    "        #config.dropout =DROPOUT\n",
    "        config.learn_rate = LR\n",
    "        config.momentum = MOMENTUM\n",
    "        #config.decay = 1e-6\n",
    "        config.epochs = EPOCHS\n",
    "        config.classes = classes\n",
    "        config.id = id\n",
    "        config.seed = seed\n",
    "        config.architecture = model_name\n",
    "        config.dataset = dataset_name\n",
    "        config.batch_norm_momentum = BATCH_NORM_MOMENTUM\n",
    "        \n",
    "\n",
    "        # enable Tensorflow Debugging\n",
    "        #tf.debugging.experimental.enable_dump_debug_info(\"./logs/debug\", \n",
    "        #        tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "\n",
    "       # optimizer = tf.keras.optimizers.SGD(learning_rate=LR, momentum=MOMENTUM)\n",
    "        config.optimizer = optimizer._name\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                        loss='sparse_categorical_crossentropy', # sparse_categorical_crossentropy\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= wandb.run.dir, histogram_freq=0, update_freq=\"epoch\") #, profile_batch=\"10, 20\")\n",
    "        #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= logdir, histogram_freq=1)\n",
    "        #wandb_callback = WandbCallback()# input_type=\"image\", labels=labels) #, validation_data = val_ds.as_numpy_iterator())\n",
    "\n",
    "        def lr_schedule(epoch):\n",
    "                \"\"\"\n",
    "                Returns a custom learning rate that decreases as epochs progress.\n",
    "                \"\"\"\n",
    "                learning_rate = LR\n",
    "                if epoch > 20:\n",
    "                        learning_rate = 0.0001\n",
    "                tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "                return learning_rate\n",
    "\n",
    "        def lr_vvw(epoch, lr):\n",
    "                \"\"\"\n",
    "                Returns the learing rate schedule used in training for Visual Wake Word dataset.\n",
    "                \"\"\"\n",
    "        \n",
    "                if epoch < 10: # was 20\n",
    "                        lr = 0.001\n",
    "                elif epoch < 30:\n",
    "                        lr = 0.0005\n",
    "                else:\n",
    "                        lr = 0.00025\n",
    "                return lr\n",
    "\n",
    "\n",
    "        lr_callback = LearningRateScheduler(lr_vvw)\n",
    "        #lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "        #best_model_path = Path(wandb.run.dir).joinpath(f\"best_model\")\n",
    "\n",
    "        checkpoint = WandbModelCheckpoint(\"best_model\",\n",
    "                monitor=\"val_accuracy\",\n",
    "                save_best_only=True,\n",
    "                save_freq=\"epoch\")\n",
    "\n",
    "        global early_stopping_patience\n",
    "        early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=early_stopping_patience) # TODO: should this be the loss?\n",
    "\n",
    "        callbacks =[\n",
    "                #tensorboard_callback,\n",
    "                lr_callback,\n",
    "                #wandb_callback,\n",
    "                WandbMetricsLogger(),\n",
    "                checkpoint,\n",
    "                #early_stopping,\n",
    "                #EarlyStoppingAtMaxValAccuracy()\n",
    "        ]\n",
    "\n",
    "        print(f\"Training on {dataset_name}\")\n",
    "\n",
    "        history = model.fit(train_ds,\n",
    "                epochs=EPOCHS, \n",
    "                validation_data=val_ds, \n",
    "                callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        #wandb.save(\"last_model.h5\")\n",
    "\n",
    "        print(\"finished training\")\n",
    "\n",
    "\n",
    "        #best_model = keras.models.load_model(best_model_path) # not needed due to \"restore_best_weights=True\"\n",
    "\n",
    "        # y_val_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "        # y_val_pred = model.predict(val_ds).argmax(axis=1)\n",
    "\n",
    "        print(\"Predict on test dataset\")\n",
    "\n",
    "\n",
    "\n",
    "        # for x_test, y_test in test_ds:\n",
    "        # #test_ds = list(test_ds)\n",
    "\n",
    "        # print(\"Get predictions on test set\")\n",
    "        # y_test_pred = model.predict(test_ds).argmax(axis=1)\n",
    "        # print(\"Get y_test_true:\")\n",
    "        # y_test_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "        # print(\"finish predictions\")\n",
    "\n",
    "        print(\"evaluate on test dataset\")\n",
    "        results = model.evaluate(test_ds, batch_size=BATCH_SIZE)\n",
    "        print(\"test loss, test acc:\", results)\n",
    "        wandb.log({\n",
    "                \"test_loss\" : results[0],\n",
    "                \"test_accuracy\" : results[1]\n",
    "        })\n",
    "\n",
    "        # # log data for the confusion matrix\n",
    "        # wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
    "        #                 y_true=y_test_true, preds=y_test_pred, #y_test_true[0]\n",
    "        #                 class_names=class_names)})\n",
    "\n",
    "\n",
    "        run.finish()\n",
    "        return history, model, run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id kje4znk1 but id 2v0implc is set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>i:\\tinyml\\tiny_cnn\\wandb\\run-20230209_204224-2v0implc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/mobilenetv1/runs/2v0implc\" target=\"_blank\">mobilenetv1_0.25_96_c3_o2_l3</a></strong> to <a href=\"https://wandb.ai/susbrock/mobilenetv1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/susbrock/mobilenetv1\" target=\"_blank\">https://wandb.ai/susbrock/mobilenetv1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/susbrock/mobilenetv1/runs/2v0implc\" target=\"_blank\">https://wandb.ai/susbrock/mobilenetv1/runs/2v0implc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on lemon_binary_datagen\n",
      " 6/52 [==>...........................] - ETA: 1:54 - loss: 0.8398 - accuracy: 0.5312WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7897s vs `on_train_batch_end` time: 1.4506s). Check your callbacks.\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.6765INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\best_model)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 330s 4s/step - loss: 0.6242 - accuracy: 0.6765 - val_loss: 1.1712 - val_accuracy: 0.4589 - lr: 0.0010\n",
      "finished training\n",
      "Predict on test dataset\n",
      "evaluate on test dataset\n",
      "7/7 [==============================] - 28s 5s/step - loss: 1.1642 - accuracy: 0.4593\n",
      "test loss, test acc: [1.164162278175354, 0.45933014154434204]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/lr</td><td></td></tr><tr><td>epoch/val_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr><tr><td>test_accuracy</td><td></td></tr><tr><td>test_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.67651</td></tr><tr><td>epoch/epoch</td><td>0</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.6242</td></tr><tr><td>epoch/lr</td><td>0.001</td></tr><tr><td>epoch/val_accuracy</td><td>0.45894</td></tr><tr><td>epoch/val_loss</td><td>1.17119</td></tr><tr><td>test_accuracy</td><td>0.45933</td></tr><tr><td>test_loss</td><td>1.16416</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mobilenetv1_0.25_96_c3_o2_l3</strong> at: <a href=\"https://wandb.ai/susbrock/mobilenetv1/runs/2v0implc\" target=\"_blank\">https://wandb.ai/susbrock/mobilenetv1/runs/2v0implc</a><br/>Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230209_204224-2v0implc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "history, model, run_id = train_model_wandb(model, train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb sync i:\\tinyml\\tiny_cnn\\wandb\\offline-run-20221227_091238-1vzrst0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = wandb.restore('/best_model/saved_model', run_path=f\"{ENTITY}/{PROJECT}/{run_id}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models_tflite_trained_path = models_dir.joinpath(model_name, f\"{model_name}_trained.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the model to the TensorFlow Lite format without quantization\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# # converter = tf.lite.TFLiteConverter.from_saved_model(models_path)\n",
    "# tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Save the model.\n",
    "# with open(models_tflite_trained_path, \"wb\") as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite with INT8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_iter = test_ds.as_numpy_iterator()\n",
    "\n",
    "# for i in range(1):\n",
    "#     sample = next(sample_iter)[0]\n",
    "# print(\"Number of samples: {}\".format(sample.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def representative_data_gen():\n",
    "#     for i in range(100):\n",
    "#       yield([test_ds[i].reshape(1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representative_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repr_ds = test_ds.unbatch()\n",
    "\n",
    "# def representative_data_gen():\n",
    "#   for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "#     yield [i_value]\n",
    "    \n",
    "# converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# # set the optimization flag\n",
    "# converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# # enforce integer only quantization\n",
    "# converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter_opt.inference_input_type = tf.uint8\n",
    "# converter_opt.inference_output_type = tf.uint8\n",
    "\n",
    "# # provide a representative dataset for quantization\n",
    "# converter_opt.representative_dataset = representative_data_gen\n",
    "\n",
    "# tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open(models_tflite_opt_path, 'wb') as f:\n",
    "#   f.write(tflite_model_opt)\n",
    "# models_tflite_opt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_tflite_quant_INT8(model, data_generator):\n",
    "#     converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "#     # set the optimization flag\n",
    "#     converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#     # enforce integer only quantization\n",
    "#     converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "#     converter_opt.inference_input_type = tf.uint8\n",
    "#     converter_opt.inference_output_type = tf.uint8\n",
    "\n",
    "#     # provide a representative dataset for quantization\n",
    "#     converter_opt.representative_dataset = data_generator\n",
    "\n",
    "#     tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "#     return tflite_model_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_opt = convert_tflite_quant_INT8(model, data_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the TensorFlow Lite models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image = test_ds.take(1)\n",
    "# test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_gen = test_ds.unbatch().batch(1)\n",
    "# test_gen = test_ds.as_numpy_iterator()\n",
    "# #test_gen = test_gen.next() \n",
    "# #test_image = test_gen.take(1)\n",
    "# test_image, test_label = next(test_gen)\n",
    "# test_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_predict(model_path, test_image):\n",
    "    # Initialize the interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(model_path))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:  # was np.uint8\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        test_image = test_image / input_scale + input_zero_point\n",
    "        \n",
    "    test_image = test_image.astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    #interpreter.set_tensor(input_details[\"index\"], np.expand_dims(test_image[0], axis=0)) # only needed when input shape (96, 96, 3)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    prediction = output.argmax()\n",
    "    print(f\"Prediction: Class {prediction} derived from {output}\")\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflite_result = tflite_predict(models_tflite_opt_path, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tflite_predict_on_dataset(model_path, dataset):\n",
    "    # find length of dataset\n",
    "    test_gen = dataset.as_numpy_iterator()\n",
    "    num_images = len(list(test_gen))\n",
    "\n",
    "    predictions = []\n",
    "    y_trues = []\n",
    "\n",
    "    test_gen = dataset.as_numpy_iterator()\n",
    "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    # iterate over the complete test_set\n",
    "    for i in range(num_images):\n",
    "        test_image, y_true = next(test_gen)\n",
    "        prediction = tflite_predict(model_path, test_image)\n",
    "        predictions.append(prediction)\n",
    "        y_trues.append(y_true[0])\n",
    "        #accuracy.update_state(y_true, prediction) # TODO: correct accuracy\n",
    "        print(f\"{i}, {test_image.shape} - true label: {y_true[0]} vs {tflite_result}\")\n",
    "\n",
    "    #accuracy = (np.sum(predictions == y_trues) * 100) / num_images\n",
    "    print(f\"Accuracy: {accuracy.result()} - (Number of test samples: {num_images})\")\n",
    "    return predictions, y_trues    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds, trues = tflite_predict_on_dataset(models_tflite_opt_path, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = (np.sum(preds == trues) * 100) / num_test_images\n",
    "# accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "# print(\"Evaluate on test data\")\n",
    "# results = model.evaluate(test_ds, batch_size=BATCH_SIZE)\n",
    "# print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "# print(\"Generate predictions for 3 samples\")\n",
    "# predictions = model.predict(x_test[:3])\n",
    "# print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity = \"susbrock\"\n",
    "\n",
    "\n",
    "# run = api.run(f\"{entity}/{PROJECT}/{run_id}\")\n",
    "# run.summary[\"test_accuracy\"] = results[1]\n",
    "# run.summary[\"test_loss\"] = results[0]\n",
    "# run.summary.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(test_ds)\n",
    "# test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_pred_ids = test_predictions.argmax(axis=1)\n",
    "# len(top_pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = [y for x, y in test_ds]\n",
    "# y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "# len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_mtx = tf.math.confusion_matrix(y_true, top_pred_ids, num_classes=classes)\n",
    "#     # list(ds_test.map(lambda x, y: y)),\n",
    "#     # predict_class_label_number(test_data),\n",
    "#     # num_classes=len(label_names))\n",
    "    \n",
    "# confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, labels):\n",
    "  plt.figure(figsize=(6, 6))\n",
    "  sns.heatmap(cm, xticklabels=labels, yticklabels=labels, \n",
    "              annot=True, fmt='g')\n",
    "  plt.xlabel('Prediction')\n",
    "  plt.ylabel('Label')\n",
    "  plt.show()\n",
    "  return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_plot = show_confusion_matrix(confusion_mtx, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_plot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code reserved for troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha):\n",
    "#     model = tf.keras.applications.mobilenet.MobileNet(\n",
    "#         input_shape=input_shape,\n",
    "#         alpha=alpha,\n",
    "#         depth_multiplier=1,\n",
    "#         dropout=0.001,\n",
    "#         include_top=True,\n",
    "#         weights=None, #'imagenet'\n",
    "#         input_tensor=None,\n",
    "#         pooling=None,\n",
    "#         classes=classes,\n",
    "#         classifier_activation='softmax',\n",
    "#         #**kwargs\n",
    "#     )\n",
    "\n",
    "#     #model._name = model.name + \"_keras\" # model.name cannot be overritten\n",
    "\n",
    "#     return model\n",
    "#     #model = mobilenet_v1_keras((IMG_WIDTH, IMG_HEIGHT, 3), classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "# def train_model(model):\n",
    "\n",
    "#         # solve issue from: https://github.com/wandb/wandb/issues/3536\n",
    "#         # if len(wandb.patched[\"tensorboard\"]) > 0:\n",
    "#         #         wandb.tensorboard.unpatch()\n",
    "                \n",
    "#         # Configure Tensorboard root log directory to read the debugging information\n",
    "#         #wandb.tensorboard.patch(root_logdir=root_logdir)\n",
    "#         # wandb.tensorboard.patch(root_logdir=\"wandb.run.dir\")\n",
    "        \n",
    "#         # wandb.init(\n",
    "#         #         # Set the project where this run will be logged\n",
    "#         #         project=PROJECT, \n",
    "#         #         # Track hyperparameters and run metadata\n",
    "#         #         #config={\n",
    "#         #         #\"learning_rate\": LR,\n",
    "#         #         #\"epochs\": EPOCHS,\n",
    "#         #         #},\n",
    "#         #         sync_tensorboard=True\n",
    "#         #         )\n",
    "\n",
    "\n",
    "\n",
    "#         # config = wandb.config\n",
    "#         # # Specify the configuration variables\n",
    "#         # config.batch_size = BATCH_SIZE\n",
    "#         # config.dropout =DROPOUT\n",
    "#         # config.learn_rate = LR\n",
    "#         # #config.decay = 1e-6\n",
    "#         # #config.momentum = 0.9\n",
    "#         # config.epochs = EPOCHS\n",
    "#         # config.classes = classes\n",
    "        \n",
    "\n",
    "#         # enable Tensorflow Debugging\n",
    "#         #tf.debugging.experimental.enable_dump_debug_info(\"./logs/debug\", \n",
    "#         #        tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "#         #model = mobilenet\n",
    "#         model.compile(optimizer='adam',\n",
    "#                         loss='sparse_categorical_crossentropy',\n",
    "#                         metrics=['accuracy'])\n",
    "\n",
    "#         logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#         #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= wandb.run.dir, histogram_freq=10, update_freq=\"epoch\") #, profile_batch=\"10, 20\")\n",
    "#         tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= logdir) #, histogram_freq=1)\n",
    "#         #wandb_callback = WandbCallback()# input_type=\"image\", labels=labels) #, validation_data = val_ds.as_numpy_iterator())\n",
    "\n",
    "#         early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience= early_stopping_patience)\n",
    "\n",
    "#         #checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n",
    "\n",
    "#         callbacks =[\n",
    "#                 #tensorboard_callback,\n",
    "#                 #wandb_callback,\n",
    "#                 #WandbMetricsLogger(),\n",
    "#                 #checkpoint,\n",
    "#                 #early_stopping\n",
    "#         ]\n",
    "\n",
    "#         history = model.fit(train_ds,\n",
    "#                 epochs=EPOCHS, \n",
    "#                 validation_data=val_ds, \n",
    "#                 callbacks=callbacks\n",
    "#         )\n",
    "\n",
    "#         # wandb.log({\n",
    "#         #         \"loss\": history.history[\"loss\"],\n",
    "#         #         \"accuracy\": history.history[\"accuracy\"],\n",
    "#         #         \"val_loss\": history.history[\"val_loss\"],\n",
    "#         #         \"val_accuracy\": history.history[\"val_accuracy\"],                                \n",
    "#         # })\n",
    "        \n",
    "#         #wandb.finish()\n",
    "#         return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faa6c31b20b8f809b81d6d7d22a84ccd9f354666f54133d1793fa4c65539801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
