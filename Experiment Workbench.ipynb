{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "#import deeplake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Confirm that TensorFlow can access GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Tensorboard session\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['WANDB_NOTEBOOK_NAME'] = 'Experiment Workbench'\n",
    "\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "#LOGGING_STEPS = 64\n",
    "LR = 0.0001\n",
    "DROPOUT = 0.2\n",
    "\n",
    "PROJECT = \"Tiny CNN\"\n",
    "MODELNAME = \"Simple_Net\"\n",
    "\n",
    "logdir = os.path.join(\"logs\", MODELNAME, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "root_logdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Lemon Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 32\n",
    "#img_height = 92\n",
    "#img_width = 92\n",
    "shuffle_seed = 42\n",
    "\n",
    "def get_lemon_quality_dataset(dataset_path, img_width, img_height, batch_size, normalize=True):\n",
    "    \"\"\" Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "    Args: \n",
    "        dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "        normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "    Returns:\n",
    "        (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "    \n",
    "    \"\"\"\n",
    "    if dataset_path.exists():\n",
    "        try:\n",
    "            train_dir = dataset_path.joinpath(\"train\")\n",
    "            val_dir = dataset_path.joinpath( \"val\")\n",
    "            test_dir = dataset_path.joinpath( \"test\")\n",
    "        except:\n",
    "            print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "            raise\n",
    "\n",
    "    print(\"Preparing training dataset...\")        \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "\n",
    "    print(\"Preparing validation dataset...\")    \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    print(\"Preparing test dataset...\")    \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "    \n",
    "    # Normalize the data to the range [0, 1]\n",
    "    if normalize:\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "        train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print (f\"Class names: {class_names}\")\n",
    "    print(train_ds.element_spec)\n",
    "    print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "dataset_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training dataset...\n",
      "Found 2021 files belonging to 3 classes.\n",
      "Preparing validation dataset...\n",
      "Found 252 files belonging to 3 classes.\n",
      "Preparing test dataset...\n",
      "Found 255 files belonging to 3 classes.\n",
      "Class names: ['bad_quality', 'empty_background', 'good_quality']\n",
      "(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "Normalize: True\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = list(train_ds.as_numpy_iterator())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 96, 96, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
    "    input_shape=(96,96,3),\n",
    "    alpha=0.25,\n",
    "    depth_multiplier=1,\n",
    "    dropout=DROPOUT,\n",
    "    include_top=True,\n",
    "    weights= None, #'imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation='softmax',\n",
    "    #**kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the data flow\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "def train_model():\n",
    "        # solve issue from: https://github.com/wandb/wandb/issues/3536\n",
    "        if len(wandb.patched[\"tensorboard\"]) > 0:\n",
    "                wandb.tensorboard.unpatch()\n",
    "                \n",
    "        # Configure Tensorboard root log directory to read the debugging information\n",
    "        \n",
    "        wandb.tensorboard.patch(root_logdir=root_logdir)\n",
    "        # wandb.tensorboard.patch(root_logdir=\"wandb.run.dir\")\n",
    "        \n",
    "        wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT, \n",
    "                # Track hyperparameters and run metadata\n",
    "                #config={\n",
    "                #\"learning_rate\": LR,\n",
    "                #\"epochs\": EPOCHS,\n",
    "                #},\n",
    "                sync_tensorboard=True\n",
    "                )\n",
    "\n",
    "\n",
    "        config = wandb.config\n",
    "        # Specify the configuration variables\n",
    "        config.dropout =DROPOUT\n",
    "        config.learn_rate = LR\n",
    "        #config.decay = 1e-6\n",
    "        #config.momentum = 0.9\n",
    "        config.epochs = EPOCHS\n",
    "        config.classes = classes\n",
    "\n",
    "        # enable Tensorflow Debugging\n",
    "        #tf.debugging.experimental.enable_dump_debug_info(\"./logs/debug\", \n",
    "        #        tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "        model = mobilenet\n",
    "        model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= wandb.run.dir, histogram_freq=10, update_freq=\"epoch\") #, profile_batch=\"10, 20\")\n",
    "        #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= logdir, histogram_freq=1)\n",
    "        wandb_callback = WandbCallback(input_type=\"image\", labels=labels, validation_data = val_ds)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=50)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n",
    "\n",
    "        history = model.fit(train_ds,\n",
    "                epochs=EPOCHS, \n",
    "                validation_data=val_ds, \n",
    "                callbacks=[tensorboard_callback,\n",
    "                #wandb_callback, \n",
    "                checkpoint, \n",
    "                early_stopping]\n",
    "        )\n",
    "\n",
    "        wandb.log({\n",
    "                \"loss\": history.history[\"loss\"],\n",
    "                \"accuracy\": history.history[\"accuracy\"],\n",
    "                \"val_loss\": history.history[\"val_loss\"],\n",
    "                \"val_accuracy\": history.history[\"val_accuracy\"],                                \n",
    "        })\n",
    "        \n",
    "        wandb.finish()\n",
    "        return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>i:\\tinyml\\tiny_cnn\\wandb\\run-20221106_190447-1xmvqy8q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/1xmvqy8q\" target=\"_blank\">usual-yogurt-74</a></strong> to <a href=\"https://wandb.ai/susbrock/Tiny%20CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 14s 132ms/step - loss: 1.0285 - accuracy: 0.4617 - val_loss: 1.0815 - val_accuracy: 0.4444\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.8385 - accuracy: 0.5997 - val_loss: 1.0617 - val_accuracy: 0.4444\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.5696 - accuracy: 0.7546 - val_loss: 1.0519 - val_accuracy: 0.4444\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.3631 - accuracy: 0.8525 - val_loss: 1.0481 - val_accuracy: 0.4444\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 4s 63ms/step - loss: 0.2771 - accuracy: 0.8926 - val_loss: 1.0498 - val_accuracy: 0.4444\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.2430 - accuracy: 0.9109 - val_loss: 1.0943 - val_accuracy: 0.4444\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.1708 - accuracy: 0.9362 - val_loss: 1.3069 - val_accuracy: 0.1786\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1360 - accuracy: 0.9480 - val_loss: 1.9421 - val_accuracy: 0.1786\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.1474 - accuracy: 0.9485 - val_loss: 2.2975 - val_accuracy: 0.2659\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 4s 55ms/step - loss: 0.1400 - accuracy: 0.9461 - val_loss: 0.5005 - val_accuracy: 0.8095\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0941 - accuracy: 0.9713 - val_loss: 1.5266 - val_accuracy: 0.6587\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 4s 53ms/step - loss: 0.0874 - accuracy: 0.9703 - val_loss: 0.1272 - val_accuracy: 0.9643\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 5s 72ms/step - loss: 0.0694 - accuracy: 0.9762 - val_loss: 0.3446 - val_accuracy: 0.9127\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 5s 69ms/step - loss: 0.0665 - accuracy: 0.9777 - val_loss: 0.4391 - val_accuracy: 0.9167\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 4s 64ms/step - loss: 0.0809 - accuracy: 0.9683 - val_loss: 0.6248 - val_accuracy: 0.8492\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.6931 - val_accuracy: 0.8532\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 4s 64ms/step - loss: 0.0613 - accuracy: 0.9792 - val_loss: 0.2264 - val_accuracy: 0.9127\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 0.0618 - accuracy: 0.9762 - val_loss: 0.5364 - val_accuracy: 0.8730\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 0.0416 - accuracy: 0.9861 - val_loss: 0.1707 - val_accuracy: 0.9603\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.0473 - accuracy: 0.9827 - val_loss: 0.3299 - val_accuracy: 0.9206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">usual-yogurt-74</strong>: <a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/1xmvqy8q\" target=\"_blank\">https://wandb.ai/susbrock/Tiny%20CNN/runs/1xmvqy8q</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221106_190447-1xmvqy8q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "history, model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn",
   "language": "python",
   "name": "tiny_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
