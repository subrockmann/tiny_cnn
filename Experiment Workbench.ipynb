{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "#import deeplake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Confirm that TensorFlow can access GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Start a Tensorboard session\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['WANDB_NOTEBOOK_NAME'] = 'Experiment Workbench'\n",
    "\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "#LOGGING_STEPS = 64\n",
    "LR = 0.0001\n",
    "DROPOUT = 0.2\n",
    "\n",
    "PROJECT = \"Tiny CNN\"\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED) # global seed for tensorflow random parts, like dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Lemon Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 32\n",
    "#img_height = 92\n",
    "#img_width = 92\n",
    "shuffle_seed = 42\n",
    "\n",
    "def get_lemon_quality_dataset(dataset_path, img_width, img_height, batch_size, normalize=True):\n",
    "    \"\"\" Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "    Args: \n",
    "        dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "        normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "    Returns:\n",
    "        (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "    \n",
    "    \"\"\"\n",
    "    if dataset_path.exists():\n",
    "        try:\n",
    "            train_dir = dataset_path.joinpath(\"train\")\n",
    "            val_dir = dataset_path.joinpath( \"val\")\n",
    "            test_dir = dataset_path.joinpath( \"test\")\n",
    "        except:\n",
    "            print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "            raise\n",
    "\n",
    "    print(\"Preparing training dataset...\")        \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "\n",
    "    print(\"Preparing validation dataset...\")    \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    print(\"Preparing test dataset...\")    \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        #batch_size=batch_size)\n",
    "    )\n",
    "    \n",
    "    # Normalize the data to the range [0, 1]\n",
    "    if normalize:\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "        train_ds= train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        val_ds= val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        test_ds= test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print (f\"Class names: {class_names}\")\n",
    "    print(train_ds.element_spec)\n",
    "    print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "dataset_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training dataset...\n",
      "Found 2021 files belonging to 3 classes.\n",
      "Preparing validation dataset...\n",
      "Found 252 files belonging to 3 classes.\n",
      "Preparing test dataset...\n",
      "Found 255 files belonging to 3 classes.\n",
      "Class names: ['bad_quality', 'empty_background', 'good_quality']\n",
      "(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "Normalize: True\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = list(train_ds.as_numpy_iterator())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 96, 96, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
    "    input_shape=(96,96,3),\n",
    "    alpha=0.25,\n",
    "    depth_multiplier=1,\n",
    "    dropout=DROPOUT,\n",
    "    include_top=True,\n",
    "    weights= None, #'imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation='softmax',\n",
    "    #**kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobilenet_0.25_96'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", MODELNAME, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "root_logdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the data flow\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "def train_model():\n",
    "        # solve issue from: https://github.com/wandb/wandb/issues/3536\n",
    "        if len(wandb.patched[\"tensorboard\"]) > 0:\n",
    "                wandb.tensorboard.unpatch()\n",
    "                \n",
    "        # Configure Tensorboard root log directory to read the debugging information\n",
    "        \n",
    "        wandb.tensorboard.patch(root_logdir=root_logdir)\n",
    "        # wandb.tensorboard.patch(root_logdir=\"wandb.run.dir\")\n",
    "        \n",
    "        wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT, \n",
    "                # Track hyperparameters and run metadata\n",
    "                #config={\n",
    "                #\"learning_rate\": LR,\n",
    "                #\"epochs\": EPOCHS,\n",
    "                #},\n",
    "                sync_tensorboard=True\n",
    "                )\n",
    "\n",
    "\n",
    "        config = wandb.config\n",
    "        # Specify the configuration variables\n",
    "        config.batch_size = BATCH_SIZE\n",
    "        config.dropout =DROPOUT\n",
    "        config.learn_rate = LR\n",
    "        #config.decay = 1e-6\n",
    "        #config.momentum = 0.9\n",
    "        config.epochs = EPOCHS\n",
    "        config.classes = classes\n",
    "\n",
    "        # enable Tensorflow Debugging\n",
    "        #tf.debugging.experimental.enable_dump_debug_info(\"./logs/debug\", \n",
    "        #        tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "        model = mobilenet\n",
    "        model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= wandb.run.dir, histogram_freq=10, update_freq=\"epoch\") #, profile_batch=\"10, 20\")\n",
    "        #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= logdir, histogram_freq=1)\n",
    "        wandb_callback = WandbCallback(input_type=\"image\", labels=labels, validation_data = val_ds.as_numpy_iterator())\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=50)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n",
    "\n",
    "        history = model.fit(train_ds,\n",
    "                epochs=EPOCHS, \n",
    "                validation_data=val_ds, \n",
    "                callbacks=[tensorboard_callback,\n",
    "                #wandb_callback, \n",
    "                checkpoint, \n",
    "                early_stopping]\n",
    "        )\n",
    "\n",
    "        wandb.log({\n",
    "                \"loss\": history.history[\"loss\"],\n",
    "                \"accuracy\": history.history[\"accuracy\"],\n",
    "                \"val_loss\": history.history[\"val_loss\"],\n",
    "                \"val_accuracy\": history.history[\"val_accuracy\"],                                \n",
    "        })\n",
    "        \n",
    "        wandb.finish()\n",
    "        return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>i:\\tinyml\\tiny_cnn\\wandb\\run-20221106_213753-3jev37n6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/3jev37n6\" target=\"_blank\">stellar-hill-78</a></strong> to <a href=\"https://wandb.ai/susbrock/Tiny%20CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - 11s 109ms/step - loss: 1.0083 - accuracy: 0.4730 - val_loss: 1.0489 - val_accuracy: 0.3770\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.7682 - accuracy: 0.6358 - val_loss: 1.0363 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 3s 53ms/step - loss: 0.5340 - accuracy: 0.7739 - val_loss: 1.0719 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 4s 63ms/step - loss: 0.3683 - accuracy: 0.8456 - val_loss: 1.0907 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 4s 53ms/step - loss: 0.2779 - accuracy: 0.8926 - val_loss: 1.1689 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.2416 - accuracy: 0.9090 - val_loss: 1.1578 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 0.1832 - accuracy: 0.9253 - val_loss: 1.1428 - val_accuracy: 0.4444\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 5s 71ms/step - loss: 0.1519 - accuracy: 0.9480 - val_loss: 0.8999 - val_accuracy: 0.4921\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 5s 70ms/step - loss: 0.1698 - accuracy: 0.9347 - val_loss: 0.7242 - val_accuracy: 0.6429\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1354 - accuracy: 0.9461 - val_loss: 0.2903 - val_accuracy: 0.8651\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 5s 80ms/step - loss: 0.1106 - accuracy: 0.9574 - val_loss: 0.2029 - val_accuracy: 0.9087\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 0.1136 - accuracy: 0.9579 - val_loss: 0.1848 - val_accuracy: 0.9444\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0696 - accuracy: 0.9738 - val_loss: 0.3290 - val_accuracy: 0.8849\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1065 - accuracy: 0.9619 - val_loss: 0.1431 - val_accuracy: 0.9444\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 4s 69ms/step - loss: 0.1218 - accuracy: 0.9545 - val_loss: 0.4044 - val_accuracy: 0.8810\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.0723 - accuracy: 0.9728 - val_loss: 0.1491 - val_accuracy: 0.9405\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 4s 62ms/step - loss: 0.0823 - accuracy: 0.9748 - val_loss: 1.3222 - val_accuracy: 0.7421\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.0714 - accuracy: 0.9738 - val_loss: 0.5114 - val_accuracy: 0.8452\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.1544 - val_accuracy: 0.9484\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 4s 69ms/step - loss: 0.0498 - accuracy: 0.9807 - val_loss: 0.2025 - val_accuracy: 0.9325\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 5s 83ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.0888 - val_accuracy: 0.9683\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 0.1203 - val_accuracy: 0.9683\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0364 - accuracy: 0.9876 - val_loss: 0.3235 - val_accuracy: 0.8929\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.7057 - val_accuracy: 0.8452\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 4s 62ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.1560 - val_accuracy: 0.9444\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 4s 62ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.3463 - val_accuracy: 0.9048\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0770 - accuracy: 0.9733 - val_loss: 0.1876 - val_accuracy: 0.9286\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 4s 62ms/step - loss: 0.0501 - accuracy: 0.9807 - val_loss: 0.0724 - val_accuracy: 0.9643\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 3s 53ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.0409 - val_accuracy: 0.9802\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 5s 71ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.1464 - val_accuracy: 0.9563\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 6s 95ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.1634 - val_accuracy: 0.9484\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.3776 - val_accuracy: 0.8810\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.0418 - accuracy: 0.9852 - val_loss: 0.1546 - val_accuracy: 0.9524\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 5s 70ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.2776 - val_accuracy: 0.9325\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.1215 - val_accuracy: 0.9524\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 5s 70ms/step - loss: 0.0785 - accuracy: 0.9703 - val_loss: 0.5288 - val_accuracy: 0.8810\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.1584 - val_accuracy: 0.9524\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 5s 71ms/step - loss: 0.0816 - accuracy: 0.9723 - val_loss: 0.5285 - val_accuracy: 0.9008\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.1800 - val_accuracy: 0.9444\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 3s 48ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9762\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 0.0216 - accuracy: 0.9906 - val_loss: 0.1067 - val_accuracy: 0.9444\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0933 - val_accuracy: 0.9563\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0375 - val_accuracy: 0.9802\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.1158 - val_accuracy: 0.9563\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1530 - accuracy: 0.9510 - val_loss: 1.0162 - val_accuracy: 0.8373\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.0992 - val_accuracy: 0.9683\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 4s 54ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0911 - val_accuracy: 0.9643\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 3s 52ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.2057 - val_accuracy: 0.9524\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.0740 - val_accuracy: 0.9762\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 5s 70ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.1127 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stellar-hill-78</strong>: <a href=\"https://wandb.ai/susbrock/Tiny%20CNN/runs/3jev37n6\" target=\"_blank\">https://wandb.ai/susbrock/Tiny%20CNN/runs/3jev37n6</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221106_213753-3jev37n6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "history, model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn",
   "language": "python",
   "name": "tiny_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
