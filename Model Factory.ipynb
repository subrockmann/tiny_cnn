{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime, csv\n",
    "import psutil\n",
    "\n",
    "# import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Add,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Reshape,\n",
    "    Activation,\n",
    "    DepthwiseConv2D,\n",
    "    MaxPooling2D,\n",
    "    AvgPool2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Softmax,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Permute,\n",
    "    ReLU\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "from tf2cv.model_provider import get_model as tf2cv_get_model\n",
    "\n",
    "# Import the necessary MLTK APIs\n",
    "from mltk.core import view_model, summarize_model, profile_model\n",
    "\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths, get_file_size, create_model_name, append_dict_to_csv\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# import deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_1 = 1\n",
    "seed_2 = 15\n",
    "seed_3 = 30\n",
    "seed_4 = 42\n",
    "seed_5 = 75\n",
    "\n",
    "seed = seed_1\n",
    "\n",
    "# set the random seeds\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"]= \"1\"\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.random.set_seed(seed) # setting tensorflow global seed\n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "img_res = 224\n",
    "channels = 3\n",
    "classes = 3\n",
    "alpha = 1\n",
    "global dropout_rate\n",
    "dropout_rate = 0.2\n",
    "architecture = \"shufflenet_v2tiny\" #\"mobilenet_v2_keras\" ##\"mobilenet_v3_large_keras\" # \"mobilenet_v3_small_keras\" #\"efficientNetB0_keras\" #\"mobilenet_v2_keras\" #\n",
    "loop_depth = 5\n",
    "groups = 1 # [1, 2, 3, 4, 8] used in shuffleNetv1\n",
    "first_layer_channels = 4 # standard 24\n",
    "last_layer_channels = 1024 # standard 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_res,img_res,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {\"img_res\" : img_res,\n",
    "    \"classes\" : classes,\n",
    "    \"channels\" : channels,\n",
    "    \"alpha\" : alpha,\n",
    "    \"dropout_rate\" : dropout_rate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v1(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V1 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "    global dropout_rate\n",
    "    \n",
    "    # MobileNet V1 Block\n",
    "    def mobilenet_v1_block(x, filters, strides):\n",
    "        # Depthwise convolution\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        # Pointwise convolution = standard convolution with kernel size =1\n",
    "        x = Conv2D(filters=filters, kernel_size=1, strides=1)(x)  # strides for pointwise convolution must be 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=32 * alpha, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "    # Main part of the model\n",
    "    x = mobilenet_v1_block(x, filters=64 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=512 * alpha, strides=2)\n",
    "\n",
    "    for _ in range(loop_depth):  # TODO: reduce the depth of the net for faster inference\n",
    "        x = mobilenet_v1_block(x, filters=512 * alpha, strides=1)\n",
    "\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=1)\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x) #\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "        x = Reshape(target_shape=(classes,))(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=x.shape[-1], strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetv1\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formular to avoid exccessive downsampling\n",
    "# copied from: https://github.com/keras-team/keras/blob/v2.11.0/keras/applications/mobilenet_v2.py#L563\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "\n",
    "def mobilenet_v2(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V2 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "\n",
    "    global block_id\n",
    "    block_id = 1\n",
    "    global dropout_rate\n",
    "\n",
    "    # Expansion block\n",
    "    def expansion_block(x, t, filters, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = Conv2D(kernel_size=1, filters = filters * t, use_bias=False, name= prefix + \"expand\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"expand_bn\")(x)\n",
    "        x = ReLU(6, name=prefix + \"expand_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    def depthwise_block(x, strides, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\", use_bias=False, name= prefix + \"dw_conv\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"dw_bn\")(x)\n",
    "        x = ReLU(6, name=prefix + \"dw_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    def projection_block(x, out_channels, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = Conv2D(filters=out_channels, kernel_size=1, strides=1, padding=\"same\", use_bias=False, name= prefix + \"compress\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"compress_bn\")(x)\n",
    "        return x\n",
    "\n",
    "    def bottleneck_residual_block(x, t, filters, out_channels, strides):\n",
    "        global block_id\n",
    "        block_id =  block_id +1\n",
    "        y = expansion_block(x, t, filters, block_id)\n",
    "        y = depthwise_block(y, strides, block_id)\n",
    "        y = projection_block(y, out_channels, block_id)\n",
    "\n",
    "        # TODO: Check if this implementation is ok\n",
    "        if y.shape[-1] == x.shape[-1]:\n",
    "            y = Add()([x, y])\n",
    "        return y\n",
    "\n",
    "    # Avoid massive downsampling\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=first_block_filters, kernel_size=3, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = BatchNormalization(name='conv1_bn')(x)\n",
    "    x = ReLU(6, name = 'conv1_relu')(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "\n",
    "    # Main part of the model\n",
    "    block_id = 0\n",
    "    x = depthwise_block(x, strides=1, block_id=block_id)\n",
    "    x = projection_block(x, out_channels=16 * alpha, block_id=block_id)\n",
    "\n",
    "    # 2 identical layers\n",
    "    x  = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=24 * alpha, strides=2) #, block_id=block_id +1)\n",
    "    x  = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=24 * alpha, strides=1) #, block_id=block_id +1)\n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 4 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=320 * alpha, strides=1) #, block_id=block_id +1) \n",
    "\n",
    "\n",
    "    # no alpha applied to last conv as stated in the paper:\n",
    "    # if the width multiplier is greater than 1 we increase the number of output\n",
    "    # channels.\n",
    "    if alpha > 1.0:\n",
    "        last_block_filters = _make_divisible(1280 * alpha, 8)\n",
    "    else:\n",
    "        last_block_filters = 1280\n",
    "\n",
    "    # 1*1 conv\n",
    "    x = Conv2D(filters=last_block_filters, kernel_size=1, padding=\"same\", use_bias=False, name=\"last_conv\")(x)\n",
    "    x = BatchNormalization(name='last_bn')(x)\n",
    "    x = ReLU(6,name='last_relu')(x)\n",
    "\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "        x = Reshape(target_shape=(classes,))(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "        #outputs = Softmax()(x)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=7, strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  # TODO: is there a stride=1 implementation in Dense?\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetv2\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # form https://github.com/keras-team/keras/blob/v2.11.0/keras/applications/mobilenet_v2.py#L96-L485\n",
    "# def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n",
    "#     \"\"\"Inverted ResNet block.\"\"\"\n",
    "#     channel_axis = 1 if backend.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "#     in_channels = backend.int_shape(inputs)[channel_axis]\n",
    "#     pointwise_conv_filters = int(filters * alpha)\n",
    "#     # Ensure the number of filters on the last 1x1 convolution is divisible by\n",
    "#     # 8.\n",
    "#     pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "#     x = inputs\n",
    "#     prefix = f\"block_{block_id}_\"\n",
    "\n",
    "#     if block_id:\n",
    "#         # Expand with a pointwise 1x1 convolution.\n",
    "#         x = layers.Conv2D(\n",
    "#             expansion * in_channels,\n",
    "#             kernel_size=1,\n",
    "#             padding=\"same\",\n",
    "#             use_bias=False,\n",
    "#             activation=None,\n",
    "#             name=prefix + \"expand\",\n",
    "#         )(x)\n",
    "#         x = layers.BatchNormalization(\n",
    "#             axis=channel_axis,\n",
    "#             epsilon=1e-3,\n",
    "#             momentum=0.999,\n",
    "#             name=prefix + \"expand_BN\",\n",
    "#         )(x)\n",
    "#         x = layers.ReLU(6.0, name=prefix + \"expand_relu\")(x)\n",
    "#     else:\n",
    "#         prefix = \"expanded_conv_\"\n",
    "\n",
    "#     # Depthwise 3x3 convolution.\n",
    "#     if stride == 2:\n",
    "#         x = layers.ZeroPadding2D(\n",
    "#             padding=imagenet_utils.correct_pad(x, 3), name=prefix + \"pad\"\n",
    "#         )(x)\n",
    "#     x = layers.DepthwiseConv2D(\n",
    "#         kernel_size=3,\n",
    "#         strides=stride,\n",
    "#         activation=None,\n",
    "#         use_bias=False,\n",
    "#         padding=\"same\" if stride == 1 else \"valid\",\n",
    "#         name=prefix + \"depthwise\",\n",
    "#     )(x)\n",
    "#     x = layers.BatchNormalization(\n",
    "#         axis=channel_axis,\n",
    "#         epsilon=1e-3,\n",
    "#         momentum=0.999,\n",
    "#         name=prefix + \"depthwise_BN\",\n",
    "#     )(x)\n",
    "\n",
    "#     x = layers.ReLU(6.0, name=prefix + \"depthwise_relu\")(x)\n",
    "\n",
    "#     # Project with a pointwise 1x1 convolution.\n",
    "#     x = layers.Conv2D(\n",
    "#         pointwise_filters,\n",
    "#         kernel_size=1,\n",
    "#         padding=\"same\",\n",
    "#         use_bias=False,\n",
    "#         activation=None,\n",
    "#         name=prefix + \"project\",\n",
    "#     )(x)\n",
    "#     x = layers.BatchNormalization(\n",
    "#         axis=channel_axis,\n",
    "#         epsilon=1e-3,\n",
    "#         momentum=0.999,\n",
    "#         name=prefix + \"project_BN\",\n",
    "#     )(x)\n",
    "\n",
    "#     if in_channels == pointwise_filters and stride == 1:\n",
    "#         return layers.Add(name=prefix + \"add\")([inputs, x])\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    global dropout_rate\n",
    "    model = tf.keras.applications.mobilenet.MobileNet(\n",
    "        input_shape=input_shape,\n",
    "        alpha=alpha,\n",
    "        depth_multiplier=1,\n",
    "        dropout=dropout_rate,\n",
    "        include_top=True,\n",
    "        weights=None, #'imagenet'\n",
    "        input_tensor=None,\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation='softmax',\n",
    "        #**kwargs\n",
    "    )\n",
    "\n",
    "    #model._name = model.name + \"_keras\" # model.name cannot be overritten\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v2_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        alpha=alpha,\n",
    "        include_top=True,\n",
    "        weights=None, #'imagenet'\n",
    "        input_tensor=None,\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation='softmax',\n",
    "        #**kwargs\n",
    "    )\n",
    "\n",
    "    #model._name = model.name + \"_keras\" # model.name cannot be overritten\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v3_small_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    global dropout_rate\n",
    "    model = tf.keras.applications.MobileNetV3Small(\n",
    "        input_shape=input_shape,\n",
    "        minimalistic=False, # TODO find out about this parameter\n",
    "        alpha=alpha,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        input_tensor=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "        dropout_rate=dropout_rate,\n",
    "        include_preprocessing=False\n",
    "        #**kwargs\n",
    "        )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v3_large_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    global dropout_rate\n",
    "    model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=input_shape,\n",
    "        minimalistic=False, # TODO find out about this parameter\n",
    "        alpha=alpha,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        input_tensor=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "        dropout_rate=dropout_rate,\n",
    "        include_preprocessing=False\n",
    "        #**kwargs\n",
    "        )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientNetB0_keras(input_shape, classes= classes, alpha= alpha):\n",
    "    model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "        include_top=True,\n",
    "        weights= None, #'imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=input_shape,\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation='softmax',\n",
    "        #**kwargs\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shufflenet_v1(input_shape, classes=classes, alpha= alpha, groups = 1):\n",
    "    # inspired by https://github.com/Haikoitoh/paper-implementation/blob/main/ShuffleNet.ipynb\n",
    "\n",
    "    #groups = 2 # [1, 2, 3, 4, 8]\n",
    "\n",
    "    start_channels_dict={\n",
    "        \"1\" : 144,\n",
    "        \"2\" : 200,\n",
    "        \"3\" : 240,\n",
    "        \"4\" : 272,\n",
    "        \"8\" : 384\n",
    "    }\n",
    "\n",
    "    start_channels = start_channels_dict[str(groups)]\n",
    "\n",
    "    def channel_shuffle(x, groups):  \n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        group_ch = channels // groups\n",
    "\n",
    "        x = Reshape([width, height, group_ch, groups])(x)\n",
    "        x = Permute([1, 2, 4, 3])(x)\n",
    "        x = Reshape([width, height, channels])(x)\n",
    "        return x\n",
    "\n",
    "    def shuffle_unit(x, groups, channels, strides):\n",
    "\n",
    "        y = x\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', groups=groups)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = channel_shuffle(x, groups)\n",
    "        \n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = strides, padding = 'same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if strides == (2,2):\n",
    "            channels = channels - y.shape[-1]\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', groups=groups)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if strides ==(1,1):\n",
    "            x =Add()([x,y])\n",
    "        if strides == (2,2):\n",
    "            y = AvgPool2D((3,3), strides = (2,2), padding = 'same')(y)\n",
    "            x = Concatenate(axis=-1)([x,y]) # TODO: check if the axis is correct!\n",
    "        \n",
    "        x = ReLU()(x)\n",
    "        return x\n",
    "\n",
    "    # Main architecture\n",
    "\n",
    "    input = Input (input_shape)\n",
    "\n",
    "    x =  Conv2D (24,kernel_size=3,strides = (2,2), padding = 'same', use_bias = True)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x =  ReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D (pool_size=(3,3), strides = 2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3,7,3]\n",
    "\n",
    "    for i,repetition in enumerate(repetitions):\n",
    "        channels = start_channels * (2**i)\n",
    "\n",
    "        x  = shuffle_unit(x, groups, channels * alpha ,strides = (2,2))\n",
    "\n",
    "        for i in range(repetition):\n",
    "            x = shuffle_unit(x, groups, channels * alpha ,strides=(1,1))\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output = Dense(classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output, name=\"shufflenetv1\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shufflenet_v2(input_shape, classes=classes, alpha=alpha, use_bias=False):\n",
    "    \n",
    "\n",
    "    #groups = 2 # [1, 2, 3, 4, 8]\n",
    "\n",
    "    start_channels_dict={  # based on alpha factor\n",
    "        \"0.5\" : 48,\n",
    "        \"1\" : 116,\n",
    "        \"1.5\" : 176,\n",
    "        \"2\" : 244,\n",
    "    }\n",
    "\n",
    "    first_layer_channels = 24\n",
    "    last_layer_channels = 1024\n",
    "\n",
    "    start_channels = start_channels_dict[str(alpha)]\n",
    "\n",
    "    def channel_shuffle(x, groups):  \n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        group_ch = channels // groups\n",
    "\n",
    "        x = Reshape([width, height, group_ch, groups])(x)\n",
    "        x = Permute([1, 2, 4, 3])(x)\n",
    "        x = Reshape([width, height, channels])(x)\n",
    "        return x\n",
    "\n",
    "    def basic_unit(x, channels):\n",
    "\n",
    "        y,z = tf.split(x, num_or_size_splits=2, axis=-1) # channel split \n",
    "        # batch, width, height, channels = x.get_shape().as_list()\n",
    "        # channel_split = channels//2\n",
    "        # y = x[:, :, :, 0:channel_split+1]\n",
    "        # print(y.shape)\n",
    "        # z = x[:, :, :, channel_split:-1]\n",
    "        # print(z.shape)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1) ,padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "        \n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        y = Concatenate(axis=-1)([y,z]) # TODO: check if the axis is correct!\n",
    "        y = channel_shuffle(y, 2)\n",
    "        return y\n",
    "\n",
    "    def down_sampling_unit(x, channels):\n",
    "\n",
    "        y = x\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        \n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        x = Concatenate(axis=-1)([x,y]) # TODO: check if the axis is correct!\n",
    "        x = channel_shuffle(x, 2)\n",
    "        return x\n",
    "\n",
    "    # Main architecture\n",
    "\n",
    "    input = Input (input_shape)\n",
    "\n",
    "    x =  Conv2D (first_layer_channels ,kernel_size=3, strides = (2,2), padding = 'valid', use_bias=use_bias)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x =  ReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D (pool_size=(3,3), strides = 2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3,7,3]\n",
    "\n",
    "    channels = start_channels\n",
    "\n",
    "    for i,repetition in enumerate(repetitions):\n",
    "\n",
    "        x  = down_sampling_unit(x, channels)\n",
    "\n",
    "        for j in range(repetition):\n",
    "            x = basic_unit(x, channels)\n",
    "\n",
    "        channels = channels * 2 # ShuffleNet V1 *(2**1)\n",
    "\n",
    "    x =  Conv2D (last_layer_channels, kernel_size=1,strides = (1,1), padding = 'same', use_bias=use_bias)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output = Dense(classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output, name=\"shufflenetv2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shufflenet_v2tiny(input_shape, classes=classes, alpha=alpha, first_layer_channels=24, last_layer_channels=1024, use_bias=False):\n",
    "    \n",
    "\n",
    "    #groups = 2 # [1, 2, 3, 4, 8]\n",
    "\n",
    "    start_channels_dict={  # based on alpha factor\n",
    "        \"0.05\" : 6,\n",
    "        \"0.1\" : 12,\n",
    "        \"0.2\" : 24,\n",
    "        \"0.25\" : 28,\n",
    "        \"0.3\" : 34,        \n",
    "        \"0.5\" : 48, # this is the smallest original architecture alpha\n",
    "        \"1\" : 116,\n",
    "        \"1.5\" : 176,\n",
    "        \"2\" : 244,\n",
    "    }\n",
    "\n",
    "    # first_layer_channels = 24\n",
    "    # last_layer_channels = 1024\n",
    "\n",
    "    start_channels = start_channels_dict[str(alpha)]\n",
    "\n",
    "    def channel_shuffle(x, groups):  \n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        group_ch = channels // groups\n",
    "\n",
    "        x = Reshape([width, height, group_ch, groups])(x)\n",
    "        x = Permute([1, 2, 4, 3])(x)\n",
    "        x = Reshape([width, height, channels])(x)\n",
    "        return x\n",
    "\n",
    "    def basic_unit(x, channels):\n",
    "\n",
    "        #x,y = tf.split(x, num_or_size_splits=2, axis=-1) # channel split \n",
    "\n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        channel_split = channels//2 \n",
    "        y = x[:, :, :, 0:channel_split]\n",
    "        print(f\"Basic unit y: {y.shape} - channels: {channels}\")\n",
    "        z = x[:, :, :, channel_split-1:-1]\n",
    "        print(f\"Basic unit z: {z.shape} - channels: {channels}\")\n",
    "\n",
    "\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1) ,padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "        \n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        y = Concatenate(axis=-1)([y,z]) # TODO: check if the axis is correct!\n",
    "        y = channel_shuffle(y, 2) # use 2 groups\n",
    "        return y\n",
    "\n",
    "    def down_sampling_unit(x, channels):\n",
    "\n",
    "        y = x\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        \n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        x = Concatenate(axis=-1)([x,y]) # TODO: check if the axis is correct!\n",
    "        x = channel_shuffle(x, 2)\n",
    "        return x\n",
    "\n",
    "    # Main architecture\n",
    "\n",
    "    input = Input (input_shape)\n",
    "\n",
    "    x =  Conv2D (first_layer_channels ,kernel_size=3, strides = (2,2), padding = 'valid', use_bias=use_bias)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x =  ReLU()(x)\n",
    "    \n",
    "    # exclude pooling layer to avoid model collapse\n",
    "    x = MaxPooling2D (pool_size=(3,3), strides = 2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3,7,3]\n",
    "\n",
    "    channels = start_channels\n",
    "\n",
    "    # stage 2\n",
    "    print(\"stage 2\")\n",
    "    x = down_sampling_unit(x, channels)\n",
    "    for i in range(repetitions[0]):\n",
    "        print(f\"rep {i}, channels {channels}\")\n",
    "        x = basic_unit(x, channels)\n",
    "    \n",
    "    # stage 3\n",
    "    print(\"stage 3\")\n",
    "    channels = channels *2\n",
    "    print(\"channels\")\n",
    "\n",
    "    x = down_sampling_unit(x, channels)\n",
    "    for i in range(repetitions[1]):\n",
    "        print(f\"rep {i}, channels {channels}\")\n",
    "        x = basic_unit(x, channels)\n",
    "\n",
    "    # stage 3\n",
    "    channels = channels *2\n",
    "\n",
    "    x = down_sampling_unit(x, channels)\n",
    "    for i in range(repetitions[2]):\n",
    "        x = basic_unit(x, channels)\n",
    "       \n",
    "\n",
    "    # for i,repetition in enumerate(repetitions):\n",
    "\n",
    "    #     x  = down_sampling_unit(x, channels)\n",
    "\n",
    "    #     for j in range(repetition):\n",
    "    #         x = basic_unit(x, channels)\n",
    "\n",
    "    #     channels = channels * 2 # ShuffleNet V1 *(2**1)\n",
    "\n",
    "    x =  Conv2D (last_layer_channels, kernel_size=1,strides = (1,1), padding = 'same', use_bias=use_bias)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output = Dense(classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output, name=\"shufflenetv2tiny\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = net = tf2cv_get_model(\"resnet18\", pretrained=True, data_format=\"channels_last\")\n",
    "#model.build(input_shape)\n",
    "#model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = shufflenet_v2(input_shape, classes=classes, alpha= alpha)\n",
    "# model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = mobilenet_v1(input_shape, classes=classes, alpha=alpha)\n",
    "#model = mobilenet_v2(input_shape, classes=classes, alpha=alpha)\n",
    "#model = mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha)\n",
    "#model = mobilenet_v2_keras(input_shape, classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(architecture, input_shape, classes, alpha, loop_depth= None,first_layer_channels=None, last_layer_channels=None, use_bias=False):\n",
    "    global base_model_name\n",
    "    if architecture==\"mobilenet_v1\":\n",
    "        if loop_depth==None:\n",
    "            model = mobilenet_v1(input_shape, classes=classes, alpha=alpha)\n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = mobilenet_v1(input_shape, classes=classes, alpha=alpha, loop_depth=loop_depth)\n",
    "            variation_code =\"l\"+str(loop_depth)\n",
    "        base_model_name = model.name\n",
    "    elif architecture==\"mobilenet_v1_keras\":\n",
    "        model = mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]+\"v1\"\n",
    "    elif architecture==\"mobilenet_v2\":\n",
    "        if loop_depth==None:\n",
    "            model = mobilenet_v2(input_shape, classes=classes, alpha=alpha)\n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = mobilenet_v2(input_shape, classes=classes, alpha=alpha, loop_depth=loop_depth)\n",
    "            variation_code =\"l\"+str(loop_depth)\n",
    "        base_model_name = model.name\n",
    "    elif architecture==\"mobilenet_v2_keras\":\n",
    "        model = mobilenet_v2_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]#+\"v2\"\n",
    "    elif architecture== \"mobilenet_v3_small_keras\":\n",
    "        model = mobilenet_v3_small_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]\n",
    "    elif architecture== \"mobilenet_v3_large_keras\":\n",
    "        model = mobilenet_v3_large_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]\n",
    "    elif architecture==\"efficientNetB0_keras\":\n",
    "        model = efficientNetB0_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = \"efficientNetB0\"\n",
    "    elif architecture==\"shufflenet_v1\":\n",
    "        model = shufflenet_v1(input_shape, classes=classes, alpha= alpha, groups=groups)\n",
    "        variation_code =\"g\"+str(groups)\n",
    "        base_model_name = model.name\n",
    "    elif architecture==\"shufflenet_v2\":\n",
    "        model = shufflenet_v2(input_shape, classes=classes, alpha= alpha)\n",
    "        variation_code =\"000\"\n",
    "        base_model_name = model.name\n",
    "\n",
    "    elif architecture==\"shufflenet_v2tiny\":\n",
    "        if (first_layer_channels==None) |(last_layer_channels==None) :\n",
    "            model = shufflenet_v2tiny(input_shape, classes, alpha, first_layer_channels=24, last_layer_channels=1024, use_bias=False) \n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = shufflenet_v2tiny(input_shape, classes, alpha, first_layer_channels=first_layer_channels, last_layer_channels=last_layer_channels, use_bias=False) \n",
    "            variation_code = \"f\"+str(first_layer_channels)+\"l\"+str(last_layer_channels)\n",
    "        base_model_name = model.name\n",
    "    else:\n",
    "        #raise Exception e:\n",
    "        print(f\"Model architecture {architecture} is not supported.\")\n",
    "\n",
    "    return model, variation_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 2\n",
      "rep 0, channels 116\n",
      "Basic unit y: (None, 28, 28, 116) - channels: 232\n",
      "Basic unit z: (None, 28, 28, 116) - channels: 232\n",
      "rep 1, channels 116\n",
      "Basic unit y: (None, 28, 28, 174) - channels: 348\n",
      "Basic unit z: (None, 28, 28, 174) - channels: 348\n",
      "rep 2, channels 116\n",
      "Basic unit y: (None, 28, 28, 261) - channels: 522\n",
      "Basic unit z: (None, 28, 28, 261) - channels: 522\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_227\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [28, 28, 783], output_shape = [28, 28, 391, 2]\n\nCall arguments received by layer \"reshape_227\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 28, 28, 783), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [233], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, variation_code \u001b[39m=\u001b[39m get_model(architecture, input_shape, classes, alpha, loop_depth, first_layer_channels\u001b[39m=\u001b[39;49mfirst_layer_channels, last_layer_channels\u001b[39m=\u001b[39;49mlast_layer_channels)\n",
      "Cell \u001b[1;32mIn [232], line 53\u001b[0m, in \u001b[0;36mget_model\u001b[1;34m(architecture, input_shape, classes, alpha, loop_depth, first_layer_channels, last_layer_channels, use_bias)\u001b[0m\n\u001b[0;32m     51\u001b[0m     variation_code \u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m000\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     model \u001b[39m=\u001b[39m shufflenet_v2tiny(input_shape, classes, alpha, first_layer_channels\u001b[39m=\u001b[39;49mfirst_layer_channels, last_layer_channels\u001b[39m=\u001b[39;49mlast_layer_channels, use_bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \n\u001b[0;32m     54\u001b[0m     variation_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(first_layer_channels)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ml\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(last_layer_channels)\n\u001b[0;32m     55\u001b[0m base_model_name \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mname\n",
      "Cell \u001b[1;32mIn [228], line 105\u001b[0m, in \u001b[0;36mshufflenet_v2tiny\u001b[1;34m(input_shape, classes, alpha, first_layer_channels, last_layer_channels, use_bias)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repetitions[\u001b[39m0\u001b[39m]):\n\u001b[0;32m    104\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrep \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, channels \u001b[39m\u001b[39m{\u001b[39;00mchannels\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m     x \u001b[39m=\u001b[39m basic_unit(x, channels)\n\u001b[0;32m    107\u001b[0m \u001b[39m# stage 3\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstage 3\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [228], line 57\u001b[0m, in \u001b[0;36mshufflenet_v2tiny.<locals>.basic_unit\u001b[1;34m(x, channels)\u001b[0m\n\u001b[0;32m     54\u001b[0m y \u001b[39m=\u001b[39m ReLU()(y)\n\u001b[0;32m     56\u001b[0m y \u001b[39m=\u001b[39m Concatenate(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)([y,z]) \u001b[39m# TODO: check if the axis is correct!\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m y \u001b[39m=\u001b[39m channel_shuffle(y, \u001b[39m2\u001b[39;49m) \u001b[39m# use 2 groups\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "Cell \u001b[1;32mIn [228], line 27\u001b[0m, in \u001b[0;36mshufflenet_v2tiny.<locals>.channel_shuffle\u001b[1;34m(x, groups)\u001b[0m\n\u001b[0;32m     24\u001b[0m batch, width, height, channels \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mas_list()\n\u001b[0;32m     25\u001b[0m group_ch \u001b[39m=\u001b[39m channels \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m groups\n\u001b[1;32m---> 27\u001b[0m x \u001b[39m=\u001b[39m Reshape([width, height, group_ch, groups])(x)\n\u001b[0;32m     28\u001b[0m x \u001b[39m=\u001b[39m Permute([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m3\u001b[39m])(x)\n\u001b[0;32m     29\u001b[0m x \u001b[39m=\u001b[39m Reshape([width, height, channels])(x)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\tiny_cnn_6\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\tiny_cnn_6\\lib\\site-packages\\keras\\layers\\reshaping\\reshape.py:118\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[1;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[0;32m    116\u001b[0m     output_shape[unknown] \u001b[39m=\u001b[39m original \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m known\n\u001b[0;32m    117\u001b[0m \u001b[39melif\u001b[39;00m original \u001b[39m!=\u001b[39m known:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m output_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_227\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [28, 28, 783], output_shape = [28, 28, 391, 2]\n\nCall arguments received by layer \"reshape_227\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 28, 28, 783), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model, variation_code = get_model(architecture, input_shape, classes, alpha, loop_depth, first_layer_channels=first_layer_channels, last_layer_channels=last_layer_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shufflenetv2'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "#         include_top=True,\n",
    "#         weights= None, #'imagenet',\n",
    "#         input_tensor=None,\n",
    "#         input_shape=input_shape,\n",
    "#         pooling=None,\n",
    "#         classes=classes,\n",
    "#         classifier_activation='softmax',\n",
    "#         #**kwargs\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = efficientNetB0_keras(input_shape, classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mobilenet_v1(input_shape, classes=classes, alpha=alpha, global_average_pooling=False)\n",
    "# variation_code =\"noGAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model name\n",
    "\n",
    "model_name = create_model_name(base_model_name, alpha, input_shape, classes, variation_code)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"model_name\"] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filepath structure\n",
    "(\n",
    "    models_path,\n",
    "    models_summary_path,\n",
    "    models_image_path,\n",
    "    models_layer_df_path,\n",
    "    models_tf_path,\n",
    "    models_tflite_path,\n",
    "    models_tflite_opt_path,\n",
    ") = create_filepaths(model_name)\n",
    "\n",
    "# mobilenet_v1 = keras.models.load_model(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model in local version of Netron.app\n",
    "view_model(model, tflite=True, build=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=models_image_path,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",  # TB for vertical plot, LR for horizontal plot\n",
    "    expand_nested=True,\n",
    "    layer_range=None,\n",
    "    dpi=200,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltk_summary = summarize_model(model)\n",
    "print(mltk_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open(models_summary_path, \"w\", encoding='utf-8') as f:\n",
    "    with redirect_stdout(f):\n",
    "        #model.summary()\n",
    "        print(mltk_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_summary(filepath): \n",
    "    # Parse the MLTK model summary to grab important metrics   \n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines() # list containing lines of file\n",
    "        #columns = [] # To store column names\n",
    "\n",
    "        i = 1\n",
    "        for line in lines:\n",
    "            line = line.strip() # remove leading/trailing white spaces\n",
    "            if line.startswith(\"Total params:\"):\n",
    "                total_params = line.split()[-1]\n",
    "                total_params = int(total_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Trainable params:\"):\n",
    "                trainable_params = line.split()[-1]\n",
    "                trainable_params =  int(trainable_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Non-trainable params:\"):\n",
    "                non_trainable_params = line.split()[-1]\n",
    "                non_trainable_params = int(non_trainable_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Total MACs:\"):\n",
    "                MACs = line.split()[-2] + \" \" + line.split()[-1]\n",
    "                #MACs = (float(MACs))\n",
    "            elif line.startswith(\"Total OPs:\"):\n",
    "                FLOPs = line.split()[-2] + \" \" + line.split()[-1]\n",
    "                #FLOPs = (float(FLOPs))\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    return (total_params, trainable_params, non_trainable_params, MACs, FLOPs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLTK profile model reads the mode from a path - only works for MLTK models! / Model must be trained first\n",
    "\n",
    "#profiling_results = profile_model(model, accelerator='None', build=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, trainable_params, non_trainable_params, MACs, FLOPs = parse_model_summary(models_summary_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MACs: {MACs} - FLOPs {FLOPs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"MACs\"] = MACs\n",
    "model_stats[\"FLOPs\"] = FLOPs\n",
    "model_stats[\"total_params\"] = total_params\n",
    "model_stats[\"trainable_params\"] = trainable_params\n",
    "model_stats[\"non_trainable_params\"] = non_trainable_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(models_tf_path)\n",
    "models_tf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"model_size_kb\"] = get_file_size(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_model = keras.models.load_model(models_tf_path)\n",
    "\n",
    "# Let's check:\n",
    "# np.testing.assert_allclose(\n",
    "#     model.predict(test_input), reconstructed_model.predict(test_input)\n",
    "# )\n",
    "\n",
    "# # The reconstructed model is already compiled and has retained the optimizer\n",
    "# # state, so training can resume:\n",
    "# reconstructed_model.fit(test_input, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(models_path)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "# Save the model.\n",
    "with open(models_tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"tflite_model_size_kb\"] = get_file_size(models_tflite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"time_stamp\"] = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file_name = f\"{base_model_name}_stats.csv\"\n",
    "csv_file_name = f\"model_stats.csv\"\n",
    "csv_path = Path.cwd().joinpath(csv_file_name)\n",
    "append_dict_to_csv(csv_path, model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to W&B\n",
    "wandb.login()\n",
    "\n",
    "# Initialize a W&B run\n",
    "run = wandb.init(project=f'{base_model_name}') #, group='alpha variations')\n",
    "\n",
    "config = wandb.config\n",
    "config.update(model_stats)\n",
    "#wandb.log({'augmented data': augment_table})\n",
    "\n",
    "# Finish the run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on TFLite Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the TFLite interpreter\n",
    "# interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# # Allocate the tensors\n",
    "# interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get input/output layer information\n",
    "# i_details = interpreter.get_input_details()[0]\n",
    "# o_details = interpreter.get_output_details()[0]\n",
    "\n",
    "# # Get input quantization parameters.\n",
    "# i_quant = i_details[\"quantization_parameters\"]\n",
    "# try:\n",
    "#     i_scale      = i_quant['scales'][0]\n",
    "# except:\n",
    "#     i_scale = 1\n",
    "\n",
    "# try:\n",
    "#     i_zero_point = i_quant['zero_points'][0]\n",
    "# except:\n",
    "#     i_zero_point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite with Quantization\n",
    "A representative dataset is needed for quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create representative dataset for quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")\n",
    "# dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "# dataset_path.exists()\n",
    "\n",
    "# shuffle_seed = 42\n",
    "\n",
    "\n",
    "# def get_lemon_quality_dataset(\n",
    "#     dataset_path, img_width, img_height, batch_size, normalize=True\n",
    "# ):\n",
    "#     \"\"\"Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "#     Args:\n",
    "#         dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "#         normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "#     Returns:\n",
    "#         (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "\n",
    "#     \"\"\"\n",
    "#     if dataset_path.exists():\n",
    "#         try:\n",
    "#             train_dir = dataset_path.joinpath(\"train\")\n",
    "#             val_dir = dataset_path.joinpath(\"val\")\n",
    "#             test_dir = dataset_path.joinpath(\"test\")\n",
    "#         except:\n",
    "#             print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "#             raise\n",
    "\n",
    "#     print(\"Preparing training dataset...\")\n",
    "#     train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         train_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         # batch_size=1)\n",
    "#     )\n",
    "\n",
    "#     class_names = train_ds.class_names\n",
    "\n",
    "#     print(\"Preparing validation dataset...\")\n",
    "#     val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         val_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         # batch_size=batch_size)\n",
    "#     )\n",
    "\n",
    "#     print(\"Preparing test dataset...\")\n",
    "#     test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         test_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         # batch_size=batch_size)\n",
    "#     )\n",
    "\n",
    "#     # https://github.com/tensorflow/tensorflow/issues/56089\n",
    "\n",
    "#     # # Normalize the data to the range [0, 1]\n",
    "#     # if normalize:\n",
    "#     #     normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "#     #     train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     #     val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     #     test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     # else:\n",
    "#     #     pass\n",
    "\n",
    "#     print(f\"Class names: {class_names}\")\n",
    "#     print(train_ds.element_spec)\n",
    "#     #print(f\"Normalize: {normalize}\")\n",
    "#     return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_WIDTH = input_shape[1]\n",
    "# IMG_HEIGHT = input_shape[0]\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(\n",
    "#     dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale = tf.keras.layers.Rescaling(1.0 / 255, offset=-1)\n",
    "# train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "# train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_ds = train_ds.unbatch()\n",
    "# rep_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def representative_data_gen():\n",
    "#     # for input_value in train_ds.unbatch.batch(1).take(100):\n",
    "#     for input_value, output_value in rep_ds.batch(1).take(100):\n",
    "#         # Model has only one input so each data point has one element.\n",
    "#         print(input_value)\n",
    "#         yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter_INT = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# # Set the optimization flag.\n",
    "# converter_INT.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# # Enforce integer only quantization\n",
    "# converter_INT.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter_INT.inference_input_type = tf.int8\n",
    "# converter_INT.inference_output_type = tf.int8\n",
    "# # Provide a representative dataset to ensure we quantize correctly.\n",
    "# # converter_INT.representative_dataset = representative_dataset(rep_ds)\n",
    "# converter_INT.representative_dataset = representative_data_gen\n",
    "# # converter_INT.representative_dataset = rep_ds\n",
    "# model_tflite_opt = converter_INT.convert()\n",
    "\n",
    "# # Save the model to disk\n",
    "# with open(models_tflite_opt_path, \"wb\") as f:\n",
    "#     f.write(model_tflite_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_stats[\"tflite_INT8_model_size_kb\"] = get_file_size(models_tflite_opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repr_ds = test_ds.unbatch()\n",
    "\n",
    "# # def representative_data_gen():\n",
    "# #   for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "# #     yield [i_value]\n",
    "# converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# #converter_opt = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL)\n",
    "# # converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n",
    "# converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# #converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# #converter_opt.inference_input_type = tf.int8\n",
    "\n",
    "# tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open(models_tflite_opt_path, 'wb') as f:\n",
    "#   f.write(tflite_model_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(models_tflite_opt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the TFLite model to C-byte array with xxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #open(\"model.tflite\", \"wb\").write(tfl_model)\n",
    "# !apt-get update && apt-get -qq install xxd\n",
    "# #!xxd -c 60 -i model.tflite > indoor_scene_recognition.h\n",
    "# !xxd -c 60 -i i:\\\\tinyml\\\\tiny_cnn\\\\models\\\\mobilenet_0.25_96_c3\\\\mobilenet_0.25_96_c3_INT8.tflite' > model_INT.h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model) -> float:\n",
    "    \"\"\"\n",
    "    Calculate FLOPS [GFLOPs] for a tf.keras.Model or tf.keras.Sequential model\n",
    "    in inference mode. It uses tf.compat.v1.profiler under the hood.\n",
    "    \"\"\"\n",
    "    # if not hasattr(model.model, \"model\"):\n",
    "    #     raise wandb.Error(\"self.model must be set before using this method.\")\n",
    "\n",
    "    if not isinstance(\n",
    "        model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Calculating FLOPS is only supported for \"\n",
    "            \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "        )\n",
    "\n",
    "    from tensorflow.python.framework.convert_to_constants import (\n",
    "        convert_variables_to_constants_v2_as_graph,\n",
    "    )\n",
    "\n",
    "    # Compute FLOPs for one sample\n",
    "    batch_size = 1\n",
    "    inputs = [\n",
    "        tf.TensorSpec([batch_size] + inp.shape[1:], inp.dtype)\n",
    "        for inp in model.inputs\n",
    "    ]\n",
    "\n",
    "    # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "    real_model = tf.function(model).get_concrete_function(inputs)\n",
    "    frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "    # Calculate FLOPs with tf.profiler\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = (\n",
    "        tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "        )\n",
    "        .with_empty_output()\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    flops = tf.compat.v1.profiler.profile(\n",
    "        graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "    )\n",
    "\n",
    "    # convert to GFLOPs\n",
    "    return (flops.total_float_ops / 1e9) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import hexdump\n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "# def port(model, optimize=False, variable_name='model_data', pretty_print=False):\n",
    "#     converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "#     if optimize:\n",
    "#         if isinstance(optimize, bool):\n",
    "#             optimizers = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "#         else:\n",
    "#             optimizers = optimize\n",
    "#         converter.optimizations = optimizers\n",
    "#     tflite_model = converter.convert()\n",
    "#     bytes = hexdump.dump(tflite_model).split(' ')\n",
    "#     c_array = ', '.join(['0x%02x' % int(byte, 16) for byte in bytes])\n",
    "#     c = 'const unsigned char %s[] DATA_ALIGN_ATTRIBUTE = {%s};' % (variable_name, c_array)\n",
    "#     if pretty_print:\n",
    "#         c = c.replace('{', '{\\n\\t').replace('}', '\\n}')\n",
    "#         c = re.sub(r'(0x..?, ){12}', lambda x: '%s\\n\\t' % x.group(0), c)\n",
    "#     c += '\\nconst int %s_len = %d;' % (variable_name, len(bytes))\n",
    "#     preamble = '''\n",
    "# // if having troubles with min/max, uncomment the following\n",
    "# // #undef min    \n",
    "# // #undef max\n",
    "# #ifdef __has_attribute\n",
    "# #define HAVE_ATTRIBUTE(x) __has_attribute(x)\n",
    "# #else\n",
    "# #define HAVE_ATTRIBUTE(x) 0\n",
    "# #endif\n",
    "# #if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))\n",
    "# #define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\n",
    "# #else\n",
    "# #define DATA_ALIGN_ATTRIBUTE\n",
    "# #endif\n",
    "# '''\n",
    "#     return preamble + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable_name='model_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def c_code_generator(tflite_model,variable_name=\"model_data\", pretty_print=False):\n",
    "#     \"\"\"Creating c_code from TensorFlow Lite model. \n",
    "#        Code inspired by: https://github.com/eloquentarduino/tinymlgen/blob/master/tinymlgen/tinymlgen.py\n",
    "\n",
    "#     Args:\n",
    "#         tflite_model (_type_): _description_\n",
    "#         variable_name (str, optional): _description_. Defaults to \"model_data\".\n",
    "#         pretty_print (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "#     Returns:\n",
    "#         _type_: _description_\n",
    "#     \"\"\"\n",
    "#     bytes = hexdump.dump(tflite_model).split(' ')\n",
    "#     c_array = ', '.join(['0x%02x' % int(byte, 16) for byte in bytes])\n",
    "#     c = 'const unsigned char %s[] DATA_ALIGN_ATTRIBUTE = {%s};' % (variable_name, c_array)\n",
    "#     if pretty_print:\n",
    "#         c = c.replace('{', '{\\n\\t').replace('}', '\\n}')\n",
    "#         c = re.sub(r'(0x..?, ){12}', lambda x: '%s\\n\\t' % x.group(0), c)\n",
    "#     c += '\\nconst int %s_len = %d;' % (variable_name, len(bytes))\n",
    "#     preamble = '''\n",
    "#     // if having troubles with min/max, uncomment the following\n",
    "#     // #undef min    \n",
    "#     // #undef max\n",
    "#     #ifdef __has_attribute\n",
    "#     #define HAVE_ATTRIBUTE(x) __has_attribute(x)\n",
    "#     #else\n",
    "#     #define HAVE_ATTRIBUTE(x) 0\n",
    "#     #endif\n",
    "#     #if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))\n",
    "#     #define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\n",
    "#     #else\n",
    "#     #define DATA_ALIGN_ATTRIBUTE\n",
    "#     #endif\n",
    "#     '''\n",
    "#     c_code = preamble + c\n",
    "#     return c_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_code = c_code_generator(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faa6c31b20b8f809b81d6d7d22a84ccd9f354666f54133d1793fa4c65539801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
