{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime, csv\n",
    "import psutil\n",
    "\n",
    "# import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# see https://github.com/microsoft/pylance-release/issues/1066\n",
    "#from tensorflow import keras\n",
    "keras = tf.keras\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Add,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Reshape,\n",
    "    Activation,\n",
    "    DepthwiseConv2D,\n",
    "    MaxPooling2D,\n",
    "    AvgPool2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Softmax,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Permute,\n",
    "    ReLU\n",
    ")\n",
    "\n",
    "from keras.models import Model\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "#from tf2cv.model_provider import get_model as tf2cv_get_model\n",
    "\n",
    "# Import the necessary MLTK APIs\n",
    "from mltk.core import view_model, summarize_model, profile_model\n",
    "\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths, get_file_size, create_model_name, append_dict_to_csv\n",
    "from workbench.tensorflow import set_batchnorm_momentum\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# import deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_1 = 1\n",
    "seed_2 = 15\n",
    "seed_3 = 30\n",
    "seed_4 = 42\n",
    "seed_5 = 75\n",
    "\n",
    "seed = seed_1\n",
    "\n",
    "# set the random seeds#\n",
    "#os.environ[\"TF_CUDNN_DETERMINISTIC\"]= \"1\"\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.random.set_seed(seed) # setting tensorflow global seed\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "#tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "img_res = 96\n",
    "channels = 3\n",
    "classes = 3\n",
    "alpha = 0.35\n",
    "global dropout_rate\n",
    "dropout_rate = 0.001 # 0.2\n",
    "architecture = \"mobilenet_v2_keras\" # \"mobilenet_v3_small_keras\" ##\"shufflenet_v2tiny\" # ##\"mobilenet_v3_large_keras\"  #\"efficientNetB0_keras\" #\"mobilenet_v2_keras\" #\n",
    "loop_depth = 5\n",
    "groups = 1 # [1, 2, 3, 4, 8] used in shuffleNetv1\n",
    "first_layer_channels = 4 # standard 24\n",
    "last_layer_channels = 1024 # standard 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_res,img_res,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {\"img_res\" : img_res,\n",
    "    \"classes\" : classes,\n",
    "    \"channels\" : channels,\n",
    "    \"alpha\" : alpha,\n",
    "    \"dropout_rate\" : dropout_rate,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_batchnorm_momentum(model, momentum=0.9):\n",
    "    for layer in model.layers:\n",
    "        if type(layer)==type(tf.keras.layers.BatchNormalization()):\n",
    "            #print(layer.momentum)\n",
    "            layer.momentum=momentum\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet V1 & V2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast downsampling mobilenet https://github.com/qinzheng93/FD-MobileNet/blob/master/pyvision/models/ImageNet/MobileNet.py  \n",
    "\n",
    "Keras Effnet https://github.com/arthurdouillard/keras-effnet/blob/master/effnet.py  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v1(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V1 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "    global dropout_rate\n",
    "    \n",
    "    # MobileNet V1 Block\n",
    "    def mobilenet_v1_block(x, filters, strides):\n",
    "        # Depthwise convolution\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        # Pointwise convolution = standard convolution with kernel size =1\n",
    "        x = Conv2D(filters=filters, kernel_size=1, strides=1)(x)  # strides for pointwise convolution must be 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=32 * alpha, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "    # Main part of the model\n",
    "    x = mobilenet_v1_block(x, filters=64 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=512 * alpha, strides=2)\n",
    "\n",
    "    for _ in range(loop_depth):  # TODO: reduce the depth of the net for faster inference\n",
    "        x = mobilenet_v1_block(x, filters=512 * alpha, strides=1)\n",
    "\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=1)\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x) #\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "        x = Reshape(target_shape=(classes,))(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=x.shape[-1], strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetv1\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MOBILENET V2 not yet correctly implemented!\n",
    "\n",
    "\n",
    "# Formular to avoid exccessive downsampling\n",
    "# copied from: https://github.com/keras-team/keras/blob/v2.11.0/keras/applications/mobilenet_v2.py#L563\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "\n",
    "def mobilenet_v2(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V2 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "\n",
    "    global block_id\n",
    "    block_id = 1\n",
    "    global dropout_rate\n",
    "\n",
    "    # Expansion block\n",
    "    def expansion_block(x, t, filters, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = Conv2D(kernel_size=1, filters = filters * t, use_bias=False, name= prefix + \"expand\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"expand_bn\")(x)\n",
    "        x = ReLU(6, name=prefix + \"expand_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    def depthwise_block(x, strides, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\", use_bias=False, name= prefix + \"dw_conv\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"dw_bn\")(x)\n",
    "        x = ReLU(6, name=prefix + \"dw_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    def projection_block(x, out_channels, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = Conv2D(filters=out_channels, kernel_size=1, strides=1, padding=\"same\", use_bias=False, name= prefix + \"compress\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"compress_bn\")(x)\n",
    "        return x\n",
    "\n",
    "    def bottleneck_residual_block(x, t, filters, out_channels, strides):\n",
    "        global block_id\n",
    "        block_id =  block_id +1\n",
    "        y = expansion_block(x, t, filters, block_id)\n",
    "        y = depthwise_block(y, strides, block_id)\n",
    "        y = projection_block(y, out_channels, block_id)\n",
    "\n",
    "        # TODO: Check if this implementation is ok\n",
    "        if y.shape[-1] == x.shape[-1]:\n",
    "            y = Add()([x, y])\n",
    "        return y\n",
    "\n",
    "    # Avoid massive downsampling\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=first_block_filters, kernel_size=3, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = BatchNormalization(name='conv1_bn')(x)\n",
    "    x = ReLU(6, name = 'conv1_relu')(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "\n",
    "    # Main part of the model\n",
    "    block_id = 0\n",
    "    x = depthwise_block(x, strides=1, block_id=block_id)\n",
    "    x = projection_block(x, out_channels=16 * alpha, block_id=block_id)\n",
    "\n",
    "    # 2 identical layers\n",
    "    x  = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=24 * alpha, strides=2) #, block_id=block_id +1)\n",
    "    x  = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=24 * alpha, strides=1) #, block_id=block_id +1)\n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 4 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=320 * alpha, strides=1) #, block_id=block_id +1) \n",
    "\n",
    "\n",
    "    # no alpha applied to last conv as stated in the paper:\n",
    "    # if the width multiplier is greater than 1 we increase the number of output\n",
    "    # channels.\n",
    "    if alpha > 1.0:\n",
    "        last_block_filters = _make_divisible(1280 * alpha, 8)\n",
    "    else:\n",
    "        last_block_filters = 1280\n",
    "\n",
    "    # 1*1 conv\n",
    "    x = Conv2D(filters=last_block_filters, kernel_size=1, padding=\"same\", use_bias=False, name=\"last_conv\")(x)\n",
    "    x = BatchNormalization(name='last_bn')(x)\n",
    "    x = ReLU(6,name='last_relu')(x)\n",
    "\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "        x = Reshape(target_shape=(classes,))(x)\n",
    "        #outputs = Activation(\"softmax\")(x)\n",
    "        outputs = Softmax()(x)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=7, strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  # TODO: is there a stride=1 implementation in Dense?\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetv2\")\n",
    "\n",
    "    # https://github.com/tensorflow/tensorflow/issues/36065\n",
    "    # model in the original version does not train because momentum is set to 0.999 by default\n",
    "    model = set_batchnorm_momentum(model, momentum=0.9)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MY VERSION OF MOBILENET V2\n",
    "\n",
    "# Formular to avoid exccessive downsampling\n",
    "# copied from: https://github.com/keras-team/keras/blob/v2.11.0/keras/applications/mobilenet_v2.py#L563\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "\n",
    "def mobilenet_vme(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V2 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "\n",
    "    global block_id\n",
    "    block_id = 1\n",
    "    global dropout_rate\n",
    "\n",
    "    # Expansion block\n",
    "    def expansion_block(x, t, filters, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = Conv2D(kernel_size=1, filters = filters * t, use_bias=False, name= prefix + \"expand\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"expand_bn\")(x)\n",
    "        x = ReLU(6, name=prefix + \"expand_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    def depthwise_block(x, strides, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\", use_bias=False, name= prefix + \"dw_conv\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"dw_bn\")(x)\n",
    "        x = ReLU(6, name=prefix + \"dw_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    def projection_block(x, out_channels, block_id):\n",
    "        prefix = f\"block_{block_id}_\"\n",
    "        x = Conv2D(filters=out_channels, kernel_size=1, strides=1, padding=\"same\", use_bias=False, name= prefix + \"compress\")(x)\n",
    "        x = BatchNormalization(name = prefix + \"compress_bn\")(x)\n",
    "        return x\n",
    "\n",
    "    def bottleneck_residual_block(x, t, filters, out_channels, strides):\n",
    "        global block_id\n",
    "        block_id =  block_id +1\n",
    "        y = expansion_block(x, t, filters, block_id)\n",
    "        y = depthwise_block(y, strides, block_id)\n",
    "        y = projection_block(y, out_channels, block_id)\n",
    "\n",
    "        # TODO: Check if this implementation is ok\n",
    "        if y.shape[-1] == x.shape[-1]:\n",
    "            y = Add()([x, y])\n",
    "        return y\n",
    "\n",
    "    # Avoid massive downsampling\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=first_block_filters, kernel_size=3, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = BatchNormalization(name='conv1_bn')(x)\n",
    "    x = ReLU(6, name = 'conv1_relu')(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "\n",
    "    # Main part of the model\n",
    "    block_id = 0\n",
    "    x = depthwise_block(x, strides=1, block_id=block_id)\n",
    "    x = projection_block(x, out_channels=16 * alpha, block_id=block_id)\n",
    "\n",
    "    # 2 identical layers\n",
    "    x  = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=24 * alpha, strides=2) #, block_id=block_id +1)\n",
    "    x  = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=24 * alpha, strides=1) #, block_id=block_id +1)\n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=32 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 4 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=64 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=96 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    # 3 repeated bottle_necks\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=2) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=160 * alpha, strides=1) #, block_id=block_id +1)   \n",
    "\n",
    "    x = bottleneck_residual_block(x, t=6, filters=x.shape[-1], out_channels=320 * alpha, strides=1) #, block_id=block_id +1) \n",
    "\n",
    "\n",
    "    # no alpha applied to last conv as stated in the paper:\n",
    "    # if the width multiplier is greater than 1 we increase the number of output\n",
    "    # channels.\n",
    "    if alpha > 1.0:\n",
    "        last_block_filters = _make_divisible(1280 * alpha, 8)\n",
    "    else:\n",
    "        last_block_filters = 1280\n",
    "\n",
    "    # 1*1 conv\n",
    "    x = Conv2D(filters=last_block_filters, kernel_size=1, padding=\"same\", use_bias=False, name=\"last_conv\")(x)\n",
    "    x = BatchNormalization(name='last_bn')(x)\n",
    "    x = ReLU(6,name='last_relu')(x)\n",
    "\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "        x = Reshape(target_shape=(classes,))(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "        #outputs = Softmax()(x)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=7, strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  # TODO: is there a stride=1 implementation in Dense?\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetvme\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # form https://github.com/keras-team/keras/blob/v2.11.0/keras/applications/mobilenet_v2.py#L96-L485\n",
    "# def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n",
    "#     \"\"\"Inverted ResNet block.\"\"\"\n",
    "#     channel_axis = 1 if backend.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "#     in_channels = backend.int_shape(inputs)[channel_axis]\n",
    "#     pointwise_conv_filters = int(filters * alpha)\n",
    "#     # Ensure the number of filters on the last 1x1 convolution is divisible by\n",
    "#     # 8.\n",
    "#     pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "#     x = inputs\n",
    "#     prefix = f\"block_{block_id}_\"\n",
    "\n",
    "#     if block_id:\n",
    "#         # Expand with a pointwise 1x1 convolution.\n",
    "#         x = layers.Conv2D(\n",
    "#             expansion * in_channels,\n",
    "#             kernel_size=1,\n",
    "#             padding=\"same\",\n",
    "#             use_bias=False,\n",
    "#             activation=None,\n",
    "#             name=prefix + \"expand\",\n",
    "#         )(x)\n",
    "#         x = layers.BatchNormalization(\n",
    "#             axis=channel_axis,\n",
    "#             epsilon=1e-3,\n",
    "#             momentum=0.999,\n",
    "#             name=prefix + \"expand_BN\",\n",
    "#         )(x)\n",
    "#         x = layers.ReLU(6.0, name=prefix + \"expand_relu\")(x)\n",
    "#     else:\n",
    "#         prefix = \"expanded_conv_\"\n",
    "\n",
    "#     # Depthwise 3x3 convolution.\n",
    "#     if stride == 2:\n",
    "#         x = layers.ZeroPadding2D(\n",
    "#             padding=imagenet_utils.correct_pad(x, 3), name=prefix + \"pad\"\n",
    "#         )(x)\n",
    "#     x = layers.DepthwiseConv2D(\n",
    "#         kernel_size=3,\n",
    "#         strides=stride,\n",
    "#         activation=None,\n",
    "#         use_bias=False,\n",
    "#         padding=\"same\" if stride == 1 else \"valid\",\n",
    "#         name=prefix + \"depthwise\",\n",
    "#     )(x)\n",
    "#     x = layers.BatchNormalization(\n",
    "#         axis=channel_axis,\n",
    "#         epsilon=1e-3,\n",
    "#         momentum=0.999,\n",
    "#         name=prefix + \"depthwise_BN\",\n",
    "#     )(x)\n",
    "\n",
    "#     x = layers.ReLU(6.0, name=prefix + \"depthwise_relu\")(x)\n",
    "\n",
    "#     # Project with a pointwise 1x1 convolution.\n",
    "#     x = layers.Conv2D(\n",
    "#         pointwise_filters,\n",
    "#         kernel_size=1,\n",
    "#         padding=\"same\",\n",
    "#         use_bias=False,\n",
    "#         activation=None,\n",
    "#         name=prefix + \"project\",\n",
    "#     )(x)\n",
    "#     x = layers.BatchNormalization(\n",
    "#         axis=channel_axis,\n",
    "#         epsilon=1e-3,\n",
    "#         momentum=0.999,\n",
    "#         name=prefix + \"project_BN\",\n",
    "#     )(x)\n",
    "\n",
    "#     if in_channels == pointwise_filters and stride == 1:\n",
    "#         return layers.Add(name=prefix + \"add\")([inputs, x])\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    global dropout_rate\n",
    "    model = tf.keras.applications.mobilenet.MobileNet(\n",
    "        input_shape=input_shape,\n",
    "        alpha=alpha,\n",
    "        depth_multiplier=1,\n",
    "        dropout=dropout_rate,\n",
    "        include_top=True,\n",
    "        weights=None, #'imagenet'\n",
    "        input_tensor=None,\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation='softmax',\n",
    "        #**kwargs\n",
    "    )\n",
    "\n",
    "    #model._name = model.name + \"_keras\" # model.name cannot be overritten\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v2_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        alpha=alpha,\n",
    "        include_top=True, # False should be corect\n",
    "        weights=None, #'imagenet'\n",
    "        input_tensor=None,\n",
    "        pooling=\"avg\",\n",
    "        classes=classes,\n",
    "        classifier_activation='softmax',\n",
    "        #**kwargs\n",
    "    )\n",
    "\n",
    "    # https://github.com/tensorflow/tensorflow/issues/36065\n",
    "    # model in the original version does not train because momentum is set to 0.999 by default\n",
    "    model = set_batchnorm_momentum(model, momentum=0.9)\n",
    "    \n",
    "    #model._name = model.name + \"_keras\" # model.name cannot be overritten\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v3_small_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    global dropout_rate\n",
    "    model = tf.keras.applications.MobileNetV3Small(\n",
    "        input_shape=input_shape,\n",
    "        minimalistic=False, # TODO find out about this parameter\n",
    "        alpha=alpha,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        input_tensor=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "        dropout_rate=dropout_rate,\n",
    "        include_preprocessing=False\n",
    "        #**kwargs\n",
    "        )\n",
    "    # https://github.com/tensorflow/tensorflow/issues/36065\n",
    "    # model in the original version does not train because momentum is set to 0.999 by default\n",
    "    model = set_batchnorm_momentum(model, momentum=0.9)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v3_large_keras(input_shape, classes=classes, alpha=alpha):\n",
    "    global dropout_rate\n",
    "    model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=input_shape,\n",
    "        minimalistic=False, # TODO find out about this parameter\n",
    "        alpha=alpha,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        input_tensor=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "        dropout_rate=dropout_rate,\n",
    "        include_preprocessing=False\n",
    "        #**kwargs\n",
    "        )\n",
    "\n",
    "    # https://github.com/tensorflow/tensorflow/issues/36065\n",
    "    # model in the original version does not train because momentum is set to 0.999 by default\n",
    "    model = set_batchnorm_momentum(model, momentum=0.9)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientNetB0_keras(input_shape, classes= classes, alpha= alpha):\n",
    "    model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "        include_top=True,\n",
    "        weights= None, #'imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=input_shape,\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation='softmax',\n",
    "        #**kwargs\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shufflenet_v1(input_shape, classes=classes, alpha= alpha, groups = 1):\n",
    "    # inspired by https://github.com/Haikoitoh/paper-implementation/blob/main/ShuffleNet.ipynb\n",
    "\n",
    "    #groups = 2 # [1, 2, 3, 4, 8]\n",
    "\n",
    "    start_channels_dict={\n",
    "        \"1\" : 144,\n",
    "        \"2\" : 200,\n",
    "        \"3\" : 240,\n",
    "        \"4\" : 272,\n",
    "        \"8\" : 384\n",
    "    }\n",
    "\n",
    "    start_channels = start_channels_dict[str(groups)]\n",
    "\n",
    "    def channel_shuffle(x, groups):  \n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        group_ch = channels // groups\n",
    "\n",
    "        x = Reshape([width, height, group_ch, groups])(x)\n",
    "        x = Permute([1, 2, 4, 3])(x)\n",
    "        x = Reshape([width, height, channels])(x)\n",
    "        return x\n",
    "\n",
    "    def shuffle_unit(x, groups, channels, strides):\n",
    "\n",
    "        y = x\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', groups=groups)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = channel_shuffle(x, groups)\n",
    "        \n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = strides, padding = 'same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if strides == (2,2):\n",
    "            channels = channels - y.shape[-1]\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', groups=groups)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if strides ==(1,1):\n",
    "            x =Add()([x,y])\n",
    "        if strides == (2,2):\n",
    "            y = AvgPool2D((3,3), strides = (2,2), padding = 'same')(y)\n",
    "            x = Concatenate(axis=-1)([x,y]) # TODO: check if the axis is correct!\n",
    "        \n",
    "        x = ReLU()(x)\n",
    "        return x\n",
    "\n",
    "    # Main architecture\n",
    "\n",
    "    input = Input (input_shape)\n",
    "\n",
    "    x =  Conv2D (24,kernel_size=3,strides = (2,2), padding = 'same', use_bias = True)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x =  ReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D (pool_size=(3,3), strides = 2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3,7,3]\n",
    "\n",
    "    for i,repetition in enumerate(repetitions):\n",
    "        channels = start_channels * (2**i)\n",
    "\n",
    "        x  = shuffle_unit(x, groups, channels * alpha ,strides = (2,2))\n",
    "\n",
    "        for i in range(repetition):\n",
    "            x = shuffle_unit(x, groups, channels * alpha ,strides=(1,1))\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output = Dense(classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output, name=\"shufflenetv1\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shufflenet_v2(input_shape, classes=classes, alpha=alpha, use_bias=False):\n",
    "    \n",
    "\n",
    "    #groups = 2 # [1, 2, 3, 4, 8]\n",
    "\n",
    "    start_channels_dict={  # based on alpha factor\n",
    "        \"0.5\" : 48,\n",
    "        \"1\" : 116,\n",
    "        \"1.5\" : 176,\n",
    "        \"2\" : 244,\n",
    "    }\n",
    "\n",
    "    first_layer_channels = 24\n",
    "    last_layer_channels = 1024\n",
    "\n",
    "    start_channels = start_channels_dict[str(alpha)]\n",
    "\n",
    "    def channel_shuffle(x, groups):  \n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        group_ch = channels // groups\n",
    "\n",
    "        x = Reshape([width, height, group_ch, groups])(x)\n",
    "        x = Permute([1, 2, 4, 3])(x)\n",
    "        x = Reshape([width, height, channels])(x)\n",
    "        return x\n",
    "\n",
    "    def basic_unit(x, channels):\n",
    "\n",
    "        y,z = tf.split(x, num_or_size_splits=2, axis=-1) # channel split \n",
    "        # batch, width, height, channels = x.get_shape().as_list()\n",
    "        # channel_split = channels//2\n",
    "        # y = x[:, :, :, 0:channel_split+1]\n",
    "        # print(y.shape)\n",
    "        # z = x[:, :, :, channel_split:-1]\n",
    "        # print(z.shape)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1) ,padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "        \n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        y = Concatenate(axis=-1)([y,z]) # TODO: check if the axis is correct!\n",
    "        y = channel_shuffle(y, 2)\n",
    "        return y\n",
    "\n",
    "    def down_sampling_unit(x, channels):\n",
    "\n",
    "        y = x\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        \n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        x = Concatenate(axis=-1)([x,y]) # TODO: check if the axis is correct!\n",
    "        x = channel_shuffle(x, 2)\n",
    "        return x\n",
    "\n",
    "    # Main architecture\n",
    "\n",
    "    input = Input (input_shape)\n",
    "\n",
    "    x =  Conv2D (first_layer_channels ,kernel_size=3, strides = (2,2), padding = 'valid', use_bias=use_bias)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x =  ReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D (pool_size=(3,3), strides = 2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3,7,3]\n",
    "\n",
    "    channels = start_channels\n",
    "\n",
    "    for i,repetition in enumerate(repetitions):\n",
    "\n",
    "        x  = down_sampling_unit(x, channels)\n",
    "\n",
    "        for j in range(repetition):\n",
    "            x = basic_unit(x, channels)\n",
    "\n",
    "        channels = channels * 2 # ShuffleNet V1 *(2**1)\n",
    "\n",
    "    x =  Conv2D (last_layer_channels, kernel_size=1,strides = (1,1), padding = 'same', use_bias=use_bias)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output = Dense(classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output, name=\"shufflenetv2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shufflenet_v2tiny(input_shape, classes=classes, alpha=alpha, first_layer_channels=24, last_layer_channels=1024, use_bias=False):\n",
    "    \n",
    "\n",
    "    #groups = 2 # [1, 2, 3, 4, 8]\n",
    "\n",
    "    start_channels_dict={  # based on alpha factor\n",
    "        \"0.05\" : 6,\n",
    "        \"0.1\" : 12,\n",
    "        \"0.2\" : 24,\n",
    "        \"0.25\" : 28,\n",
    "        \"0.3\" : 34,        \n",
    "        \"0.5\" : 48, # this is the smallest original architecture alpha\n",
    "        \"1\" : 116,\n",
    "        \"1.5\" : 176,\n",
    "        \"2\" : 244,\n",
    "    }\n",
    "\n",
    "    # first_layer_channels = 24\n",
    "    # last_layer_channels = 1024\n",
    "\n",
    "    start_channels = start_channels_dict[str(alpha)]\n",
    "\n",
    "    def channel_shuffle(x, groups):  \n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        group_ch = channels // groups\n",
    "\n",
    "        x = Reshape([width, height, group_ch, groups])(x)\n",
    "        x = Permute([1, 2, 4, 3])(x)\n",
    "        x = Reshape([width, height, channels])(x)\n",
    "        return x\n",
    "\n",
    "    #     x = Reshape([width, height, group_ch, groups])(x)\n",
    "    #     x = Permute([1, 2, 4, 3])(x)\n",
    "    #     x = Reshape([width, height, channels])(x)\n",
    "    #     return x\n",
    "\n",
    "    # https://stackoverflow.com/questions/62794840/apply-channel-shuffle-in-tensorflow-or-keras\n",
    "\n",
    "    # trouble version\n",
    "    # def channel_shuffle(x, groups):\n",
    "    #     # g = 2\n",
    "    #     b, h, w, c = x.shape.as_list()\n",
    "    #     x = tf.reshape(x,[-1, h, w, groups, c // groups])\n",
    "    #     x = tf.transpose(x, perm = [0, 1, 2, 4, 3])\n",
    "    #     #x = tf.reverse(x,[-1]) \n",
    "    #     x = tf.reshape(x, [-1, h, w, c])\n",
    "    #     return x\n",
    "\n",
    "\n",
    "    # https://github.com/MG2033/ShuffleNet/blob/master/layers.py#L238\n",
    "    # def channel_shuffle(name, x, num_groups):\n",
    "    #     with tf.variable_scope(name) as scope:\n",
    "    #         n, h, w, c = x.shape.as_list()\n",
    "    #         x_reshaped = tf.reshape(x, [-1, h, w, num_groups, c // num_groups])\n",
    "    #         x_transposed = tf.transpose(x_reshaped, [0, 1, 2, 4, 3])\n",
    "    #         output = tf.reshape(x_transposed, [-1, h, w, c])\n",
    "    #         return output\n",
    "\n",
    "\n",
    "    ## https://github.com/timctho/shufflenet-v2-tensorflow/blob/master/module.py\n",
    "    def channel_shuffle(x, groups):\n",
    "    #with tf.variable_scope('shuffle_unit'):\n",
    "    \n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, groups, c // groups]))\n",
    "        x = tf.transpose(x, tf.convert_to_tensor([0, 1, 2, 4, 3]))\n",
    "        x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, c]))\n",
    "        return x\n",
    "\n",
    "    def basic_unit(x, channels):\n",
    "\n",
    "        #x,y = tf.split(x, num_or_size_splits=2, axis=-1) # channel split \n",
    "\n",
    "        batch, width, height, channels = x.get_shape().as_list()\n",
    "        channel_split = channels//2 \n",
    "        y = x[:, :, :, 0:channel_split]\n",
    "        print(f\"Basic unit y: {y.shape} - channels: {channels}\")\n",
    "        z = x[:, :, :, channel_split-1:-1]\n",
    "        print(f\"Basic unit z: {z.shape} - channels: {channels}\")\n",
    "\n",
    "\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1) ,padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "        \n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        y = Concatenate(axis=-1)([y,z]) # TODO: check if the axis is correct!\n",
    "        y = channel_shuffle(y, 2) # use 2 groups\n",
    "        return y\n",
    "\n",
    "    def down_sampling_unit(x, channels):\n",
    "\n",
    "        y = x\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        \n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        y = DepthwiseConv2D(kernel_size = (3,3), strides = (2,2), padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Conv2D(channels, kernel_size = 1, strides = (1,1),padding = 'same', use_bias=use_bias)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        x = Concatenate(axis=-1)([x,y]) # TODO: check if the axis is correct!\n",
    "        x = channel_shuffle(x, 2)\n",
    "        return x\n",
    "\n",
    "    # Main architecture\n",
    "\n",
    "    input = Input (input_shape)\n",
    "\n",
    "    x =  Conv2D (first_layer_channels ,kernel_size=3, strides = (2,2), padding = 'valid', use_bias=use_bias)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x =  ReLU()(x)\n",
    "    \n",
    "    # exclude pooling layer to avoid model collapse\n",
    "    x = MaxPooling2D (pool_size=(3,3), strides = 2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3,7,3]\n",
    "\n",
    "    channels = start_channels\n",
    "\n",
    "    # stage 2\n",
    "    print(\"stage 2\")\n",
    "    x = down_sampling_unit(x, channels)\n",
    "    for i in range(repetitions[0]):\n",
    "        print(f\"rep {i}, channels {channels}\")\n",
    "        x = basic_unit(x, channels)\n",
    "    \n",
    "    # stage 3\n",
    "    print(\"stage 3\")\n",
    "    channels = channels *2\n",
    "    print(\"channels\")\n",
    "\n",
    "    x = down_sampling_unit(x, channels)\n",
    "    for i in range(repetitions[1]):\n",
    "        print(f\"rep {i}, channels {channels}\")\n",
    "        x = basic_unit(x, channels)\n",
    "\n",
    "    # stage 3\n",
    "    channels = channels *2\n",
    "\n",
    "    x = down_sampling_unit(x, channels)\n",
    "    for i in range(repetitions[2]):\n",
    "        x = basic_unit(x, channels)\n",
    "       \n",
    "\n",
    "    # for i,repetition in enumerate(repetitions):\n",
    "\n",
    "    #     x  = down_sampling_unit(x, channels)\n",
    "\n",
    "    #     for j in range(repetition):\n",
    "    #         x = basic_unit(x, channels)\n",
    "\n",
    "    #     channels = channels * 2 # ShuffleNet V1 *(2**1)\n",
    "\n",
    "    x =  Conv2D (last_layer_channels, kernel_size=1,strides = (1,1), padding = 'same', use_bias=use_bias)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output = Dense(classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output, name=\"shufflenetv2tiny\")\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = net = tf2cv_get_model(\"resnet18\", pretrained=True, data_format=\"channels_last\")\n",
    "#model.build(input_shape)\n",
    "#model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = shufflenet_v2(input_shape, classes=classes, alpha= alpha)\n",
    "# model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = mobilenet_v1(input_shape, classes=classes, alpha=alpha)\n",
    "#model = mobilenet_v2(input_shape, classes=classes, alpha=alpha)\n",
    "#model = mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha)\n",
    "#model = mobilenet_v2_keras(input_shape, classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(architecture, input_shape, classes, alpha, loop_depth= None,first_layer_channels=None, last_layer_channels=None, use_bias=False):\n",
    "    global base_model_name\n",
    "    if architecture==\"mobilenet_v1\":\n",
    "        if loop_depth==None:\n",
    "            model = mobilenet_v1(input_shape, classes=classes, alpha=alpha)\n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = mobilenet_v1(input_shape, classes=classes, alpha=alpha, loop_depth=loop_depth)\n",
    "            variation_code =\"l\"+str(loop_depth)\n",
    "        base_model_name = model.name\n",
    "    elif architecture==\"mobilenet_v1_keras\":\n",
    "        model = mobilenet_v1_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]+\"v1\"\n",
    "    elif architecture==\"mobilenet_v2\":\n",
    "        if loop_depth==None:\n",
    "            model = mobilenet_v2(input_shape, classes=classes, alpha=alpha)\n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = mobilenet_v2(input_shape, classes=classes, alpha=alpha, loop_depth=loop_depth)\n",
    "            variation_code =\"l\"+str(loop_depth)\n",
    "        base_model_name = model.name\n",
    "\n",
    "    # my personal mobilenet version    \n",
    "    elif architecture==\"mobilenet_vme\":\n",
    "        if loop_depth==None:\n",
    "            model = mobilenet_vme(input_shape, classes=classes, alpha=alpha)\n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = mobilenet_vme(input_shape, classes=classes, alpha=alpha, loop_depth=loop_depth)\n",
    "            variation_code =\"l\"+str(loop_depth)\n",
    "        base_model_name = model.name\n",
    "    elif architecture==\"mobilenet_v2_keras\":\n",
    "        model = mobilenet_v2_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]#+\"v2\"\n",
    "    elif architecture== \"mobilenet_v3_small_keras\":\n",
    "        model = mobilenet_v3_small_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]\n",
    "    elif architecture== \"mobilenet_v3_large_keras\":\n",
    "        model = mobilenet_v3_large_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = model.name.split(\"_\")[0]\n",
    "    elif architecture==\"efficientNetB0_keras\":\n",
    "        model = efficientNetB0_keras(input_shape, classes=classes, alpha=alpha)\n",
    "        variation_code =\"keras\"\n",
    "        base_model_name = \"efficientNetB0\"\n",
    "    elif architecture==\"shufflenet_v1\":\n",
    "        model = shufflenet_v1(input_shape, classes=classes, alpha= alpha, groups=groups)\n",
    "        variation_code =\"g\"+str(groups)\n",
    "        base_model_name = model.name\n",
    "    elif architecture==\"shufflenet_v2\":\n",
    "        model = shufflenet_v2(input_shape, classes=classes, alpha= alpha)\n",
    "        variation_code =\"000\"\n",
    "        base_model_name = model.name\n",
    "\n",
    "    elif architecture==\"shufflenet_v2tiny\":\n",
    "        if (first_layer_channels==None) |(last_layer_channels==None) :\n",
    "            model = shufflenet_v2tiny(input_shape, classes, alpha, first_layer_channels=24, last_layer_channels=1024, use_bias=False) \n",
    "            variation_code =\"000\"\n",
    "        else:\n",
    "            model = shufflenet_v2tiny(input_shape, classes, alpha, first_layer_channels=first_layer_channels, last_layer_channels=last_layer_channels, use_bias=False) \n",
    "            variation_code = \"f\"+str(first_layer_channels)+\"l\"+str(last_layer_channels)\n",
    "        base_model_name = model.name\n",
    "    else:\n",
    "        #raise Exception e:\n",
    "        print(f\"Model architecture {architecture} is not supported.\")\n",
    "\n",
    "    return model, variation_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobilenetv2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, variation_code = get_model(architecture, input_shape, classes, alpha, loop_depth, first_layer_channels=first_layer_channels, last_layer_channels=last_layer_channels)\n",
    "base_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = set_batchnorm_momentum(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n",
      "0.9\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if type(layer)==type(tf.keras.layers.BatchNormalization()):\n",
    "        print(layer.momentum)\n",
    "        print(layer.trainable)\n",
    "        #layer.momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'keras'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "#         include_top=True,\n",
    "#         weights= None, #'imagenet',\n",
    "#         input_tensor=None,\n",
    "#         input_shape=input_shape,\n",
    "#         pooling=None,\n",
    "#         classes=classes,\n",
    "#         classifier_activation='softmax',\n",
    "#         #**kwargs\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = efficientNetB0_keras(input_shape, classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1dfdde8fc40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mobilenet_v1(input_shape, classes=classes, alpha=alpha, global_average_pooling=False)\n",
    "# variation_code =\"noGAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_0.35_96_c3_o3_keras\n"
     ]
    }
   ],
   "source": [
    "# Create the model name\n",
    "\n",
    "model_name = create_model_name(base_model_name, alpha, input_shape, classes, variation_code)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"model_name\"] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\tinyml\\tiny_cnn\\models\n"
     ]
    }
   ],
   "source": [
    "# Create the filepath structure\n",
    "(\n",
    "    models_path,\n",
    "    models_summary_path,\n",
    "    models_image_path,\n",
    "    models_layer_df_path,\n",
    "    models_tf_path,\n",
    "    models_tflite_path,\n",
    "    models_tflite_opt_path,\n",
    ") = create_filepaths(model_name)\n",
    "\n",
    "# mobilenet_v1 = keras.models.load_model(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model in local version of Netron.app\n",
    "#view_model(model, tflite=True, build=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(\n",
    "#     model,\n",
    "#     to_file=models_image_path,\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=False,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir=\"TB\",  # TB for vertical plot, LR for horizontal plot\n",
    "#     expand_nested=True,\n",
    "#     layer_range=None,\n",
    "#     dpi=200,\n",
    "#     show_layer_activations=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_0.35_96\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 48, 48, 16)   432         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 48, 48, 16)   64          ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 48, 48, 16)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 48, 48, 16)  144         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 48, 48, 16)  64          ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 48, 48, 16)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 48, 48, 8)   128         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 48, 48, 8)   32          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 48, 48, 48)   384         ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 48, 48, 48)  192         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 48, 48, 48)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 49, 49, 48)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 24, 24, 48)  432         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 24, 24, 48)  192         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 24, 24, 48)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 24, 24, 8)    384         ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 24, 24, 8)   32          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 24, 24, 48)   384         ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 24, 24, 48)  192         ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 24, 24, 48)   0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 24, 24, 48)  432         ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 24, 24, 48)  192         ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 24, 24, 48)   0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 24, 24, 8)    384         ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 24, 24, 8)   32          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 24, 24, 8)    0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 24, 24, 48)   384         ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 24, 24, 48)  192         ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 24, 24, 48)   0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 25, 25, 48)   0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 12, 12, 48)  432         ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 12, 12, 48)  192         ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 12, 12, 48)   0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 12, 12, 16)   768         ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 12, 12, 16)  64          ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 12, 12, 96)   1536        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 12, 12, 96)  384         ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 12, 12, 96)   0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 12, 12, 96)  864         ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 12, 12, 96)  384         ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 12, 12, 96)   0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 12, 12, 16)   1536        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 12, 12, 16)  64          ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 12, 12, 16)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 12, 12, 96)   1536        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 12, 12, 96)  384         ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 12, 12, 96)   0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 12, 12, 96)  864         ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 12, 12, 96)  384         ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 12, 12, 96)   0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 12, 12, 16)   1536        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 12, 12, 16)  64          ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 12, 12, 16)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 12, 12, 96)   1536        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 12, 12, 96)  384         ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 12, 12, 96)   0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 13, 13, 96)   0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 6, 6, 96)    864         ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 6, 6, 96)    384         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 6, 6, 96)     0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 6, 6, 24)     2304        ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 6, 6, 24)    96          ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 6, 6, 144)    3456        ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 6, 6, 144)   576         ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 6, 6, 144)    0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 6, 6, 144)   1296        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 6, 6, 144)   576         ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 6, 6, 144)    0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 6, 6, 24)     3456        ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 6, 6, 24)    96          ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 6, 6, 24)     0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 6, 6, 144)    3456        ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 6, 6, 144)   576         ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 6, 6, 144)    0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 6, 6, 144)   1296        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 6, 6, 144)   576         ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 6, 6, 144)    0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 6, 6, 24)     3456        ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 6, 6, 24)    96          ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 6, 6, 24)     0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 6, 6, 144)    3456        ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 6, 6, 144)   576         ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 6, 6, 144)    0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 6, 6, 144)   1296        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 6, 6, 144)   576         ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 6, 6, 144)    0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 6, 6, 24)     3456        ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 6, 6, 24)    96          ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 6, 6, 24)     0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 6, 6, 144)    3456        ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 6, 6, 144)   576         ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 6, 6, 144)    0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 6, 6, 144)   1296        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 6, 6, 144)   576         ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 6, 6, 144)   0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 6, 6, 32)     4608        ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 6, 6, 32)    128         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 6, 6, 192)    6144        ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 6, 6, 192)   768         ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 6, 6, 192)    0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 6, 6, 192)   1728        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 6, 6, 192)   768         ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 6, 6, 192)   0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 6, 6, 32)     6144        ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 6, 6, 32)    128         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 6, 6, 32)     0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 6, 6, 192)    6144        ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 6, 6, 192)   768         ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 6, 6, 192)    0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 6, 6, 192)   1728        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 6, 6, 192)   768         ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 6, 6, 192)   0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 6, 6, 32)     6144        ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 6, 6, 32)    128         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 6, 6, 32)     0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 6, 6, 192)    6144        ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 6, 6, 192)   768         ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 6, 6, 192)    0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 7, 7, 192)    0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 3, 3, 192)   1728        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 3, 3, 192)   768         ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 3, 3, 192)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 3, 3, 56)     10752       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 3, 3, 56)    224         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 3, 3, 336)    18816       ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 3, 3, 336)   1344        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 3, 3, 336)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 3, 3, 336)   3024        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 3, 3, 336)   1344        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 3, 3, 336)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 3, 3, 56)     18816       ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 3, 3, 56)    224         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 3, 3, 56)     0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 3, 3, 336)    18816       ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 3, 3, 336)   1344        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 3, 3, 336)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 3, 3, 336)   3024        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 3, 3, 336)   1344        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 3, 3, 336)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 3, 3, 56)     18816       ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 3, 3, 56)    224         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 3, 3, 56)     0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 3, 3, 336)    18816       ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 3, 3, 336)   1344        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 3, 3, 336)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 3, 3, 336)   3024        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 3, 3, 336)   1344        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 3, 3, 336)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 3, 3, 112)    37632       ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 3, 3, 112)   448         ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 3, 3, 1280)   143360      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 3, 3, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 3, 3, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 3)            3843        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 414,051\n",
      "Trainable params: 399,971\n",
      "Non-trainable params: 14,080\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Total MACs: 10.658 M\n",
      "Total OPs: 22.295 M\n"
     ]
    }
   ],
   "source": [
    "mltk_summary = summarize_model(model)\n",
    "print(mltk_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model summary to disk\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open(models_summary_path, \"w\", encoding='utf-8') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print(mltk_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_summary(filepath): \n",
    "    # Parse the MLTK model summary to grab important metrics   \n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines() # list containing lines of file\n",
    "        #columns = [] # To store column names\n",
    "\n",
    "        i = 1\n",
    "        for line in lines:\n",
    "            line = line.strip() # remove leading/trailing white spaces\n",
    "            if line.startswith(\"Total params:\"):\n",
    "                total_params = line.split()[-1]\n",
    "                total_params = int(total_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Trainable params:\"):\n",
    "                trainable_params = line.split()[-1]\n",
    "                trainable_params =  int(trainable_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Non-trainable params:\"):\n",
    "                non_trainable_params = line.split()[-1]\n",
    "                non_trainable_params = int(non_trainable_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Total MACs:\"):\n",
    "                MACs = line.split()[-2] + \" \" + line.split()[-1]\n",
    "                #MACs = (float(MACs))\n",
    "            elif line.startswith(\"Total OPs:\"):\n",
    "                FLOPs = line.split()[-2] + \" \" + line.split()[-1]\n",
    "                #FLOPs = (float(FLOPs))\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    return (total_params, trainable_params, non_trainable_params, MACs, FLOPs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# MLTK profile model reads the mode from a path - only works for MLTK models! / Model must be trained first\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m profiling_results \u001b[39m=\u001b[39m profile_model(model, accelerator\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mNone\u001b[39;49m\u001b[39m'\u001b[39;49m, build\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\tiny_cnn_6\\lib\\site-packages\\mltk\\core\\profile_model.py:61\u001b[0m, in \u001b[0;36mprofile_model\u001b[1;34m(model, image_path, accelerator, baud, port, use_device, build, platform, runtime_buffer_size, test, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m#accelerator = TfliteMicro.normalize_accelerator_name(accelerator)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     tflite_model \u001b[39m=\u001b[39m load_tflite_model(model\u001b[39m=\u001b[39;49mmodel, build\u001b[39m=\u001b[39;49mbuild, test\u001b[39m=\u001b[39;49mtest)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m ArchiveFileNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m     append_exception_msg(e,\n\u001b[0;32m     64\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAlternatively, add the --build option to profile the model without training it first\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\tiny_cnn_6\\lib\\site-packages\\mltk\\core\\model\\model_utils.py:386\u001b[0m, in \u001b[0;36mload_tflite_model\u001b[1;34m(model, build, print_not_found_err, return_tflite_path, test, logger)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[39mreturn\u001b[39;00m tflite_path\n\u001b[0;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39massert\u001b[39;00m tflite_model \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[39mreturn\u001b[39;00m tflite_model\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MLTK profile model reads the mode from a path - only works for MLTK models! / Model must be trained first?\n",
    "# This only works with TFLite Models!\n",
    "\n",
    "#profiling_results = profile_model(model, accelerator='None', build=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, trainable_params, non_trainable_params, MACs, FLOPs = parse_model_summary(models_summary_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 10.658 M - FLOPs 22.295 M\n"
     ]
    }
   ],
   "source": [
    "print(f\"MACs: {MACs} - FLOPs {FLOPs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"MACs\"] = MACs\n",
    "model_stats[\"FLOPs\"] = FLOPs\n",
    "model_stats[\"total_params\"] = total_params\n",
    "model_stats[\"trainable_params\"] = trainable_params\n",
    "model_stats[\"non_trainable_params\"] = non_trainable_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('i:/tinyml/tiny_cnn/models/mobilenetv2_0.35_96_c3_o3_keras/mobilenetv2_0.35_96_c3_o3_keras.h5')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(models_tf_path)\n",
    "models_tf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size in bytes is 2130072\n",
      "File size in kilobytes is 2080.1484375\n"
     ]
    }
   ],
   "source": [
    "model_stats[\"model_size_kb\"] = get_file_size(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_model = keras.models.load_model(models_tf_path)\n",
    "\n",
    "# Let's check:\n",
    "# np.testing.assert_allclose(\n",
    "#     model.predict(test_input), reconstructed_model.predict(test_input)\n",
    "# )\n",
    "\n",
    "# # The reconstructed model is already compiled and has retained the optimizer\n",
    "# # state, so training can resume:\n",
    "# reconstructed_model.fit(test_input, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Susanne\\AppData\\Local\\Temp\\tmpaa8ip3l1\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(models_path)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "# Save the model.\n",
    "with open(models_tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size in bytes is 1588020\n",
      "File size in kilobytes is 1550.80078125\n"
     ]
    }
   ],
   "source": [
    "model_stats[\"tflite_model_size_kb\"] = get_file_size(models_tflite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"time_stamp\"] = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file_name = f\"{base_model_name}_stats.csv\"\n",
    "csv_file_name = f\"model_stats.csv\"\n",
    "csv_path = Path.cwd().joinpath(csv_file_name)\n",
    "append_dict_to_csv(csv_path, model_stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting peak memory info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_peak_memory_path = models_dir.joinpath(model_name, f\"{model_name}_peak_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"i:\\tinyml\\tflite-tools\\tflite_tools.py\", line 49, in <module>\n",
      "    main()\n",
      "  File \"i:\\tinyml\\tflite-tools\\tflite_tools.py\", line 23, in main\n",
      "    model = TFLiteModel.load_from_file(args.input_path)\n",
      "  File \"i:\\tinyml\\tflite-tools\\tflite_tools\\tflite_model.py\", line 118, in load_from_file\n",
      "    with open(model_path, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'i:\\\\tinyml\\\\tiny_cnn\\\\models\\\\mobilenetv2_0.35_96_c3_o3_keras\\\\mobilenetv2_0.35_96_c3_o3_keras_INT8.tflite'\n"
     ]
    }
   ],
   "source": [
    "! python i:\\tinyml\\tflite-tools\\tflite_tools.py -i $models_tflite_opt_path --csv $models_peak_memory_path\n",
    "! explorer $models_peak_memory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#built_model = model.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>i:\\tinyml\\tiny_cnn\\wandb\\run-20230127_163434-qqvb8qzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/mobilenetv2/runs/qqvb8qzc\" target=\"_blank\">fortuitous-dumpling-68</a></strong> to <a href=\"https://wandb.ai/susbrock/mobilenetv2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fortuitous-dumpling-68</strong>: <a href=\"https://wandb.ai/susbrock/mobilenetv2/runs/qqvb8qzc\" target=\"_blank\">https://wandb.ai/susbrock/mobilenetv2/runs/qqvb8qzc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230127_163434-qqvb8qzc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login to W&B\n",
    "wandb.login()\n",
    "\n",
    "# Initialize a W&B run\n",
    "run = wandb.init(project=f'{base_model_name}') #, group='alpha variations')\n",
    "\n",
    "config = wandb.config\n",
    "config.update(model_stats)\n",
    "#wandb.log({'augmented data': augment_table})\n",
    "\n",
    "# Finish the run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on TFLite Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the TFLite interpreter\n",
    "# interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# # Allocate the tensors\n",
    "# interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get input/output layer information\n",
    "# i_details = interpreter.get_input_details()[0]\n",
    "# o_details = interpreter.get_output_details()[0]\n",
    "\n",
    "# # Get input quantization parameters.\n",
    "# i_quant = i_details[\"quantization_parameters\"]\n",
    "# try:\n",
    "#     i_scale      = i_quant['scales'][0]\n",
    "# except:\n",
    "#     i_scale = 1\n",
    "\n",
    "# try:\n",
    "#     i_zero_point = i_quant['zero_points'][0]\n",
    "# except:\n",
    "#     i_zero_point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite with Quantization\n",
    "A representative dataset is needed for quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create representative dataset for quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")\n",
    "# dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "# dataset_path.exists()\n",
    "\n",
    "# shuffle_seed = 42\n",
    "\n",
    "\n",
    "# def get_lemon_quality_dataset(\n",
    "#     dataset_path, img_width, img_height, batch_size, normalize=True\n",
    "# ):\n",
    "#     \"\"\"Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "#     Args:\n",
    "#         dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "#         normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "#     Returns:\n",
    "#         (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "\n",
    "#     \"\"\"\n",
    "#     if dataset_path.exists():\n",
    "#         try:\n",
    "#             train_dir = dataset_path.joinpath(\"train\")\n",
    "#             val_dir = dataset_path.joinpath(\"val\")\n",
    "#             test_dir = dataset_path.joinpath(\"test\")\n",
    "#         except:\n",
    "#             print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "#             raise\n",
    "\n",
    "#     print(\"Preparing training dataset...\")\n",
    "#     train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         train_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         # batch_size=1)\n",
    "#     )\n",
    "\n",
    "#     class_names = train_ds.class_names\n",
    "\n",
    "#     print(\"Preparing validation dataset...\")\n",
    "#     val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         val_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         # batch_size=batch_size)\n",
    "#     )\n",
    "\n",
    "#     print(\"Preparing test dataset...\")\n",
    "#     test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         test_dir,\n",
    "#         subset=None,\n",
    "#         seed=shuffle_seed,\n",
    "#         image_size=(img_height, img_width),\n",
    "#         # batch_size=batch_size)\n",
    "#     )\n",
    "\n",
    "#     # https://github.com/tensorflow/tensorflow/issues/56089\n",
    "\n",
    "#     # # Normalize the data to the range [0, 1]\n",
    "#     # if normalize:\n",
    "#     #     normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "#     #     train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     #     val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     #     test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     # else:\n",
    "#     #     pass\n",
    "\n",
    "#     print(f\"Class names: {class_names}\")\n",
    "#     print(train_ds.element_spec)\n",
    "#     #print(f\"Normalize: {normalize}\")\n",
    "#     return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_WIDTH = input_shape[1]\n",
    "# IMG_HEIGHT = input_shape[0]\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(\n",
    "#     dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale = tf.keras.layers.Rescaling(1.0 / 255, offset=-1)\n",
    "# train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "# train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_ds = train_ds.unbatch()\n",
    "# rep_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def representative_data_gen():\n",
    "#     # for input_value in train_ds.unbatch.batch(1).take(100):\n",
    "#     for input_value, output_value in rep_ds.batch(1).take(100):\n",
    "#         # Model has only one input so each data point has one element.\n",
    "#         print(input_value)\n",
    "#         yield [input_value]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wsl ls ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wsl pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wsl ls ./models -l >model.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wsl ls ./models -laR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linux_path = models_tflite_path.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wsl i:\\tinyml\\tiny_cnn\\benchmarking\\linux_x86-64_benchmark_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wsl ./benchmarking/linux_x86-64_benchmark_model --graph=$models_tflite_path --num_threads=1 --enable_op_profiling=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter_INT = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# # Set the optimization flag.\n",
    "# converter_INT.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# # Enforce integer only quantization\n",
    "# converter_INT.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter_INT.inference_input_type = tf.int8\n",
    "# converter_INT.inference_output_type = tf.int8\n",
    "# # Provide a representative dataset to ensure we quantize correctly.\n",
    "# # converter_INT.representative_dataset = representative_dataset(rep_ds)\n",
    "# converter_INT.representative_dataset = representative_data_gen\n",
    "# # converter_INT.representative_dataset = rep_ds\n",
    "# model_tflite_opt = converter_INT.convert()\n",
    "\n",
    "# # Save the model to disk\n",
    "# with open(models_tflite_opt_path, \"wb\") as f:\n",
    "#     f.write(model_tflite_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_stats[\"tflite_INT8_model_size_kb\"] = get_file_size(models_tflite_opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repr_ds = test_ds.unbatch()\n",
    "\n",
    "# # def representative_data_gen():\n",
    "# #   for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "# #     yield [i_value]\n",
    "# converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# #converter_opt = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL)\n",
    "# # converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n",
    "# converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# #converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# #converter_opt.inference_input_type = tf.int8\n",
    "\n",
    "# tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open(models_tflite_opt_path, 'wb') as f:\n",
    "#   f.write(tflite_model_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(models_tflite_opt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('i:/tinyml/tiny_cnn/models/mobilenetv2_0.35_96_c3_o3_keras/mobilenetv2_0.35_96_c3_o3_keras.h5')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_tf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:30:19) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faa6c31b20b8f809b81d6d7d22a84ccd9f354666f54133d1793fa4c65539801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
