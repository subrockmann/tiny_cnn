{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import psutil\n",
    "\n",
    "# import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Reshape,\n",
    "    DepthwiseConv2D,\n",
    "    MaxPooling2D,\n",
    "    AvgPool2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Softmax,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    ")\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "# Import the necessary MLTK APIs\n",
    "from mltk.core import view_model, summarize_model, profile_model\n",
    "\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths, get_file_size, create_model_name\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# import deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "# input_shape =(128,128,3)\n",
    "\n",
    "classes = 3\n",
    "alpha = 0.5\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {\"input_shape\" : input_shape,\n",
    "    \"classes\" : classes,\n",
    "    \"channels\" : channels,\n",
    "    \"alpha\" : alpha,\n",
    "    \"dropout_rate\" : dropout_rate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v1(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V1 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # MobileNet V1 Block\n",
    "    def mobilenet_v1_block(x, filters, strides):\n",
    "        # Depthwise convolution\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        # Pointwise convolution = standard convolution with kernel size =1\n",
    "        x = Conv2D(filters=filters, kernel_size=1, strides=1)(\n",
    "            x\n",
    "        )  # strides for pointwise convolution must be 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=32 * alpha, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "    # Main part of the model\n",
    "    x = mobilenet_v1_block(x, filters=64 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=512 * alpha, strides=2)\n",
    "\n",
    "    for _ in range(loop_depth):  # TODO: reduce the depth of the net for faster inference\n",
    "        x = mobilenet_v1_block(x, filters=512, strides=1)\n",
    "\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=1)\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1)(x)\n",
    "        x = Reshape((1,classes))(x)\n",
    "        outputs = Softmax()(x)\n",
    "\n",
    "        #outputs = Reshape((classes))(x)\n",
    "        #outputs = Dense(classes, activation=\"softmax\")(x)\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=7, strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  # TODO: is there a stride=1 implementation in Dense?\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetv1\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobilenet_v1(input_shape, classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
    "#     inpmobilenetut_shape=input_shape,\n",
    "#     alpha=alpha,\n",
    "#     depth_multiplier=1,\n",
    "#     dropout=0.001,\n",
    "#     include_top=True,\n",
    "#     weights=None, #'imagenet'\n",
    "#     input_tensor=None,\n",
    "#     pooling=None,\n",
    "#     classes=classes,\n",
    "#     classifier_activation='softmax',\n",
    "#     #**kwargs\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mobilenet\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model in local version of Netron.app\n",
    "view_model(model, tflite=True, build=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model name\n",
    "base_model_name = model.name\n",
    "variation_code = \"000\"  # code for special tweaks on the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = create_model_name(base_model_name, alpha, input_shape, classes, variation_code)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"model_name\"] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filepath structure\n",
    "(\n",
    "    models_path,\n",
    "    models_summary_path,\n",
    "    models_image_path,\n",
    "    models_layer_df_path,\n",
    "    models_tf_path,\n",
    "    models_tflite_path,\n",
    "    models_tflite_opt_path,\n",
    ") = create_filepaths(model_name)\n",
    "\n",
    "# mobilenet_v1 = keras.models.load_model(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=models_image_path,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",  # TB for vertical plot, LR for horizontal plot\n",
    "    expand_nested=True,\n",
    "    layer_range=None,\n",
    "    dpi=200,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltk_summary = summarize_model(model)\n",
    "print(mltk_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open(models_summary_path, \"w\") as f:\n",
    "    with redirect_stdout(f):\n",
    "        #model.summary()\n",
    "        print(mltk_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_summary(filepath): \n",
    "    # Parse the MLTK model summary to grab important metrics   \n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines() # list containing lines of file\n",
    "        #columns = [] # To store column names\n",
    "\n",
    "        i = 1\n",
    "        for line in lines:\n",
    "            line = line.strip() # remove leading/trailing white spaces\n",
    "            if line.startswith(\"Total params:\"):\n",
    "                total_params = line.split()[-1]\n",
    "                total_params = int(total_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Trainable params:\"):\n",
    "                trainable_params = line.split()[-1]\n",
    "                trainable_params =  int(trainable_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Non-trainable params:\"):\n",
    "                non_trainable_params = line.split()[-1]\n",
    "                non_trainable_params = int(non_trainable_params.replace(\",\", \"\"))\n",
    "            elif line.startswith(\"Total MACs:\"):\n",
    "                MMACs = line.split()[-2]\n",
    "                MMACs = (float(MMACs))\n",
    "            elif line.startswith(\"Total OPs:\"):\n",
    "                MFLOPs = line.split()[-2]\n",
    "                MFLOPs = (float(MFLOPs))\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    return (total_params, trainable_params, non_trainable_params, MMACs, MFLOPs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_params, trainable_params, non_trainable_params, MMACs, MFLOPs = parse_model_summary(models_summary_path)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"M_MACs\"] = MMACs\n",
    "model_stats[\"M_FLOPs\"] = MFLOPs\n",
    "model_stats[\"total_params\"] = total_params\n",
    "model_stats[\"trainable_params\"] = trainable_params\n",
    "model_stats[\"non_trainable_params\"] = non_trainable_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(models_tf_path)\n",
    "models_tf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"model_size_kb\"] = get_file_size(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(models_tf_path)\n",
    "\n",
    "# Let's check:\n",
    "# np.testing.assert_allclose(\n",
    "#     model.predict(test_input), reconstructed_model.predict(test_input)\n",
    "# )\n",
    "\n",
    "# # The reconstructed model is already compiled and has retained the optimizer\n",
    "# # state, so training can resume:\n",
    "# reconstructed_model.fit(test_input, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(models_path)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(models_tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"tflite_model_size_kb\"] = get_file_size(models_tflite_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite with Quantization\n",
    "A representative dataset is needed for quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create representative dataset for quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")\n",
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "dataset_path.exists()\n",
    "\n",
    "shuffle_seed = 42\n",
    "\n",
    "\n",
    "def get_lemon_quality_dataset(\n",
    "    dataset_path, img_width, img_height, batch_size, normalize=True\n",
    "):\n",
    "    \"\"\"Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "        normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "    Returns:\n",
    "        (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "\n",
    "    \"\"\"\n",
    "    if dataset_path.exists():\n",
    "        try:\n",
    "            train_dir = dataset_path.joinpath(\"train\")\n",
    "            val_dir = dataset_path.joinpath(\"val\")\n",
    "            test_dir = dataset_path.joinpath(\"test\")\n",
    "        except:\n",
    "            print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "            raise\n",
    "\n",
    "    print(\"Preparing training dataset...\")\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        # batch_size=1)\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    print(\"Preparing validation dataset...\")\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        # batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    print(\"Preparing test dataset...\")\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        # batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    # https://github.com/tensorflow/tensorflow/issues/56089\n",
    "\n",
    "    # # Normalize the data to the range [0, 1]\n",
    "    # if normalize:\n",
    "    #     normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "    #     train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    #     val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    #     test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    # else:\n",
    "    #     pass\n",
    "\n",
    "    print(f\"Class names: {class_names}\")\n",
    "    print(train_ds.element_spec)\n",
    "    #print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = input_shape[1]\n",
    "IMG_HEIGHT = input_shape[0]\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(\n",
    "    dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1.0 / 255, offset=-1)\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_ds = train_ds.unbatch()\n",
    "rep_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    # for input_value in train_ds.unbatch.batch(1).take(100):\n",
    "    for input_value, output_value in rep_ds.batch(1).take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        print(input_value)\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently not needed, just needed for testing\n",
    "# test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     dataset_path,\n",
    "#     interpolation=\"bilinear\",\n",
    "#     image_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "#     # batch_size=1)\n",
    "# )\n",
    "\n",
    "# test_ds = test_ds.map(lambda x, y: (rescale(x), y))\n",
    "# test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_INT = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Set the optimization flag.\n",
    "converter_INT.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter_INT.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter_INT.inference_input_type = tf.int8\n",
    "converter_INT.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "# converter_INT.representative_dataset = representative_dataset(rep_ds)\n",
    "converter_INT.representative_dataset = representative_data_gen\n",
    "# converter_INT.representative_dataset = rep_ds\n",
    "model_tflite_opt = converter_INT.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "with open(models_tflite_opt_path, \"wb\") as f:\n",
    "    f.write(model_tflite_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"tflite_INT8_model_size_kb\"] = get_file_size(models_tflite_opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repr_ds = test_ds.unbatch()\n",
    "\n",
    "# # def representative_data_gen():\n",
    "# #   for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "# #     yield [i_value]\n",
    "# converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# #converter_opt = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL)\n",
    "# # converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n",
    "# converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# #converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# #converter_opt.inference_input_type = tf.int8\n",
    "\n",
    "# tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open(models_tflite_opt_path, 'wb') as f:\n",
    "#   f.write(tflite_model_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(models_tflite_opt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to W&B\n",
    "wandb.login()\n",
    "\n",
    "# Initialize a W&B run\n",
    "run = wandb.init(project=f'{base_model_name}', group='alpha variations')\n",
    "\n",
    "config = wandb.config\n",
    "config.update(model_stats)\n",
    "#wandb.log({'augmented data': augment_table})\n",
    "\n",
    "# Finish the run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the TFLite model to C-byte array with xxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #open(\"model.tflite\", \"wb\").write(tfl_model)\n",
    "# !apt-get update && apt-get -qq install xxd\n",
    "# #!xxd -c 60 -i model.tflite > indoor_scene_recognition.h\n",
    "# !xxd -c 60 -i i:\\\\tinyml\\\\tiny_cnn\\\\models\\\\mobilenet_0.25_96_c3\\\\mobilenet_0.25_96_c3_INT8.tflite' > model_INT.h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tiny_cnn_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5cca28df3cd0ba47059fe6cd9a53ab574e90cbce762dd1f162648074df9bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
