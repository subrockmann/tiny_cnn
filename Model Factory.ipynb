{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import psutil\n",
    "\n",
    "# import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Reshape,\n",
    "    DepthwiseConv2D,\n",
    "    MaxPooling2D,\n",
    "    AvgPool2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Softmax,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    ")\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "# Import the necessary MLTK APIs\n",
    "from mltk.core import view_model, summarize_model, profile_model\n",
    "\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# import deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "# input_shape =(128,128,3)\n",
    "\n",
    "classes = 3\n",
    "alpha = 0.5\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v1(input_shape, classes, alpha=1, loop_depth=5, global_average_pooling=True):\n",
    "    \"\"\"\n",
    "    This function builds a CNN model according to the MobileNet V1 specification, using the functional API.\n",
    "    The function returns the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # MobileNet V1 Block\n",
    "    def mobilenet_v1_block(x, filters, strides):\n",
    "        # Depthwise convolution\n",
    "        x = DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        # Pointwise convolution = standard convolution with kernel size =1\n",
    "        x = Conv2D(filters=filters, kernel_size=1, strides=1)(\n",
    "            x\n",
    "        )  # strides for pointwise convolution must be 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Stem of the model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=32 * alpha, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)  # TODO: option to change to ReLu6 or HardSwish\n",
    "\n",
    "    # Main part of the model\n",
    "    x = mobilenet_v1_block(x, filters=64 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=128 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=256 * alpha, strides=1)\n",
    "    x = mobilenet_v1_block(x, filters=512 * alpha, strides=2)\n",
    "\n",
    "    for _ in range(loop_depth):  # TODO: reduce the depth of the net for faster inference\n",
    "        x = mobilenet_v1_block(x, filters=512, strides=1)\n",
    "\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=2)\n",
    "    x = mobilenet_v1_block(x, filters=1024 * alpha, strides=1)\n",
    "\n",
    "    if global_average_pooling:  \n",
    "        x = GlobalAveragePooling2D(keepdims=True)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(filters=classes, kernel_size=1, strides=1)(x)\n",
    "        x = Reshape((1,classes))(x)\n",
    "        outputs = Softmax()(x)\n",
    "\n",
    "        #outputs = Reshape((classes))(x)\n",
    "        #outputs = Dense(classes, activation=\"softmax\")(x)\n",
    "\n",
    "    else:\n",
    "        # use the original implementation from the paper with average pooling and fully-connected layers\n",
    "        x = AvgPool2D(pool_size=7, strides=1)(x)  # TODO: pool_size is dependent on the input resolution, lower resolutions than 224 might crash the architecture\n",
    "        outputs = Dense(units=classes, activation=\"softmax\")(x)  # TODO: is there a stride=1 implementation in Dense?\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"mobilenetv1\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobilenet_v1(input_shape, classes=classes, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 112, 112, 16)      448       \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 112, 112, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_54 (ReLU)             (None, 112, 112, 16)      0         \n",
      "                                                                 \n",
      " depthwise_conv2d_26 (Depthw  (None, 112, 112, 16)     160       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 112, 112, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_55 (ReLU)             (None, 112, 112, 16)      0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 112, 112, 32)      544       \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 112, 112, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_56 (ReLU)             (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " depthwise_conv2d_27 (Depthw  (None, 56, 56, 32)       320       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 56, 56, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_57 (ReLU)             (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 56, 56, 64)        2112      \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 56, 56, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_58 (ReLU)             (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " depthwise_conv2d_28 (Depthw  (None, 56, 56, 64)       640       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 56, 56, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_59 (ReLU)             (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 56, 56, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 56, 56, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_60 (ReLU)             (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " depthwise_conv2d_29 (Depthw  (None, 28, 28, 64)       640       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 28, 28, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_61 (ReLU)             (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 28, 28, 128)       8320      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_62 (ReLU)             (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_30 (Depthw  (None, 28, 28, 128)      1280      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_63 (ReLU)             (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 28, 28, 128)       16512     \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_64 (ReLU)             (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_31 (Depthw  (None, 14, 14, 128)      1280      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 14, 14, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_65 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 14, 14, 256)       33024     \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 14, 14, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_66 (ReLU)             (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_32 (Depthw  (None, 14, 14, 256)      2560      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 14, 14, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_67 (ReLU)             (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 14, 14, 512)       131584    \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_68 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_33 (Depthw  (None, 14, 14, 512)      5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_69 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_70 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_34 (Depthw  (None, 14, 14, 512)      5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_71 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_72 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_35 (Depthw  (None, 14, 14, 512)      5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_73 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_74 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_36 (Depthw  (None, 14, 14, 512)      5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_75 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_76 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_37 (Depthw  (None, 7, 7, 512)        5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 7, 7, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_77 (ReLU)             (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 7, 7, 512)         262656    \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 7, 7, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_78 (ReLU)             (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " depthwise_conv2d_38 (Depthw  (None, 7, 7, 512)        5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 7, 7, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_79 (ReLU)             (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 7, 7, 512)         262656    \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 7, 7, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_80 (ReLU)             (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1, 1, 512)        0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 1, 1, 3)           1539      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1, 3)              0         \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 1, 3)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,843,907\n",
      "Trainable params: 1,827,843\n",
      "Non-trainable params: 16,064\n",
      "_________________________________________________________________\n",
      "\n",
      "Total MACs: 324.314 M\n",
      "Total OPs: 657.585 M\n"
     ]
    }
   ],
   "source": [
    "mltk_summary = summarize_model(model)\n",
    "print(mltk_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
    "#     inpmobilenetut_shape=input_shape,\n",
    "#     alpha=alpha,\n",
    "#     depth_multiplier=1,\n",
    "#     dropout=0.001,\n",
    "#     include_top=True,\n",
    "#     weights=None, #'imagenet'\n",
    "#     input_tensor=None,\n",
    "#     pooling=None,\n",
    "#     classes=classes,\n",
    "#     classifier_activation='softmax',\n",
    "#     #**kwargs\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mobilenet\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'C:/Users/Susanne/AppData/Local/Temp/Susanne/mltk/tmp_models/model.h5' at http://localhost:8080\n",
      "Stopping http://localhost:8080\n"
     ]
    }
   ],
   "source": [
    "# Show model in local version of Netron.app\n",
    "view_model(model, tflite=True, build=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model name\n",
    "base_model_name = model.name\n",
    "variation_code = \"000\"  # code for special tweaks on the model\n",
    "model_name = f\"{base_model_name}_{alpha}_{input_shape[0]}_c{channels}_o{classes}_{variation_code}\"\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filepath structure\n",
    "(\n",
    "    models_path,\n",
    "    models_summary_path,\n",
    "    models_image_path,\n",
    "    models_layer_df_path,\n",
    "    models_tf_path,\n",
    "    models_tflite_path,\n",
    "    models_tflite_opt_path,\n",
    ") = create_filepaths(model_name)\n",
    "\n",
    "# mobilenet_v1 = keras.models.load_model(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=models_image_path,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",  # TB for vertical plot, LR for horizontal plot\n",
    "    expand_nested=True,\n",
    "    layer_range=None,\n",
    "    dpi=200,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# def  Mymodel(backbone_model, classes):\n",
    "#     backbone = backbone_model\n",
    "#     x = backbone.output\n",
    "#     x = tf.keras.layers.Dense(classes,activation='sigmoid')(x)\n",
    "#     model = Model(inputs=backbone.input, outputs=x)\n",
    "#     return model\n",
    "\n",
    "# input_shape = (224, 224, 3)\n",
    "# model = Mymodel(backbone_model=tf.keras.applications.MobileNet(input_shape=input_shape, include_top=False, pooling='avg'),\n",
    "#                 classes=61)\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open(models_summary_path, \"w\") as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.input.shape , layer.output_shape, layer.outbound_nodes, layer.compute_dtype, layer.count_params() )#layer.get_config())\n",
    "#     if isinstance(layer, keras.layers.InputLayer):\n",
    "#         print(f\"Input Layer: {type(layer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(models_tf_path)\n",
    "models_tf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(models_tf_path)\n",
    "\n",
    "# Let's check:\n",
    "# np.testing.assert_allclose(\n",
    "#     model.predict(test_input), reconstructed_model.predict(test_input)\n",
    "# )\n",
    "\n",
    "# # The reconstructed model is already compiled and has retained the optimizer\n",
    "# # state, so training can resume:\n",
    "# reconstructed_model.fit(test_input, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(models_path)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(models_tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to TFLite with Quantization\n",
    "A representative dataset is needed for quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent.joinpath(\"lemon_dataset\", \"docs\", \"data\")\n",
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "dataset_path.exists()\n",
    "\n",
    "shuffle_seed = 42\n",
    "\n",
    "\n",
    "def get_lemon_quality_dataset(\n",
    "    dataset_path, img_width, img_height, batch_size, normalize=True\n",
    "):\n",
    "    \"\"\"Fetches the lemon quality dataset and prints dataset info. It normalizes the image data to range [0,1] by default.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (Path): the file location of the dataset. Subfolders \"train\", \"test\", and \"val\" are expected.\n",
    "        normalize (boolean): Normalizes the image data to range [0, 1]. Default: True\n",
    "\n",
    "    Returns:\n",
    "        (train_ds, val_ds, test_ds, class_names) (tuple(tf.datasets)): Tensorflow datasets for train, validation and test.\n",
    "\n",
    "    \"\"\"\n",
    "    if dataset_path.exists():\n",
    "        try:\n",
    "            train_dir = dataset_path.joinpath(\"train\")\n",
    "            val_dir = dataset_path.joinpath(\"val\")\n",
    "            test_dir = dataset_path.joinpath(\"test\")\n",
    "        except:\n",
    "            print(f\"Please check the folder structure of {dataset_path}.\")\n",
    "            raise\n",
    "\n",
    "    print(\"Preparing training dataset...\")\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        # batch_size=1)\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    print(\"Preparing validation dataset...\")\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        # batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    print(\"Preparing test dataset...\")\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        subset=None,\n",
    "        seed=shuffle_seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        # batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "    # Normalize the data to the range [0, 1]\n",
    "    if normalize:\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "        train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(f\"Class names: {class_names}\")\n",
    "    print(train_ds.element_spec)\n",
    "    print(f\"Normalize: {normalize}\")\n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = input_shape[1]\n",
    "IMG_HEIGHT = input_shape[0]\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(\n",
    "    dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_ds =list(train_ds.as_numpy_iterator())\n",
    "# rep_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def representative_dataset(rep_ds):\n",
    "#     for i in range(500):\n",
    "#         yield(list(rep_ds[i].reshape(1,1)))\n",
    "# representative_dataset(rep_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "# def representative_dataset():\n",
    "#   for i in range(500):\n",
    "#     yield([x_train[i].reshape(1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_ds = train_ds.unbatch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    # for input_value in train_ds.unbatch.batch(1).take(100):\n",
    "    for input_value, output_value in rep_ds.batch(1).take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        print(input_value)\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    interpolation=\"bilinear\",\n",
    "    image_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    # batch_size=1)\n",
    ")\n",
    "\n",
    "rescale = tf.keras.layers.Rescaling(1.0 / 255, offset=-1)\n",
    "test_ds = test_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repr_ds = test_ds.unbatch()\n",
    "# repr_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "        # for i_value, o_value in test_ds.take(48):\n",
    "        # for i_value, o_value in train_ds.take(48):\n",
    "        # for i_value, o_value in repr_ds.take(48):\n",
    "        yield [i_value]\n",
    "\n",
    "\n",
    "# next(representative_data_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter_INT = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter_INT = tf.lite.TFLiteConverter.from_saved_model(str(models_path))\n",
    "converter_INT = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Set the optimization flag.\n",
    "converter_INT.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter_INT.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter_INT.inference_input_type = tf.int8\n",
    "converter_INT.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "# converter_INT.representative_dataset = representative_dataset(rep_ds)\n",
    "converter_INT.representative_dataset = representative_data_gen\n",
    "# converter_INT.representative_dataset = rep_ds\n",
    "model_tflite_opt = converter_INT.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "with open(models_tflite_opt_path, \"wb\") as f:\n",
    "    f.write(model_tflite_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repr_ds = test_ds.unbatch()\n",
    "\n",
    "# # def representative_data_gen():\n",
    "# #   for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "# #     yield [i_value]\n",
    "# converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# #converter_opt = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL)\n",
    "# # converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n",
    "# converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# #converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# #converter_opt.inference_input_type = tf.int8\n",
    "\n",
    "# tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open(models_tflite_opt_path, 'wb') as f:\n",
    "#   f.write(tflite_model_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tflite_opt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(models_tflite_opt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the TFLite model size in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_tfl_model = len(model_tflite_opt)\n",
    "print(len(model_tflite_opt), \"bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the TFLite model to C-byte array with xxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #open(\"model.tflite\", \"wb\").write(tfl_model)\n",
    "# !apt-get update && apt-get -qq install xxd\n",
    "# #!xxd -c 60 -i model.tflite > indoor_scene_recognition.h\n",
    "# !xxd -c 60 -i i:\\\\tinyml\\\\tiny_cnn\\\\models\\\\mobilenet_0.25_96_c3\\\\mobilenet_0.25_96_c3_INT8.tflite' > model_INT.h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tiny_cnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5618f2993617940a5c26d2b4a732b1ce578923eb12d8dcc67dd41bd2b07dc9c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
