{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking TFLite Models  \n",
    "\n",
    "This notebook requires the native benchmark binary for linux that you can get from this page:  \n",
    " [https://www.tensorflow.org/lite/performance/measurement](https://www.tensorflow.org/lite/performance/measurement)  \n",
    "\n",
    " This binary must be placed into the \"benchmarking folder\".\n",
    "\n",
    " This notebook must be run under LINUX!\n",
    "\n",
    " TensorFlow Lite benchmark tools currently measure and calculate statistics for the following important performance metrics:\n",
    "\n",
    "- Initialization time\n",
    "- Inference time of warmup state\n",
    "- Inference time of steady state\n",
    "- Memory usage during initialization time\n",
    "- Overall memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# import workbench.config.config\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths\n",
    "from workbench.wandb import wandb_model_DB, get_model_DB_run_id_from_architecture, get_architecture_from_model_DB_run_id\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "#import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# enable plotly in VS Studio Code\n",
    "#import plotly.io as pio\n",
    "#pio.renderers.default = \"notebook_connected\"\n",
    "#pio.renderers.default = \"plotly_mimetype+notebook\"\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pandas to show all columns & rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "automated = False\n",
    "\n",
    "global model_name\n",
    "model_name = \"mobilenetv1_0.1_96_c3_o2_l5.MV1\"\n",
    "#model_name = \"mobilenetv2_0.5_96_c3_o2_l5\"\n",
    "#model_name = \"mobilenetv2_0.25_96_c3_o2_t5l512.MV1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/tiny_mlc/tiny_cnn/models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_path, models_summary_path, models_image_path, models_layer_df_path, models_tf_path, models_tflite_path, models_tflite_opt_path = create_filepaths(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_performance.txt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_benchmark_path = models_dir.joinpath(model_name, f\"{model_name}_benchmark.txt\")\n",
    "models_benchmark_path\n",
    "models_performance_path = models_dir.joinpath(model_name, f\"{model_name}_performance.txt\")\n",
    "models_performance_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_tflite_opt_path.as_posix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking for tflite - non quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./benchmarking/linux_x86-64_benchmark_model \\\n",
    "#     --graph=$models_tflite_path \\\n",
    "#     --num_threads=1 \\\n",
    "#     --enable_op_profiling=true \\\n",
    "#     | tee $models_benchmark_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance for quantized tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: STARTING!\n",
      "INFO: The list of TFLite runtime options to be benchmarked: [all]\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [4]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [4]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [1]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: XNNPACK delegate created.\n",
      "INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 139.423ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=2669 first=4527 curr=154 min=135 max=4527 avg=184.279 std=95\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=4756 first=287 curr=240 min=145 max=662 avg=189.332 std=42\n",
      "\n",
      "INFO: Inference timings in us: Init: 139423, First inference: 4527, Warmup (avg): 184.279, Inference (avg): 189.332\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=3.6875 overall=4.00781\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 8.08203\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 8 MB\n",
      "INFO: + RssAnnon           : 1 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t   13.747\t    6.893\t 99.610%\t 99.610%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.034\t    0.027\t  0.390%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t   13.747\t    6.893\t 99.610%\t 99.610%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.034\t    0.027\t  0.390%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t    13.785\t    99.610%\t    99.610%\t     0.000\t        2\n",
      "\t                         AllocateTensors\t        1\t     0.054\t     0.390%\t   100.000%\t     0.000\t        2\n",
      "\n",
      "Timings (microseconds): count=1 curr=13839\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.100\t    0.072\t 44.688%\t 44.688%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.015\t    0.013\t  7.832%\t 52.520%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.011\t    0.010\t  6.045%\t 58.564%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.004\t  2.386%\t 60.950%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.004\t  2.472%\t 63.422%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.006\t  3.520%\t 66.941%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.004\t  2.730%\t 69.672%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.002\t  1.382%\t 71.054%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  1.410%\t 72.464%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.003\t  2.157%\t 74.621%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.702%\t 76.323%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.001\t  0.910%\t 77.233%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  1.472%\t 78.705%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.002\t  1.354%\t 80.059%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.679%\t 81.738%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.385%\t 83.123%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.612%\t 84.735%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.002\t  1.436%\t 86.171%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.595%\t 87.766%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.438%\t 89.204%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.641%\t 90.845%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.002\t  1.410%\t 92.256%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.658%\t 93.914%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.754%\t 94.668%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.038\t    0.002\t  1.379%\t 96.047%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.001\t  0.801%\t 96.847%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.413%\t 98.260%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.003\t    0.002\t  1.152%\t 99.412%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                           Copy (NC, X8)\t    0.000\t    0.000\t  0.022%\t 99.435%\t     0.000\t        1\tDelegate/Copy (NC, X8):0\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.000\t    0.000\t  0.026%\t 99.460%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:1\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.540%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.100\t    0.072\t 44.688%\t 44.688%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.015\t    0.013\t  7.832%\t 52.520%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.011\t    0.010\t  6.045%\t 58.564%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.006\t  3.520%\t 62.084%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.004\t  2.730%\t 64.814%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.004\t  2.472%\t 67.286%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.004\t  2.386%\t 69.672%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.003\t  2.157%\t 71.829%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.702%\t 73.531%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.679%\t 75.210%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.071\t    48.630%\t    48.630%\t     0.000\t        1\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.038\t    26.027%\t    74.658%\t     0.000\t       13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.036\t    24.658%\t    99.315%\t     0.000\t       13\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.685%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                           Copy (NC, X8)\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=4756 first=245 curr=210 min=120 max=621 avg=160.035 std=40\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [1]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: XNNPACK delegate created.\n",
      "INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 23.034ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=2133 first=1606 curr=263 min=196 max=1606 avg=232.314 std=77\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=4150 first=267 curr=204 min=201 max=582 avg=225.653 std=35\n",
      "\n",
      "INFO: Inference timings in us: Init: 23034, First inference: 1606, Warmup (avg): 232.314, Inference (avg): 225.653\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.132812 overall=0.132812\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 8.64453\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 8 MB\n",
      "INFO: + RssAnnon           : 1 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.650\t    0.353\t 87.500%\t 87.500%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.069\t    0.051\t 12.500%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.650\t    0.353\t 87.500%\t 87.500%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.069\t    0.051\t 12.500%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t     0.707\t    87.500%\t    87.500%\t     0.000\t        2\n",
      "\t                         AllocateTensors\t        1\t     0.101\t    12.500%\t   100.000%\t     0.000\t        2\n",
      "\n",
      "Timings (microseconds): count=1 curr=808\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.054\t    0.047\t 23.657%\t 23.657%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.041\t    0.036\t 18.084%\t 41.741%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.020\t    0.017\t  8.724%\t 50.465%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.010\t    0.009\t  4.440%\t 54.904%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.008\t    0.007\t  3.381%\t 58.285%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.016\t    0.014\t  7.127%\t 65.413%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.009\t    0.008\t  3.934%\t 69.347%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.003\t  1.706%\t 71.053%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.730%\t 72.783%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.007\t  3.280%\t 76.063%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.005\t  2.691%\t 78.755%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  0.920%\t 79.674%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  1.116%\t 80.790%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.438%\t 82.228%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.655%\t 83.883%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.354%\t 85.237%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.640%\t 86.877%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.483%\t 88.360%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.643%\t 90.003%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.374%\t 91.377%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.620%\t 92.997%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.435%\t 94.432%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.613%\t 96.045%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.522%\t 96.567%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.001\t  0.688%\t 97.255%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.001\t  0.579%\t 97.834%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  1.166%\t 99.000%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.002\t    0.001\t  0.675%\t 99.675%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                           Copy (NC, X8)\t    0.000\t    0.000\t  0.006%\t 99.682%\t     0.000\t        1\tDelegate/Copy (NC, X8):0\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.000\t    0.000\t  0.003%\t 99.685%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:1\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.315%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.054\t    0.047\t 23.657%\t 23.657%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.041\t    0.036\t 18.084%\t 41.741%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.020\t    0.017\t  8.724%\t 50.465%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.016\t    0.014\t  7.127%\t 57.592%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.010\t    0.009\t  4.440%\t 62.032%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.009\t    0.008\t  3.934%\t 65.966%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.008\t    0.007\t  3.381%\t 69.347%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.007\t  3.280%\t 72.627%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.005\t  2.691%\t 75.319%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  1.730%\t 77.049%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.080\t    43.011%\t    43.011%\t     0.000\t       13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.058\t    31.183%\t    74.194%\t     0.000\t       13\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.047\t    25.269%\t    99.462%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.538%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                           Copy (NC, X8)\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=4150 first=231 curr=179 min=176 max=517 avg=200.559 std=32\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [2]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [2]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [1]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: XNNPACK delegate created.\n",
      "INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 7.668ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=2864 first=337 curr=156 min=146 max=704 avg=171.927 std=39\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=4989 first=192 curr=294 min=152 max=853 avg=181.696 std=42\n",
      "\n",
      "INFO: Inference timings in us: Init: 7668, First inference: 337, Warmup (avg): 171.927, Inference (avg): 181.696\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0 overall=0\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 8.80078\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 8 MB\n",
      "INFO: + RssAnnon           : 1 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.222\t    0.120\t 87.636%\t 87.636%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.024\t    0.017\t 12.364%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.222\t    0.120\t 87.636%\t 87.636%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.024\t    0.017\t 12.364%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t     0.241\t    87.636%\t    87.636%\t     0.000\t        2\n",
      "\t                         AllocateTensors\t        1\t     0.034\t    12.364%\t   100.000%\t     0.000\t        2\n",
      "\n",
      "Timings (microseconds): count=1 curr=275\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.072\t    0.050\t 32.552%\t 32.552%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.018\t    0.021\t 13.471%\t 46.023%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.009\t    0.011\t  6.903%\t 52.926%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.006\t  3.737%\t 56.663%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.005\t  2.938%\t 59.601%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.007\t    0.008\t  5.297%\t 64.897%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.005\t  3.330%\t 68.227%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.586%\t 69.813%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.584%\t 71.397%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.004\t  2.576%\t 73.973%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  2.255%\t 76.228%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.965%\t 77.193%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.354%\t 78.547%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.482%\t 80.030%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.556%\t 81.585%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.510%\t 83.096%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.559%\t 84.655%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.481%\t 86.136%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.555%\t 87.691%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.478%\t 89.169%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.588%\t 90.757%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  1.480%\t 92.237%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.541%\t 93.778%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.708%\t 94.486%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.396%\t 95.882%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.891%\t 96.773%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.538%\t 98.311%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.001\t    0.002\t  1.089%\t 99.400%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                           Copy (NC, X8)\t    0.000\t    0.000\t  0.034%\t 99.434%\t     0.000\t        1\tDelegate/Copy (NC, X8):0\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.000\t    0.000\t  0.028%\t 99.462%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:1\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.538%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.072\t    0.050\t 32.552%\t 32.552%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.018\t    0.021\t 13.471%\t 46.023%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.009\t    0.011\t  6.903%\t 52.926%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.007\t    0.008\t  5.297%\t 58.223%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.006\t  3.737%\t 61.959%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.005\t  3.330%\t 65.289%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.005\t  2.938%\t 68.227%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.004\t  2.576%\t 70.803%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  2.255%\t 73.058%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.588%\t 74.646%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.051\t    35.915%\t    35.915%\t     0.000\t       13\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.050\t    35.211%\t    71.127%\t     0.000\t        1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.040\t    28.169%\t    99.296%\t     0.000\t       13\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.704%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                           Copy (NC, X8)\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=4989 first=161 curr=266 min=127 max=817 avg=154.504 std=39\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [4]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [4]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 7.357ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1047 first=454 curr=369 min=266 max=1900 avg=474.109 std=159\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1772 first=441 curr=523 min=296 max=1505 avg=503.347 std=163\n",
      "\n",
      "INFO: Inference timings in us: Init: 7357, First inference: 454, Warmup (avg): 474.109, Inference (avg): 503.347\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.109375 overall=0.109375\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 8.91016\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 8 MB\n",
      "INFO: + RssAnnon           : 1 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.057\t    0.057\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.057\t    0.057\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.057\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=57\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                 CONV_2D\t    0.047\t    0.070\t 14.596%\t 14.596%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.050\t    0.052\t 10.947%\t 25.543%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.040\t    0.060\t 12.614%\t 38.157%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.022\t    0.026\t  5.496%\t 43.653%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                                 CONV_2D\t    0.015\t    0.022\t  4.628%\t 48.280%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.023\t    0.024\t  5.104%\t 53.384%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                                 CONV_2D\t    0.014\t    0.017\t  3.563%\t 56.947%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.009\t    0.011\t  2.367%\t 59.314%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                                 CONV_2D\t    0.017\t    0.011\t  2.257%\t 61.571%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:8\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.015\t    0.016\t  3.293%\t 64.864%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                                 CONV_2D\t    0.011\t    0.011\t  2.394%\t 67.258%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.007\t    0.008\t  1.580%\t 68.838%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:11\n",
      "\t                                 CONV_2D\t    0.006\t    0.008\t  1.693%\t 70.531%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:12\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.033\t    0.011\t  2.352%\t 72.883%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:13\n",
      "\t                                 CONV_2D\t    0.008\t    0.010\t  2.050%\t 74.934%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:14\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.011\t    0.011\t  2.349%\t 77.283%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:15\n",
      "\t                                 CONV_2D\t    0.008\t    0.010\t  2.032%\t 79.315%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:16\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.010\t    0.011\t  2.238%\t 81.553%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:17\n",
      "\t                                 CONV_2D\t    0.007\t    0.009\t  1.928%\t 83.481%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:18\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.010\t    0.011\t  2.305%\t 85.786%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:19\n",
      "\t                                 CONV_2D\t    0.007\t    0.010\t  1.995%\t 87.781%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:20\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.011\t    0.011\t  2.225%\t 90.006%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:21\n",
      "\t                                 CONV_2D\t    0.008\t    0.009\t  1.977%\t 91.983%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:22\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.004\t    0.005\t  1.015%\t 92.998%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:23\n",
      "\t                                 CONV_2D\t    0.007\t    0.010\t  2.059%\t 95.057%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:24\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.006\t    0.007\t  1.485%\t 96.542%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:25\n",
      "\t                                 CONV_2D\t    0.011\t    0.011\t  2.265%\t 98.808%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.002\t    0.002\t  0.398%\t 99.205%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                                 RESHAPE\t    0.000\t    0.001\t  0.142%\t 99.347%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:28\n",
      "\t                         FULLY_CONNECTED\t    0.001\t    0.002\t  0.452%\t 99.799%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:29\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.201%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                 CONV_2D\t    0.047\t    0.070\t 14.596%\t 14.596%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                                 CONV_2D\t    0.040\t    0.060\t 12.614%\t 27.210%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.050\t    0.052\t 10.947%\t 38.157%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.022\t    0.026\t  5.496%\t 43.653%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.023\t    0.024\t  5.104%\t 48.757%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                                 CONV_2D\t    0.015\t    0.022\t  4.628%\t 53.384%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                                 CONV_2D\t    0.014\t    0.017\t  3.563%\t 56.947%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.015\t    0.016\t  3.293%\t 60.240%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                                 CONV_2D\t    0.011\t    0.011\t  2.394%\t 62.634%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.009\t    0.011\t  2.367%\t 65.001%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                                 CONV_2D\t       14\t     0.261\t    56.371%\t    56.371%\t     0.000\t       14\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.199\t    42.981%\t    99.352%\t     0.000\t       13\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.002\t     0.432%\t    99.784%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.216%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1772 first=421 curr=501 min=276 max=1468 avg=478.388 std=158\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [2]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [2]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 27.609ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1093 first=2601 curr=354 min=348 max=2601 avg=454.995 std=202\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1942 first=472 curr=869 min=377 max=1666 avg=469.527 std=113\n",
      "\n",
      "INFO: Inference timings in us: Init: 27609, First inference: 2601, Warmup (avg): 454.995, Inference (avg): 469.527\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.214844 overall=0.214844\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 9.12891\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 9 MB\n",
      "INFO: + RssAnnon           : 2 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.196\t    0.196\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.196\t    0.196\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.196\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=196\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                 CONV_2D\t    0.058\t    0.069\t 15.289%\t 15.289%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.062\t    0.065\t 14.608%\t 29.897%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.051\t    0.048\t 10.633%\t 40.530%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.032\t    0.029\t  6.408%\t 46.938%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                                 CONV_2D\t    0.015\t    0.018\t  3.972%\t 50.910%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.061\t    0.029\t  6.468%\t 57.378%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                                 CONV_2D\t    0.013\t    0.013\t  2.906%\t 60.284%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.011\t    0.012\t  2.668%\t 62.951%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                                 CONV_2D\t    0.007\t    0.009\t  1.936%\t 64.887%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:8\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.015\t    0.018\t  3.974%\t 68.861%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                                 CONV_2D\t    0.009\t    0.009\t  1.904%\t 70.765%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.006\t  1.352%\t 72.117%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:11\n",
      "\t                                 CONV_2D\t    0.006\t    0.006\t  1.442%\t 73.559%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:12\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.010\t  2.148%\t 75.707%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:13\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.791%\t 77.498%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:14\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.010\t  2.180%\t 79.678%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:15\n",
      "\t                                 CONV_2D\t    0.006\t    0.008\t  1.714%\t 81.392%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:16\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.010\t  2.216%\t 83.608%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:17\n",
      "\t                                 CONV_2D\t    0.007\t    0.007\t  1.663%\t 85.271%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:18\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.010\t  2.145%\t 87.416%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:19\n",
      "\t                                 CONV_2D\t    0.006\t    0.008\t  1.687%\t 89.104%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:20\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.010\t  2.145%\t 91.249%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:21\n",
      "\t                                 CONV_2D\t    0.006\t    0.008\t  1.693%\t 92.942%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:22\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.003\t    0.004\t  0.989%\t 93.931%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:23\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.777%\t 95.709%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:24\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.006\t    0.007\t  1.456%\t 97.165%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:25\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.800%\t 98.965%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.002\t    0.002\t  0.337%\t 99.302%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                                 RESHAPE\t    0.001\t    0.001\t  0.128%\t 99.430%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:28\n",
      "\t                         FULLY_CONNECTED\t    0.002\t    0.002\t  0.394%\t 99.824%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:29\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.176%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                 CONV_2D\t    0.058\t    0.069\t 15.289%\t 15.289%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.062\t    0.065\t 14.608%\t 29.897%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.051\t    0.048\t 10.633%\t 40.530%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.061\t    0.029\t  6.468%\t 46.998%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.032\t    0.029\t  6.408%\t 53.406%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.015\t    0.018\t  3.974%\t 57.380%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                                 CONV_2D\t    0.015\t    0.018\t  3.972%\t 61.352%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                                 CONV_2D\t    0.013\t    0.013\t  2.906%\t 64.257%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.011\t    0.012\t  2.668%\t 66.925%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.010\t  2.216%\t 69.141%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:17\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                                 CONV_2D\t       14\t     0.218\t    50.698%\t    50.698%\t     0.000\t       14\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.210\t    48.837%\t    99.535%\t     0.000\t       13\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.001\t     0.233%\t    99.767%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.233%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1942 first=449 curr=844 min=358 max=1628 avg=448.247 std=109\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 6.586ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=731 first=569 curr=526 min=521 max=2462 avg=681.624 std=179\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1499 first=574 curr=573 min=552 max=2182 avg=624.892 std=133\n",
      "\n",
      "INFO: Inference timings in us: Init: 6586, First inference: 569, Warmup (avg): 681.624, Inference (avg): 624.892\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.195312 overall=0.195312\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 9.32422\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 9 MB\n",
      "INFO: + RssAnnon           : 2 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.058\t    0.058\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.058\t    0.058\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.058\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=58\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                 CONV_2D\t    0.080\t    0.087\t 14.463%\t 14.463%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.102\t    0.114\t 18.879%\t 33.342%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.040\t    0.044\t  7.330%\t 40.671%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.049\t  8.066%\t 48.738%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                                 CONV_2D\t    0.015\t    0.016\t  2.689%\t 51.427%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.048\t  8.016%\t 59.443%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                                 CONV_2D\t    0.015\t    0.018\t  2.939%\t 62.381%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.017\t    0.020\t  3.228%\t 65.609%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.269%\t 66.879%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:8\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.027\t    0.030\t  4.899%\t 71.778%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                                 CONV_2D\t    0.009\t    0.011\t  1.751%\t 73.529%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.008\t  1.365%\t 74.893%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:11\n",
      "\t                                 CONV_2D\t    0.006\t    0.006\t  0.947%\t 75.840%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:12\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.015\t  2.441%\t 78.282%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:13\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.326%\t 79.608%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:14\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.340%\t 81.947%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:15\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.282%\t 83.229%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:16\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.015\t  2.414%\t 85.643%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:17\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.286%\t 86.930%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:18\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.358%\t 89.288%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:19\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.304%\t 90.592%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:20\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.348%\t 92.940%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:21\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.281%\t 94.221%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:22\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.004\t    0.004\t  0.736%\t 94.957%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:23\n",
      "\t                                 CONV_2D\t    0.007\t    0.007\t  1.207%\t 96.164%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:24\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.006\t    0.007\t  1.232%\t 97.396%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:25\n",
      "\t                                 CONV_2D\t    0.010\t    0.011\t  1.873%\t 99.269%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.001\t    0.001\t  0.242%\t 99.512%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                                 RESHAPE\t    0.001\t    0.001\t  0.094%\t 99.605%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:28\n",
      "\t                         FULLY_CONNECTED\t    0.002\t    0.002\t  0.268%\t 99.873%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:29\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.127%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.102\t    0.114\t 18.879%\t 18.879%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.080\t    0.087\t 14.463%\t 33.342%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.049\t  8.066%\t 41.408%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.048\t  8.016%\t 49.424%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                                 CONV_2D\t    0.040\t    0.044\t  7.330%\t 56.754%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.027\t    0.030\t  4.899%\t 61.653%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.017\t    0.020\t  3.228%\t 64.881%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                                 CONV_2D\t    0.015\t    0.018\t  2.939%\t 67.820%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                                 CONV_2D\t    0.015\t    0.016\t  2.689%\t 70.509%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.015\t  2.441%\t 72.950%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:13\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.347\t    58.913%\t    58.913%\t     0.000\t       13\n",
      "\t                                 CONV_2D\t       14\t     0.240\t    40.747%\t    99.660%\t     0.000\t       14\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.001\t     0.170%\t    99.830%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.170%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1499 first=546 curr=556 min=533 max=2117 avg=604.344 std=129\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Report the peak memory footprint: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Use gpu: [1]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "WARN: The GPU delegate compile options are only supported on Android or iOS platforms or when the tool was built with -DCL_DELEGATE_NO_GL.\n",
      "WARN: GPU acceleration is unsupported on this platform.\n",
      "INFO: The input model file size (MB): 0.086776\n",
      "INFO: Initialized session in 7.791ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=903 first=660 curr=539 min=520 max=1285 avg=551.492 std=54\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1526 first=568 curr=577 min=552 max=1268 avg=614.412 std=82\n",
      "\n",
      "INFO: Inference timings in us: Init: 7791, First inference: 660, Warmup (avg): 551.492, Inference (avg): 614.412\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.113281 overall=0.113281\n",
      "INFO: Overall peak memory footprint (MB) via periodic monitoring: 9.4375\n",
      "INFO: Memory status at the end of exeution:\n",
      "INFO: - VmRSS              : 9 MB\n",
      "INFO: + RssAnnon           : 2 MB\n",
      "INFO: + RssFile + RssShmem : 7 MB\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.075\t    0.075\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.075\t    0.075\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.075\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=75\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                 CONV_2D\t    0.079\t    0.086\t 14.517%\t 14.517%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.103\t    0.111\t 18.765%\t 33.282%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.040\t    0.044\t  7.379%\t 40.662%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.048\t  8.008%\t 48.670%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                                 CONV_2D\t    0.015\t    0.016\t  2.712%\t 51.382%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.048\t  8.079%\t 59.461%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                                 CONV_2D\t    0.016\t    0.017\t  2.924%\t 62.386%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.018\t    0.019\t  3.227%\t 65.612%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.268%\t 66.880%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:8\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.027\t    0.029\t  4.869%\t 71.749%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                                 CONV_2D\t    0.010\t    0.011\t  1.776%\t 73.525%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.008\t  1.406%\t 74.931%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:11\n",
      "\t                                 CONV_2D\t    0.005\t    0.006\t  0.981%\t 75.912%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:12\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.386%\t 78.297%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:13\n",
      "\t                                 CONV_2D\t    0.008\t    0.008\t  1.319%\t 79.616%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:14\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.369%\t 81.985%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:15\n",
      "\t                                 CONV_2D\t    0.008\t    0.008\t  1.294%\t 83.280%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:16\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.362%\t 85.641%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:17\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.324%\t 86.965%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:18\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.362%\t 89.328%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:19\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.297%\t 90.624%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:20\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.380%\t 93.004%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:21\n",
      "\t                                 CONV_2D\t    0.007\t    0.008\t  1.299%\t 94.302%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:22\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.004\t    0.004\t  0.731%\t 95.034%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:23\n",
      "\t                                 CONV_2D\t    0.007\t    0.007\t  1.186%\t 96.220%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:24\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.007\t    0.007\t  1.240%\t 97.460%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:25\n",
      "\t                                 CONV_2D\t    0.010\t    0.011\t  1.811%\t 99.270%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.002\t    0.001\t  0.247%\t 99.517%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                                 RESHAPE\t    0.001\t    0.001\t  0.090%\t 99.607%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:28\n",
      "\t                         FULLY_CONNECTED\t    0.001\t    0.002\t  0.267%\t 99.874%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:29\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.126%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.103\t    0.111\t 18.765%\t 18.765%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:1\n",
      "\t                                 CONV_2D\t    0.079\t    0.086\t 14.517%\t 33.282%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:0\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.048\t  8.079%\t 41.362%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.044\t    0.048\t  8.008%\t 49.370%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:3\n",
      "\t                                 CONV_2D\t    0.040\t    0.044\t  7.379%\t 56.749%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.027\t    0.029\t  4.869%\t 61.618%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:9\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.018\t    0.019\t  3.227%\t 64.845%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:7\n",
      "\t                                 CONV_2D\t    0.016\t    0.017\t  2.924%\t 67.769%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:6\n",
      "\t                                 CONV_2D\t    0.015\t    0.016\t  2.712%\t 70.481%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.013\t    0.014\t  2.386%\t 72.867%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:13\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.341\t    58.895%\t    58.895%\t     0.000\t       13\n",
      "\t                                 CONV_2D\t       14\t     0.236\t    40.760%\t    99.655%\t     0.000\t       14\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.001\t     0.173%\t    99.827%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.173%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1526 first=551 curr=562 min=531 max=1247 avg=593.842 std=79\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: \n",
      "==============Summary of All Runs w/ Different Performance Options==============\n",
      "INFO: cpu w/ 2 threads (xnnpack): count=4989 first=192 curr=294 min=152 max=853 avg=181.696 std=42\n",
      "INFO: cpu w/ 4 threads (xnnpack): count=4756 first=287 curr=240 min=145 max=662 avg=189.332 std=42\n",
      "INFO: cpu w/ 1 threads (xnnpack): count=4150 first=267 curr=204 min=201 max=582 avg=225.653 std=35\n",
      "INFO:           cpu w/ 2 threads: count=1942 first=472 curr=869 min=377 max=1666 avg=469.527 std=113\n",
      "INFO:           cpu w/ 4 threads: count=1772 first=441 curr=523 min=296 max=1505 avg=503.347 std=163\n",
      "INFO:                gpu-default: count=1526 first=568 curr=577 min=552 max=1268 avg=614.412 std=82\n",
      "INFO:           cpu w/ 1 threads: count=1499 first=574 curr=573 min=552 max=2182 avg=624.892 std=133\n"
     ]
    }
   ],
   "source": [
    "! ./benchmarking/linux_x86-64_benchmark_model_performance_options \\\n",
    "    --graph=$models_tflite_opt_path \\\n",
    "    --num_threads=1 \\\n",
    "    --enable_op_profiling=true \\\n",
    "    --report_peak_memory_footprint=true \\\n",
    "    | tee $models_benchmark_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking for quantized .tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING!\n",
      "Log parameter values verbosely: [0]\n",
      "Num threads: [1]\n",
      "Report the peak memory footprint: [1]\n",
      "Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "Enable op profiling: [1]\n",
      "#threads used for CPU inference: [1]\n",
      "Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "The input model file size (MB): 0.086776\n",
      "Initialized session in 170.103ms.\n",
      "Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "count=2075 first=10421 curr=199 min=195 max=10421 avg=238.764 std=238\n",
      "\n",
      "Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "count=4053 first=221 curr=205 min=202 max=832 avg=230.364 std=44\n",
      "\n",
      "Inference timings in us: Init: 170103, First inference: 10421, Warmup (avg): 238.764, Inference (avg): 230.364\n",
      "Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "Memory footprint delta from the start of the tool (MB): init=3.32812 overall=3.60156\n",
      "Overall peak memory footprint (MB) via periodic monitoring: 7.8125\n",
      "Memory status at the end of exeution:\n",
      "- VmRSS              : 7 MB\n",
      "+ RssAnnon           : 0 MB\n",
      "+ RssFile + RssShmem : 7 MB\n",
      "Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t   18.380\t   18.380\t 99.712%\t 99.712%\t   880.000\t        1\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.053\t    0.053\t  0.288%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t   18.380\t   18.380\t 99.712%\t 99.712%\t   880.000\t        1\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.053\t    0.053\t  0.288%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t    18.380\t    99.712%\t    99.712%\t   880.000\t        1\n",
      "\t                         AllocateTensors\t        1\t     0.053\t     0.288%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=18433\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.044\t    0.048\t 23.419%\t 23.419%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.033\t    0.037\t 17.894%\t 41.314%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.016\t    0.018\t  8.686%\t 49.999%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.009\t  4.601%\t 54.601%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.007\t  3.270%\t 57.871%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.013\t    0.015\t  7.052%\t 64.922%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.008\t    0.009\t  4.239%\t 69.162%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  1.699%\t 70.860%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.765%\t 72.625%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.007\t  3.229%\t 75.854%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.006\t  2.717%\t 78.570%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.002\t  0.871%\t 79.441%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.183%\t 80.624%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.388%\t 82.011%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.599%\t 83.610%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.436%\t 85.046%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.634%\t 86.680%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.434%\t 88.114%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.592%\t 89.706%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.477%\t 91.183%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.606%\t 92.788%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  1.427%\t 94.215%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  1.607%\t 95.822%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.496%\t 96.318%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.001\t  0.671%\t 96.989%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.584%\t 97.573%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  1.153%\t 98.726%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.001\t    0.001\t  0.691%\t 99.417%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:27\n",
      "\t                                 RESHAPE\t    0.000\t    0.001\t  0.257%\t 99.673%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:28\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.000\t    0.000\t  0.008%\t 99.681%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:0\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.319%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:30\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.044\t    0.048\t 23.419%\t 23.419%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.033\t    0.037\t 17.894%\t 41.314%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.016\t    0.018\t  8.686%\t 49.999%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.013\t    0.015\t  7.052%\t 57.051%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.009\t  4.601%\t 61.652%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.008\t    0.009\t  4.239%\t 65.891%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.007\t  3.270%\t 69.162%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.007\t  3.229%\t 72.390%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.006\t  2.717%\t 75.107%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.765%\t 76.871%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\n",
      "Number of nodes executed: 31\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.082\t    43.158%\t    43.158%\t     0.000\t       13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.059\t    31.053%\t    74.211%\t     0.000\t       13\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.048\t    25.263%\t    99.474%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.526%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=4053 first=186 curr=187 min=177 max=794 avg=206.226 std=40\n",
      "Memory (bytes): count=0\n",
      "31 nodes observed\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ./benchmarking/linux_x86-64_benchmark_model \\\n",
    "    --graph=$models_tflite_opt_path \\\n",
    "    --num_threads=1 \\\n",
    "    --enable_op_profiling=true \\\n",
    "    --report_peak_memory_footprint=true \\\n",
    "    | tee $models_benchmark_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if automated == False:\n",
    "    ! code $models_benchmark_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the tensor arena size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/tiny_mlc/tflite-find-arena-size/build/find-arena-size')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_size_path = Path.cwd().parent.joinpath(\"tflite-find-arena-size\",\"build\",  \"find-arena-size\")\n",
    "arena_size_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture arena_size\n",
    "! $arena_size_path $models_tflite_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"arena_size\": 159408}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_size_raw = arena_size.stdout.strip()\n",
    "arena_size_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ast\n",
    "    arena_size_dict = ast.literal_eval(arena_size_raw)\n",
    "    arena_size = arena_size_dict[\"arena_size\"]\n",
    "    arena_size\n",
    "except:\n",
    "    arena_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3imun41'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = get_model_DB_run_id_from_architecture(model_name)\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/tiny_mlc/tiny_cnn/wandb/run-20230508_163144-t3imun41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/susbrock/model_DB/runs/t3imun41\" target=\"_blank\">mobilenetv1_0.1_96_c3_o2_l5.MV1</a></strong> to <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">https://wandb.ai/susbrock/model_DB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/susbrock/model_DB/runs/t3imun41\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/t3imun41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>arena_size</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>allocate_tensors_ms_%</td><td>0.209</td></tr><tr><td>allocate_tensors_ms_avg</td><td>0.028</td></tr><tr><td>allocate_tensors_ms_first</td><td>0.028</td></tr><tr><td>arena_size</td><td>0</td></tr><tr><td>first_inference_us</td><td>7424</td></tr><tr><td>inference_avg_us</td><td>330.124</td></tr><tr><td>init_us</td><td>455845</td></tr><tr><td>initialization_ms</td><td>455.845</td></tr><tr><td>model_size_MB</td><td>0.08718</td></tr><tr><td>modify_graph_with_delegate_mem_KB</td><td>836</td></tr><tr><td>modify_graph_with_delegate_ms_%</td><td>99.791</td></tr><tr><td>modify_graph_with_delegate_ms_avg</td><td>13.341</td></tr><tr><td>modify_graph_with_delegate_ms_first</td><td>13.341</td></tr><tr><td>test_accuracy</td><td>0.79987</td></tr><tr><td>test_loss</td><td>0.42842</td></tr><tr><td>warmup_avg_us</td><td>319.175</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mobilenetv1_0.1_96_c3_o2_l5.MV1</strong> at: <a href=\"https://wandb.ai/susbrock/model_DB/runs/t3imun41\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/t3imun41</a><br/>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230508_163144-t3imun41/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(run_id) > 1:\n",
    "\n",
    "        PROJECT = \"model_DB\"\n",
    "\n",
    "        run = wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT, \n",
    "                id = run_id, \n",
    "                resume=\"allow\",\n",
    "                )\n",
    "\n",
    "        run.log({\"arena_size\" : arena_size})\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "else:\n",
    "        print(f\"Could not find run_id {run_id}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faa6c31b20b8f809b81d6d7d22a84ccd9f354666f54133d1793fa4c65539801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
