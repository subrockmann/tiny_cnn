{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking tflite models  \n",
    "\n",
    "This notebook requires the native benchmark binary for linux that you can get from this page:  \n",
    " [https://www.tensorflow.org/lite/performance/measurement](https://www.tensorflow.org/lite/performance/measurement)  \n",
    "\n",
    " This binary must be placed into the \"benchmarking folder\".\n",
    "\n",
    " This notebook must be run under LINUX!\n",
    "\n",
    " TensorFlow Lite benchmark tools currently measure and calculate statistics for the following important performance metrics:\n",
    "\n",
    "- Initialization time\n",
    "- Inference time of warmup state\n",
    "- Inference time of steady state\n",
    "- Memory usage during initialization time\n",
    "- Overall memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# import workbench.config.config\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths\n",
    "from workbench.wandb import wandb_model_DB, get_model_DB_run_id_from_architecture, get_architecture_from_model_DB_run_id\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "#import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# enable plotly in VS Studio Code\n",
    "#import plotly.io as pio\n",
    "#pio.renderers.default = \"notebook_connected\"\n",
    "#pio.renderers.default = \"plotly_mimetype+notebook\"\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pandas to show all columns & rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "automated = False\n",
    "\n",
    "global model_name\n",
    "model_name = \"mobilenetv1_0.1_96_c3_o2_l5.MV1\"\n",
    "#model_name = \"mobilenetv2_0.5_96_c3_o2_l5\"\n",
    "#model_name = \"mobilenetv2_0.25_96_c3_o2_t5l512.MV1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/tiny_mlc/tiny_cnn/models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_path, models_summary_path, models_image_path, models_layer_df_path, models_tf_path, models_tflite_path, models_tflite_opt_path = create_filepaths(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_performance.txt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_benchmark_path = models_dir.joinpath(model_name, f\"{model_name}_benchmark.txt\")\n",
    "models_benchmark_path\n",
    "models_performance_path = models_dir.joinpath(model_name, f\"{model_name}_performance.txt\")\n",
    "models_performance_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_tflite_opt_path.as_posix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking for tflite - non quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./benchmarking/linux_x86-64_benchmark_model \\\n",
    "#     --graph=$models_tflite_path \\\n",
    "#     --num_threads=1 \\\n",
    "#     --enable_op_profiling=true \\\n",
    "#     | tee $models_benchmark_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking for quantized .tflite file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance for quantized tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: STARTING!\n",
      "INFO: The list of TFLite runtime options to be benchmarked: [all]\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [1]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: XNNPACK delegate created.\n",
      "INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 242.993ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=941 first=7052 curr=319 min=315 max=7676 avg=527.662 std=488\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=2255 first=322 curr=377 min=299 max=2076 avg=417.467 std=109\n",
      "\n",
      "INFO: Inference timings in us: Init: 242993, First inference: 7052, Warmup (avg): 527.662, Inference (avg): 417.467\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=3.49609 overall=3.77344\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t   15.207\t    7.620\t 99.634%\t 99.634%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.040\t    0.028\t  0.366%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t   15.207\t    7.620\t 99.634%\t 99.634%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.040\t    0.028\t  0.366%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t    15.239\t    99.634%\t    99.634%\t     0.000\t        2\n",
      "\t                         AllocateTensors\t        1\t     0.056\t     0.366%\t   100.000%\t     0.000\t        2\n",
      "\n",
      "Timings (microseconds): count=1 curr=15295\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.098\t    0.129\t 33.287%\t 33.287%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.046\t    0.060\t 15.610%\t 48.896%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.035\t    0.047\t 12.050%\t 60.946%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.017\t    0.022\t  5.683%\t 66.629%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.009\t    0.012\t  3.053%\t 69.681%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.008\t  2.188%\t 71.869%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.014\t    0.018\t  4.588%\t 76.457%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.008\t    0.010\t  2.666%\t 79.123%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.005\t  1.167%\t 80.290%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.005\t  1.224%\t 81.514%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.008\t  2.106%\t 83.620%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.007\t  1.699%\t 85.319%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  0.591%\t 85.910%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.003\t  0.755%\t 86.664%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.958%\t 87.623%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.147%\t 88.770%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.959%\t 89.729%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.062%\t 90.791%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.952%\t 91.743%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.111%\t 92.854%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.947%\t 93.801%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.054%\t 94.855%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.966%\t 95.821%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.047%\t 96.869%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.001\t  0.289%\t 97.157%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  0.557%\t 97.715%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.002\t  0.436%\t 98.151%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.003\t  0.824%\t 98.975%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.001\t    0.002\t  0.489%\t 99.463%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                           Copy (NC, X8)\t    0.000\t    0.000\t  0.033%\t 99.496%\t     0.000\t        1\tDelegate/Copy (NC, X8):0\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.000\t    0.000\t  0.030%\t 99.526%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:1\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.253%\t 99.779%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.001\t    0.001\t  0.221%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.098\t    0.129\t 33.287%\t 33.287%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.046\t    0.060\t 15.610%\t 48.896%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.035\t    0.047\t 12.050%\t 60.946%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.017\t    0.022\t  5.683%\t 66.629%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.014\t    0.018\t  4.588%\t 71.217%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.009\t    0.012\t  3.053%\t 74.270%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.008\t    0.010\t  2.666%\t 76.935%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.008\t  2.188%\t 79.123%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.008\t  2.106%\t 81.229%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.007\t  1.699%\t 82.928%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                                QUANTIZE\t        2\t     0.128\t    34.595%\t    34.595%\t     0.000\t        2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.105\t    28.378%\t    62.973%\t     0.000\t       13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.076\t    20.541%\t    83.514%\t     0.000\t       13\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.060\t    16.216%\t    99.730%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.001\t     0.270%\t   100.000%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                           Copy (NC, X8)\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=2255 first=294 curr=346 min=273 max=2028 avg=386.886 std=103\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [2]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [2]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [1]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: XNNPACK delegate created.\n",
      "INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 10.8ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1121 first=543 curr=286 min=285 max=2209 avg=442.173 std=139\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1994 first=303 curr=323 min=292 max=2453 avg=464.517 std=140\n",
      "\n",
      "INFO: Inference timings in us: Init: 10800, First inference: 543, Warmup (avg): 442.173, Inference (avg): 464.517\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.234375 overall=0.488281\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.221\t    0.130\t 84.416%\t 84.416%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.025\t    0.024\t 15.584%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.221\t    0.130\t 84.416%\t 84.416%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.025\t    0.024\t 15.584%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t     0.260\t    84.416%\t    84.416%\t     0.000\t        2\n",
      "\t                         AllocateTensors\t        1\t     0.048\t    15.584%\t   100.000%\t     0.000\t        2\n",
      "\n",
      "Timings (microseconds): count=1 curr=308\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.105\t    0.162\t 38.117%\t 38.117%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.054\t    0.086\t 20.239%\t 58.355%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.021\t    0.033\t  7.727%\t 66.082%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.010\t    0.020\t  4.744%\t 70.827%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.009\t  2.188%\t 73.015%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.008\t  1.926%\t 74.941%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.013\t  2.996%\t 77.937%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.007\t    0.009\t  2.145%\t 80.081%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.005\t  1.075%\t 81.156%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.005\t  1.143%\t 82.299%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.007\t  1.587%\t 83.886%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.006\t  1.477%\t 85.363%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.003\t  0.655%\t 86.018%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.003\t  0.704%\t 86.722%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.868%\t 87.590%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.004\t  0.979%\t 88.569%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.004\t  0.880%\t 89.449%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.004\t  0.909%\t 90.358%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.004\t  0.860%\t 91.218%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.004\t  0.915%\t 92.132%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.004\t  0.923%\t 93.055%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.004\t  0.921%\t 93.976%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.004\t  0.858%\t 94.834%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.004\t  0.915%\t 95.749%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.002\t  0.461%\t 96.210%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.004\t  0.862%\t 97.072%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.001\t    0.003\t  0.599%\t 97.671%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  0.923%\t 98.594%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.002\t    0.003\t  0.644%\t 99.238%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                           Copy (NC, X8)\t    0.000\t    0.000\t  0.090%\t 99.328%\t     0.000\t        1\tDelegate/Copy (NC, X8):0\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.000\t    0.000\t  0.094%\t 99.423%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:1\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.309%\t 99.732%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.000\t    0.001\t  0.268%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.105\t    0.162\t 38.117%\t 38.117%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.054\t    0.086\t 20.239%\t 58.355%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.021\t    0.033\t  7.727%\t 66.082%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.010\t    0.020\t  4.744%\t 70.827%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.013\t  2.996%\t 73.822%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.009\t  2.188%\t 76.010%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.007\t    0.009\t  2.145%\t 78.155%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.008\t  1.926%\t 80.081%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.007\t  1.587%\t 81.668%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.006\t  1.477%\t 83.145%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                                QUANTIZE\t        2\t     0.163\t    40.049%\t    40.049%\t     0.000\t        2\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.086\t    21.130%\t    61.179%\t     0.000\t        1\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.083\t    20.393%\t    81.572%\t     0.000\t       13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.072\t    17.690%\t    99.263%\t     0.000\t       13\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.002\t     0.491%\t    99.754%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.001\t     0.246%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                           Copy (NC, X8)\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1994 first=266 curr=297 min=264 max=2405 avg=425.915 std=132\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [2]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [2]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 9.632ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=659 first=827 curr=732 min=460 max=1876 avg=755.932 std=244\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1144 first=1171 curr=1241 min=496 max=3022 avg=800.951 std=267\n",
      "\n",
      "INFO: Inference timings in us: Init: 9632, First inference: 827, Warmup (avg): 755.932, Inference (avg): 800.951\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.0390625 overall=0.0390625\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.072\t    0.072\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.072\t    0.072\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.072\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=72\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.173\t    0.150\t 19.413%\t 19.413%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.163\t    0.097\t 12.523%\t 31.937%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.153\t    0.095\t 12.311%\t 44.248%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                 CONV_2D\t    0.133\t    0.064\t  8.245%\t 52.493%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.105\t    0.042\t  5.388%\t 57.882%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                                 CONV_2D\t    0.036\t    0.024\t  3.091%\t 60.972%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.075\t    0.042\t  5.440%\t 66.412%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.023\t    0.017\t  2.246%\t 68.658%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.030\t    0.018\t  2.322%\t 70.980%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.011\t    0.011\t  1.438%\t 72.418%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:9\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.033\t    0.025\t  3.290%\t 75.707%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                                 CONV_2D\t    0.012\t    0.011\t  1.417%\t 77.124%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:11\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.009\t    0.009\t  1.106%\t 78.231%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:12\n",
      "\t                                 CONV_2D\t    0.009\t    0.008\t  1.069%\t 79.300%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:13\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.012\t    0.014\t  1.750%\t 81.050%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:14\n",
      "\t                                 CONV_2D\t    0.010\t    0.010\t  1.279%\t 82.329%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:15\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.012\t    0.014\t  1.754%\t 84.083%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:16\n",
      "\t                                 CONV_2D\t    0.026\t    0.010\t  1.259%\t 85.343%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:17\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.012\t    0.013\t  1.692%\t 87.034%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:18\n",
      "\t                                 CONV_2D\t    0.010\t    0.010\t  1.341%\t 88.376%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:19\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.012\t    0.013\t  1.676%\t 90.052%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:20\n",
      "\t                                 CONV_2D\t    0.009\t    0.010\t  1.232%\t 91.284%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:21\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.012\t    0.014\t  1.756%\t 93.040%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:22\n",
      "\t                                 CONV_2D\t    0.010\t    0.010\t  1.263%\t 94.302%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:23\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.006\t    0.006\t  0.773%\t 95.075%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:24\n",
      "\t                                 CONV_2D\t    0.010\t    0.010\t  1.353%\t 96.428%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:25\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.009\t  1.173%\t 97.601%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:26\n",
      "\t                                 CONV_2D\t    0.012\t    0.011\t  1.388%\t 98.989%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:27\n",
      "\t                         AVERAGE_POOL_2D\t    0.002\t    0.002\t  0.273%\t 99.263%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                                 RESHAPE\t    0.001\t    0.001\t  0.098%\t 99.361%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:29\n",
      "\t                         FULLY_CONNECTED\t    0.003\t    0.003\t  0.340%\t 99.700%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:30\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.148%\t 99.849%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.001\t    0.001\t  0.151%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.173\t    0.150\t 19.413%\t 19.413%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.163\t    0.097\t 12.523%\t 31.937%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.153\t    0.095\t 12.311%\t 44.248%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                 CONV_2D\t    0.133\t    0.064\t  8.245%\t 52.493%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.075\t    0.042\t  5.440%\t 57.933%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.105\t    0.042\t  5.388%\t 63.321%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.033\t    0.025\t  3.290%\t 66.611%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                                 CONV_2D\t    0.036\t    0.024\t  3.091%\t 69.702%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.030\t    0.018\t  2.322%\t 72.023%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.023\t    0.017\t  2.246%\t 74.270%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.306\t    40.476%\t    40.476%\t     0.000\t       13\n",
      "\t                                 CONV_2D\t       14\t     0.294\t    38.889%\t    79.365%\t     0.000\t       14\n",
      "\t                                QUANTIZE\t        2\t     0.151\t    19.974%\t    99.339%\t     0.000\t        2\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.002\t     0.265%\t    99.603%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.002\t     0.265%\t    99.868%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.001\t     0.132%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1144 first=1134 curr=1203 min=475 max=2957 avg=772.717 std=259\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 10.266ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=464 first=1149 curr=973 min=653 max=6807 avg=1073.56 std=482\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=867 first=2148 curr=1349 min=668 max=2552 avg=1077.55 std=292\n",
      "\n",
      "INFO: Inference timings in us: Init: 10266, First inference: 1149, Warmup (avg): 1073.56, Inference (avg): 1077.55\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.277344 overall=0.277344\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.083\t    0.083\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.083\t    0.083\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.083\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=83\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.159\t    0.148\t 14.167%\t 14.167%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.507\t    0.136\t 13.007%\t 27.175%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.364\t    0.169\t 16.170%\t 43.345%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                 CONV_2D\t    0.108\t    0.066\t  6.264%\t 49.609%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.123\t    0.072\t  6.902%\t 56.511%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                                 CONV_2D\t    0.038\t    0.024\t  2.306%\t 58.817%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.126\t    0.071\t  6.804%\t 65.621%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.041\t    0.026\t  2.478%\t 68.099%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.054\t    0.029\t  2.742%\t 70.842%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.020\t    0.011\t  1.070%\t 71.911%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:9\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.094\t    0.043\t  4.116%\t 76.028%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                                 CONV_2D\t    0.025\t    0.015\t  1.463%\t 77.491%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:11\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.023\t    0.013\t  1.211%\t 78.701%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:12\n",
      "\t                                 CONV_2D\t    0.015\t    0.008\t  0.804%\t 79.506%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:13\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.036\t    0.021\t  2.011%\t 81.516%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:14\n",
      "\t                                 CONV_2D\t    0.017\t    0.011\t  1.087%\t 82.603%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:15\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.034\t    0.021\t  2.034%\t 84.637%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:16\n",
      "\t                                 CONV_2D\t    0.017\t    0.011\t  1.087%\t 85.724%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:17\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.035\t    0.021\t  2.008%\t 87.732%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:18\n",
      "\t                                 CONV_2D\t    0.018\t    0.012\t  1.118%\t 88.850%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:19\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.035\t    0.021\t  2.006%\t 90.857%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:20\n",
      "\t                                 CONV_2D\t    0.017\t    0.011\t  1.091%\t 91.947%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:21\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.034\t    0.021\t  1.974%\t 93.922%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:22\n",
      "\t                                 CONV_2D\t    0.054\t    0.011\t  1.050%\t 94.972%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:23\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.014\t    0.007\t  0.666%\t 95.638%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:24\n",
      "\t                                 CONV_2D\t    0.017\t    0.010\t  0.987%\t 96.625%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:25\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.018\t    0.011\t  1.054%\t 97.679%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:26\n",
      "\t                                 CONV_2D\t    0.022\t    0.016\t  1.494%\t 99.173%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:27\n",
      "\t                         AVERAGE_POOL_2D\t    0.005\t    0.002\t  0.220%\t 99.393%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                                 RESHAPE\t    0.002\t    0.001\t  0.098%\t 99.491%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:29\n",
      "\t                         FULLY_CONNECTED\t    0.005\t    0.003\t  0.268%\t 99.758%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:30\n",
      "\t                                 SOFTMAX\t    0.003\t    0.001\t  0.125%\t 99.883%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.002\t    0.001\t  0.117%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.364\t    0.169\t 16.170%\t 16.170%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                QUANTIZE\t    0.159\t    0.148\t 14.167%\t 30.338%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.507\t    0.136\t 13.007%\t 43.345%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.123\t    0.072\t  6.902%\t 50.247%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.126\t    0.071\t  6.804%\t 57.051%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.108\t    0.066\t  6.264%\t 63.315%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.094\t    0.043\t  4.116%\t 67.431%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.054\t    0.029\t  2.742%\t 70.173%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.041\t    0.026\t  2.478%\t 72.652%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                                 CONV_2D\t    0.038\t    0.024\t  2.306%\t 74.958%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.516\t    49.903%\t    49.903%\t     0.000\t       13\n",
      "\t                                 CONV_2D\t       14\t     0.363\t    35.106%\t    85.010%\t     0.000\t       14\n",
      "\t                                QUANTIZE\t        2\t     0.149\t    14.410%\t    99.420%\t     0.000\t        2\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.002\t     0.193%\t    99.613%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.002\t     0.193%\t    99.807%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.001\t     0.097%\t    99.903%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.001\t     0.097%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=867 first=2082 curr=1310 min=647 max=2501 avg=1047.33 std=286\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [4]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [4]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [1]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: XNNPACK delegate created.\n",
      "INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 8.543ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1016 first=597 curr=353 min=282 max=2192 avg=488.241 std=174\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=1966 first=441 curr=553 min=264 max=3130 avg=469.019 std=189\n",
      "\n",
      "INFO: Inference timings in us: Init: 8543, First inference: 597, Warmup (avg): 488.241, Inference (avg): 469.019\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.128906 overall=0.128906\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.312\t    0.175\t 85.995%\t 85.995%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.036\t    0.029\t 14.005%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    0.312\t    0.175\t 85.995%\t 85.995%\t     0.000\t        2\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.036\t    0.029\t 14.005%\t100.000%\t     0.000\t        2\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t     0.350\t    85.995%\t    85.995%\t     0.000\t        2\n",
      "\t                         AllocateTensors\t        1\t     0.057\t    14.005%\t   100.000%\t     0.000\t        2\n",
      "\n",
      "Timings (microseconds): count=1 curr=407\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.144\t    0.175\t 40.781%\t 40.781%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.088\t    0.100\t 23.300%\t 64.080%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.018\t    0.022\t  5.217%\t 69.297%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.012\t    0.016\t  3.839%\t 73.136%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.007\t  1.707%\t 74.843%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.007\t  1.587%\t 76.430%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.009\t    0.009\t  2.106%\t 78.537%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.031\t    0.008\t  1.753%\t 80.290%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.868%\t 81.159%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  0.857%\t 82.016%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.006\t  1.287%\t 83.303%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.047%\t 84.350%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.003\t  0.635%\t 84.985%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  0.952%\t 85.938%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.005\t  1.158%\t 87.096%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  1.050%\t 88.145%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:14\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.820%\t 88.966%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:15\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.005\t  1.094%\t 90.059%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:16\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.827%\t 90.886%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:17\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.004\t  1.041%\t 91.927%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:18\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.896%\t 92.823%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:19\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.004\t  1.009%\t 93.831%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:20\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.004\t  0.826%\t 94.657%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:21\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.004\t  0.985%\t 95.641%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:22\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.002\t  0.534%\t 96.176%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.003\t  0.816%\t 96.992%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.002\t    0.003\t  0.693%\t 97.685%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.004\t  0.827%\t 98.512%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                         AVERAGE_POOL_2D\t    0.019\t    0.003\t  0.682%\t 99.194%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                           Copy (NC, X8)\t    0.001\t    0.000\t  0.114%\t 99.308%\t     0.000\t        1\tDelegate/Copy (NC, X8):0\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.001\t    0.000\t  0.097%\t 99.405%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:1\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.322%\t 99.726%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.001\t    0.001\t  0.274%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.144\t    0.175\t 40.781%\t 40.781%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.088\t    0.100\t 23.300%\t 64.080%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.018\t    0.022\t  5.217%\t 69.297%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.012\t    0.016\t  3.839%\t 73.136%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.009\t    0.009\t  2.106%\t 75.243%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.031\t    0.008\t  1.753%\t 76.996%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.007\t  1.707%\t 78.703%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:3\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.007\t  1.587%\t 80.290%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:4\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.006\t  1.287%\t 81.577%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:9\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.005\t  1.158%\t 82.736%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:13\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                                QUANTIZE\t        2\t     0.175\t    42.579%\t    42.579%\t     0.000\t        2\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.099\t    24.088%\t    66.667%\t     0.000\t        1\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       13\t     0.068\t    16.545%\t    83.212%\t     0.000\t       13\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       13\t     0.066\t    16.058%\t    99.270%\t     0.000\t       13\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.002\t     0.487%\t    99.757%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.001\t     0.243%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                           Copy (NC, X8)\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1966 first=398 curr=504 min=237 max=3079 avg=428.01 std=184\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [4]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [4]\n",
      "INFO: Use gpu: [0]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 7.261ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=503 first=1030 curr=1202 min=423 max=13653 avg=989.569 std=895\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=886 first=1191 curr=558 min=476 max=3416 avg=1013.88 std=332\n",
      "\n",
      "INFO: Inference timings in us: Init: 7261, First inference: 1030, Warmup (avg): 989.569, Inference (avg): 1013.88\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.3125 overall=0.3125\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.096\t    0.096\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.096\t    0.096\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.096\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=96\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.351\t    0.234\t 24.046%\t 24.046%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.140\t    0.124\t 12.757%\t 36.802%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.076\t    0.082\t  8.427%\t 45.229%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                 CONV_2D\t    0.117\t    0.090\t  9.212%\t 54.441%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.034\t    0.041\t  4.192%\t 58.634%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                                 CONV_2D\t    0.043\t    0.033\t  3.420%\t 62.054%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.034\t    0.041\t  4.166%\t 66.219%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.024\t    0.024\t  2.508%\t 68.728%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.017\t    0.018\t  1.886%\t 70.614%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.020\t    0.016\t  1.641%\t 72.255%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:9\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.022\t    0.026\t  2.635%\t 74.890%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                                 CONV_2D\t    0.018\t    0.016\t  1.648%\t 76.538%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:11\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.010\t    0.011\t  1.125%\t 77.663%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:12\n",
      "\t                                 CONV_2D\t    0.015\t    0.012\t  1.255%\t 78.918%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:13\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.017\t    0.017\t  1.721%\t 80.638%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:14\n",
      "\t                                 CONV_2D\t    0.014\t    0.014\t  1.485%\t 82.124%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:15\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.018\t    0.016\t  1.673%\t 83.797%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:16\n",
      "\t                                 CONV_2D\t    0.012\t    0.013\t  1.374%\t 85.171%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:17\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.017\t    0.015\t  1.571%\t 86.741%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:18\n",
      "\t                                 CONV_2D\t    0.013\t    0.013\t  1.364%\t 88.105%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:19\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.016\t    0.015\t  1.571%\t 89.676%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:20\n",
      "\t                                 CONV_2D\t    0.014\t    0.013\t  1.332%\t 91.008%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:21\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.016\t    0.016\t  1.663%\t 92.671%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:22\n",
      "\t                                 CONV_2D\t    0.014\t    0.013\t  1.363%\t 94.034%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:23\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.006\t    0.007\t  0.677%\t 94.711%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:24\n",
      "\t                                 CONV_2D\t    0.017\t    0.015\t  1.497%\t 96.208%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:25\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.009\t    0.010\t  1.035%\t 97.242%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:26\n",
      "\t                                 CONV_2D\t    0.018\t    0.015\t  1.532%\t 98.775%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:27\n",
      "\t                         AVERAGE_POOL_2D\t    0.004\t    0.004\t  0.386%\t 99.160%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                                 RESHAPE\t    0.002\t    0.001\t  0.103%\t 99.264%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:29\n",
      "\t                         FULLY_CONNECTED\t    0.005\t    0.004\t  0.401%\t 99.665%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:30\n",
      "\t                                 SOFTMAX\t    0.001\t    0.002\t  0.178%\t 99.843%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.002\t    0.002\t  0.157%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.351\t    0.234\t 24.046%\t 24.046%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.140\t    0.124\t 12.757%\t 36.802%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                                 CONV_2D\t    0.117\t    0.090\t  9.212%\t 46.015%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.076\t    0.082\t  8.427%\t 54.441%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.034\t    0.041\t  4.192%\t 58.634%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.034\t    0.041\t  4.166%\t 62.799%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.043\t    0.033\t  3.420%\t 66.219%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.022\t    0.026\t  2.635%\t 68.854%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                                 CONV_2D\t    0.024\t    0.024\t  2.508%\t 71.362%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.017\t    0.018\t  1.886%\t 73.249%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                                 CONV_2D\t       14\t     0.406\t    42.380%\t    42.380%\t     0.000\t       14\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.309\t    32.255%\t    74.635%\t     0.000\t       13\n",
      "\t                                QUANTIZE\t        2\t     0.235\t    24.530%\t    99.165%\t     0.000\t        2\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.003\t     0.313%\t    99.478%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.003\t     0.313%\t    99.791%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.001\t     0.104%\t    99.896%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.001\t     0.104%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=886 first=1136 curr=536 min=455 max=3365 avg=974.146 std=322\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite]\n",
      "INFO: Enable op profiling: [1]\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Use gpu: [1]\n",
      "INFO: Use xnnpack: [0]\n",
      "INFO: Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv1_0.1_96_c3_o2_l5.MV1/mobilenetv1_0.1_96_c3_o2_l5.MV1_INT8.tflite\n",
      "WARN: The GPU delegate compile options are only supported on Android or iOS platforms or when the tool was built with -DCL_DELEGATE_NO_GL.\n",
      "WARN: GPU acceleration is unsupported on this platform.\n",
      "INFO: The input model file size (MB): 0.087176\n",
      "INFO: Initialized session in 6.479ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=459 first=885 curr=684 min=669 max=2458 avg=1084.69 std=339\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=823 first=765 curr=1011 min=681 max=10395 avg=1133.85 std=467\n",
      "\n",
      "INFO: Inference timings in us: Init: 6479, First inference: 885, Warmup (avg): 1084.69, Inference (avg): 1133.85\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0.1875 overall=0.1875\n",
      "INFO: Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.098\t    0.098\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                         AllocateTensors\t    0.098\t    0.098\t100.000%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 1\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                         AllocateTensors\t        1\t     0.098\t   100.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=98\n",
      "Memory (bytes): count=0\n",
      "1 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.106\t    0.157\t 14.266%\t 14.266%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.103\t    0.153\t 13.904%\t 28.169%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.115\t    0.176\t 15.951%\t 44.120%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                 CONV_2D\t    0.047\t    0.067\t  6.060%\t 50.180%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.048\t    0.075\t  6.782%\t 56.962%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                                 CONV_2D\t    0.017\t    0.025\t  2.265%\t 59.227%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.047\t    0.073\t  6.616%\t 65.844%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.017\t    0.026\t  2.349%\t 68.193%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.019\t    0.030\t  2.700%\t 70.893%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.007\t    0.012\t  1.079%\t 71.972%\t     0.000\t        1\t[mobilenetv1/re_lu_8/Relu;mobilenetv1/batch_normalization_91/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_88/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_88/Conv2D]:9\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.028\t    0.046\t  4.146%\t 76.117%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                                 CONV_2D\t    0.010\t    0.016\t  1.463%\t 77.581%\t     0.000\t        1\t[mobilenetv1/re_lu_10/Relu;mobilenetv1/batch_normalization_93/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_89/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/conv2d_89/Conv2D]:11\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.008\t    0.013\t  1.189%\t 78.770%\t     0.000\t        1\t[mobilenetv1/re_lu_11/Relu;mobilenetv1/batch_normalization_94/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_69/depthwise;mobilenetv1/depthwise_conv2d_69/BiasAdd]:12\n",
      "\t                                 CONV_2D\t    0.006\t    0.009\t  0.820%\t 79.590%\t     0.000\t        1\t[mobilenetv1/re_lu_12/Relu;mobilenetv1/batch_normalization_95/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_90/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_90/Conv2D]:13\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.015\t    0.022\t  2.032%\t 81.622%\t     0.000\t        1\t[mobilenetv1/re_lu_13/Relu;mobilenetv1/batch_normalization_96/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_70/depthwise;mobilenetv1/depthwise_conv2d_70/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:14\n",
      "\t                                 CONV_2D\t    0.008\t    0.012\t  1.134%\t 82.756%\t     0.000\t        1\t[mobilenetv1/re_lu_14/Relu;mobilenetv1/batch_normalization_97/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_91/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_91/Conv2D]:15\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.014\t    0.022\t  2.006%\t 84.762%\t     0.000\t        1\t[mobilenetv1/re_lu_15/Relu;mobilenetv1/batch_normalization_98/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_71/depthwise;mobilenetv1/depthwise_conv2d_71/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:16\n",
      "\t                                 CONV_2D\t    0.008\t    0.012\t  1.090%\t 85.852%\t     0.000\t        1\t[mobilenetv1/re_lu_16/Relu;mobilenetv1/batch_normalization_99/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_92/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_92/Conv2D]:17\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.014\t    0.022\t  1.990%\t 87.842%\t     0.000\t        1\t[mobilenetv1/re_lu_17/Relu;mobilenetv1/batch_normalization_100/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_72/depthwise;mobilenetv1/depthwise_conv2d_72/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:18\n",
      "\t                                 CONV_2D\t    0.020\t    0.012\t  1.104%\t 88.946%\t     0.000\t        1\t[mobilenetv1/re_lu_18/Relu;mobilenetv1/batch_normalization_101/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_93/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_93/Conv2D]:19\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.016\t    0.022\t  1.956%\t 90.902%\t     0.000\t        1\t[mobilenetv1/re_lu_19/Relu;mobilenetv1/batch_normalization_102/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_73/depthwise;mobilenetv1/depthwise_conv2d_73/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:20\n",
      "\t                                 CONV_2D\t    0.009\t    0.012\t  1.069%\t 91.971%\t     0.000\t        1\t[mobilenetv1/re_lu_20/Relu;mobilenetv1/batch_normalization_103/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_94/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_94/Conv2D]:21\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.014\t    0.021\t  1.939%\t 93.910%\t     0.000\t        1\t[mobilenetv1/re_lu_21/Relu;mobilenetv1/batch_normalization_104/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_74/depthwise;mobilenetv1/depthwise_conv2d_74/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3]:22\n",
      "\t                                 CONV_2D\t    0.008\t    0.012\t  1.076%\t 94.986%\t     0.000\t        1\t[mobilenetv1/re_lu_22/Relu;mobilenetv1/batch_normalization_105/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_95/BiasAdd;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/conv2d_95/Conv2D]:23\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.004\t    0.007\t  0.651%\t 95.637%\t     0.000\t        1\t[mobilenetv1/re_lu_23/Relu;mobilenetv1/batch_normalization_106/FusedBatchNormV3;mobilenetv1/batch_normalization_100/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_75/depthwise;mobilenetv1/depthwise_conv2d_75/BiasAdd]:24\n",
      "\t                                 CONV_2D\t    0.007\t    0.011\t  0.973%\t 96.609%\t     0.000\t        1\t[mobilenetv1/re_lu_24/Relu;mobilenetv1/batch_normalization_107/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_96/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/conv2d_96/Conv2D]:25\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.007\t    0.012\t  1.059%\t 97.668%\t     0.000\t        1\t[mobilenetv1/re_lu_25/Relu;mobilenetv1/batch_normalization_108/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_76/depthwise;mobilenetv1/depthwise_conv2d_76/BiasAdd;mobilenetv1/batch_normalization_109/FusedBatchNormV3]:26\n",
      "\t                                 CONV_2D\t    0.010\t    0.017\t  1.511%\t 99.179%\t     0.000\t        1\t[mobilenetv1/re_lu_26/Relu;mobilenetv1/batch_normalization_109/FusedBatchNormV3;mobilenetv1/batch_normalization_107/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_97/BiasAdd;mobilenetv1/conv2d_97/Conv2D]:27\n",
      "\t                         AVERAGE_POOL_2D\t    0.001\t    0.002\t  0.224%\t 99.403%\t     0.000\t        1\t[mobilenetv1/average_pooling2d/AvgPool]:28\n",
      "\t                                 RESHAPE\t    0.000\t    0.001\t  0.077%\t 99.480%\t     0.000\t        1\t[mobilenetv1/flatten/Reshape]:29\n",
      "\t                         FULLY_CONNECTED\t    0.002\t    0.003\t  0.281%\t 99.761%\t     0.000\t        1\t[mobilenetv1/dense/MatMul;mobilenetv1/dense/BiasAdd]:30\n",
      "\t                                 SOFTMAX\t    0.001\t    0.001\t  0.131%\t 99.892%\t     0.000\t        1\t[StatefulPartitionedCall:01]:31\n",
      "\t                                QUANTIZE\t    0.001\t    0.001\t  0.108%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:32\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.115\t    0.176\t 15.951%\t 15.951%\t     0.000\t        1\t[mobilenetv1/re_lu_1/Relu;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_64/depthwise;mobilenetv1/depthwise_conv2d_64/BiasAdd]:2\n",
      "\t                                QUANTIZE\t    0.106\t    0.157\t 14.266%\t 30.217%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t                                 CONV_2D\t    0.103\t    0.153\t 13.904%\t 44.120%\t     0.000\t        1\t[mobilenetv1/re_lu/Relu;mobilenetv1/batch_normalization_83/FusedBatchNormV3;mobilenetv1/batch_normalization_83/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_84/BiasAdd;mobilenetv1/batch_normalization_84/FusedBatchNormV3;mobilenetv1/conv2d_84/Conv2D]:1\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.048\t    0.075\t  6.782%\t 50.903%\t     0.000\t        1\t[mobilenetv1/re_lu_3/Relu;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_65/depthwise;mobilenetv1/depthwise_conv2d_65/BiasAdd]:4\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.047\t    0.073\t  6.616%\t 57.519%\t     0.000\t        1\t[mobilenetv1/re_lu_5/Relu;mobilenetv1/batch_normalization_88/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_66/depthwise;mobilenetv1/depthwise_conv2d_66/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3]:6\n",
      "\t                                 CONV_2D\t    0.047\t    0.067\t  6.060%\t 63.579%\t     0.000\t        1\t[mobilenetv1/re_lu_2/Relu;mobilenetv1/batch_normalization_85/FusedBatchNormV3;mobilenetv1/batch_normalization_85/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_85/BiasAdd;mobilenetv1/batch_normalization_86/FusedBatchNormV3;mobilenetv1/conv2d_85/Conv2D]:3\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.028\t    0.046\t  4.146%\t 67.725%\t     0.000\t        1\t[mobilenetv1/re_lu_9/Relu;mobilenetv1/batch_normalization_92/FusedBatchNormV3;mobilenetv1/batch_normalization_91/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_68/depthwise;mobilenetv1/depthwise_conv2d_68/BiasAdd;mobilenetv1/batch_normalization_94/FusedBatchNormV3]:10\n",
      "\t                       DEPTHWISE_CONV_2D\t    0.019\t    0.030\t  2.700%\t 70.424%\t     0.000\t        1\t[mobilenetv1/re_lu_7/Relu;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/depthwise_conv2d_67/depthwise;mobilenetv1/depthwise_conv2d_67/BiasAdd]:8\n",
      "\t                                 CONV_2D\t    0.017\t    0.026\t  2.349%\t 72.774%\t     0.000\t        1\t[mobilenetv1/re_lu_6/Relu;mobilenetv1/batch_normalization_89/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_87/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_87/Conv2D]:7\n",
      "\t                                 CONV_2D\t    0.017\t    0.025\t  2.265%\t 75.039%\t     0.000\t        1\t[mobilenetv1/re_lu_4/Relu;mobilenetv1/batch_normalization_87/FusedBatchNormV3;mobilenetv1/batch_normalization_87/FusedBatchNormV3/ReadVariableOp;mobilenetv1/conv2d_86/BiasAdd;mobilenetv1/batch_normalization_90/FusedBatchNormV3;mobilenetv1/conv2d_86/Conv2D]:5\n",
      "\n",
      "Number of nodes executed: 33\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                       DEPTHWISE_CONV_2D\t       13\t     0.533\t    49.124%\t    49.124%\t     0.000\t       13\n",
      "\t                                 CONV_2D\t       14\t     0.388\t    35.760%\t    84.885%\t     0.000\t       14\n",
      "\t                                QUANTIZE\t        2\t     0.158\t    14.562%\t    99.447%\t     0.000\t        2\n",
      "\t                         FULLY_CONNECTED\t        1\t     0.003\t     0.276%\t    99.724%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.002\t     0.184%\t    99.908%\t     0.000\t        1\n",
      "\t                                 SOFTMAX\t        1\t     0.001\t     0.092%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=823 first=737 curr=974 min=660 max=10340 avg=1100.95 std=462\n",
      "Memory (bytes): count=0\n",
      "33 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "INFO: \n",
      "==============Summary of All Runs w/ Different Performance Options==============\n",
      "INFO: cpu w/ 1 threads (xnnpack): count=2255 first=322 curr=377 min=299 max=2076 avg=417.467 std=109\n",
      "INFO: cpu w/ 2 threads (xnnpack): count=1994 first=303 curr=323 min=292 max=2453 avg=464.517 std=140\n",
      "INFO: cpu w/ 4 threads (xnnpack): count=1966 first=441 curr=553 min=264 max=3130 avg=469.019 std=189\n",
      "INFO:           cpu w/ 2 threads: count=1144 first=1171 curr=1241 min=496 max=3022 avg=800.951 std=267\n",
      "INFO:           cpu w/ 4 threads: count=886 first=1191 curr=558 min=476 max=3416 avg=1013.88 std=332\n",
      "INFO:           cpu w/ 1 threads: count=867 first=2148 curr=1349 min=668 max=2552 avg=1077.55 std=292\n",
      "INFO:                gpu-default: count=823 first=765 curr=1011 min=681 max=10395 avg=1133.85 std=467\n"
     ]
    }
   ],
   "source": [
    "! ./benchmarking/linux_x86-64_benchmark_model_performance_options \\\n",
    "    --graph=$models_tflite_opt_path \\\n",
    "    --num_threads=1 \\\n",
    "    --enable_op_profiling=true \\\n",
    "    | tee $models_benchmark_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING!\n",
      "Log parameter values verbosely: [0]\n",
      "Num threads: [1]\n",
      "Graph: [/mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv2_0.25_96_c3_o2_t5l512.MV1/mobilenetv2_0.25_96_c3_o2_t5l512.MV1_INT8.tflite]\n",
      "Enable op profiling: [1]\n",
      "#threads used for CPU inference: [1]\n",
      "Loaded model /mnt/c/tiny_mlc/tiny_cnn/models/mobilenetv2_0.25_96_c3_o2_t5l512.MV1/mobilenetv2_0.25_96_c3_o2_t5l512.MV1_INT8.tflite\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "The input model file size (MB): 0.282144\n",
      "Initialized session in 120.179ms.\n",
      "Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "count=736 first=3866 curr=782 min=435 max=4658 avg=676.192 std=332\n",
      "\n",
      "Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "count=1750 first=851 curr=652 min=452 max=1421 avg=536.384 std=133\n",
      "\n",
      "Inference timings in us: Init: 120179, First inference: 3866, Warmup (avg): 676.192, Inference (avg): 536.384\n",
      "Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "Memory footprint delta from the start of the tool (MB): init=3.6875 overall=4.30469\n",
      "Profiling Info for Benchmark Initialization:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    7.477\t    7.477\t 99.455%\t 99.455%\t  1132.000\t        1\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.041\t    0.041\t  0.545%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                 ModifyGraphWithDelegate\t    7.477\t    7.477\t 99.455%\t 99.455%\t  1132.000\t        1\tModifyGraphWithDelegate/0\n",
      "\t                         AllocateTensors\t    0.041\t    0.041\t  0.545%\t100.000%\t     0.000\t        1\tAllocateTensors/0\n",
      "\n",
      "Number of nodes executed: 2\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t                 ModifyGraphWithDelegate\t        1\t     7.477\t    99.455%\t    99.455%\t  1132.000\t        1\n",
      "\t                         AllocateTensors\t        1\t     0.041\t     0.545%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1 curr=7518\n",
      "Memory (bytes): count=0\n",
      "2 nodes observed\n",
      "\n",
      "\n",
      "\n",
      "Operator-wise Profiling Info for Regular Benchmark Runs:\n",
      "============================== Run Order ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.189\t    0.107\t 22.194%\t 22.194%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.071\t    0.048\t  9.950%\t 32.144%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.097\t    0.037\t  7.747%\t 39.891%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.025\t    0.017\t  3.582%\t 43.472%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.052\t    0.039\t  7.980%\t 51.452%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:3\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.031\t    0.022\t  4.562%\t 56.014%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:4\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.009\t    0.006\t  1.263%\t 57.278%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:5\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.017\t    0.013\t  2.613%\t 59.890%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.039\t    0.027\t  5.586%\t 65.476%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.010\t    0.007\t  1.441%\t 66.918%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:8\n",
      "\t                           Add (ND, QS8)\t    0.001\t    0.001\t  0.225%\t 67.142%\t     0.000\t        1\tDelegate/Add (ND, QS8):9\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.026\t    0.013\t  2.668%\t 69.810%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.010\t    0.007\t  1.458%\t 71.268%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:11\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.002\t  0.328%\t 71.596%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:12\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.004\t  0.735%\t 72.331%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:13\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.012\t    0.008\t  1.741%\t 74.072%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:14\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.450%\t 74.523%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:15\n",
      "\t                           Add (ND, QS8)\t    0.001\t    0.000\t  0.033%\t 74.556%\t     0.000\t        1\tDelegate/Add (ND, QS8):16\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.004\t  0.759%\t 75.314%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:17\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.012\t    0.008\t  1.751%\t 77.066%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:18\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.451%\t 77.517%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:19\n",
      "\t                           Add (ND, QS8)\t    0.001\t    0.000\t  0.025%\t 77.541%\t     0.000\t        1\tDelegate/Add (ND, QS8):20\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.004\t  0.743%\t 78.284%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:21\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.002\t  0.483%\t 78.767%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:22\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.001\t    0.001\t  0.226%\t 78.993%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:23\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.479%\t 79.471%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:24\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.006\t    0.004\t  0.823%\t 80.295%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:25\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.001\t  0.261%\t 80.556%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:26\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.008%\t 80.564%\t     0.000\t        1\tDelegate/Add (ND, QS8):27\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.002\t  0.485%\t 81.048%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:28\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.004\t  0.832%\t 81.881%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:29\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.001\t  0.257%\t 82.138%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:30\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.013%\t 82.152%\t     0.000\t        1\tDelegate/Add (ND, QS8):31\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.481%\t 82.632%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:32\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.004\t  0.832%\t 83.464%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:33\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.001\t  0.264%\t 83.728%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:34\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.018%\t 83.746%\t     0.000\t        1\tDelegate/Add (ND, QS8):35\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.472%\t 84.218%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:36\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.005\t    0.004\t  0.830%\t 85.047%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:37\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.460%\t 85.507%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:38\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.004\t  0.819%\t 86.326%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:39\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.006\t  1.222%\t 87.547%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:40\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  0.528%\t 88.075%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:41\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.016%\t 88.091%\t     0.000\t        1\tDelegate/Add (ND, QS8):42\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.004\t  0.841%\t 88.932%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:43\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.008\t    0.006\t  1.222%\t 90.154%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:44\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.002\t  0.505%\t 90.660%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:45\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.016%\t 90.675%\t     0.000\t        1\tDelegate/Add (ND, QS8):46\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.006\t    0.004\t  0.830%\t 91.505%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:47\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.001\t  0.306%\t 91.811%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:48\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.002\t    0.001\t  0.246%\t 92.058%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:49\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.003\t  0.531%\t 92.589%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:50\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.004\t    0.002\t  0.505%\t 93.094%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:51\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.352%\t 93.445%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:52\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.006%\t 93.452%\t     0.000\t        1\tDelegate/Add (ND, QS8):53\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.004\t    0.002\t  0.504%\t 93.955%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:54\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.003\t  0.517%\t 94.473%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:55\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.324%\t 94.796%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:56\n",
      "\t                           Add (ND, QS8)\t    0.000\t    0.000\t  0.010%\t 94.806%\t     0.000\t        1\tDelegate/Add (ND, QS8):57\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.003\t    0.002\t  0.516%\t 95.322%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:58\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.003\t    0.002\t  0.500%\t 95.822%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:59\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.005\t    0.004\t  0.738%\t 96.560%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:60\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.014\t    0.011\t  2.193%\t 98.753%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:61\n",
      "\t                         AVERAGE_POOL_2D\t    0.006\t    0.004\t  0.760%\t 99.514%\t     0.000\t        1\t[mobilenetv2/average_pooling2d/AvgPool]:63\n",
      "\t                                 RESHAPE\t    0.002\t    0.001\t  0.120%\t 99.634%\t     0.000\t        1\t[mobilenetv2/flatten/Reshape]:64\n",
      "\t          Fully Connected (NC, QS8) GEMM\t    0.001\t    0.000\t  0.035%\t 99.668%\t     0.000\t        1\tDelegate/Fully Connected (NC, QS8) GEMM:0\n",
      "\t                                 SOFTMAX\t    0.002\t    0.001\t  0.165%\t 99.834%\t     0.000\t        1\t[StatefulPartitionedCall:01]:66\n",
      "\t                                QUANTIZE\t    0.001\t    0.001\t  0.166%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:67\n",
      "\n",
      "============================== Top by Computation Time ==============================\n",
      "\t                             [node type]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\n",
      "\t                                QUANTIZE\t    0.189\t    0.107\t 22.194%\t 22.194%\t     0.000\t        1\t[tfl.quantize]:0\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t    0.071\t    0.048\t  9.950%\t 32.144%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) IGEMM:0\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.052\t    0.039\t  7.980%\t 40.124%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:3\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.097\t    0.037\t  7.747%\t 47.871%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:1\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.039\t    0.027\t  5.586%\t 53.457%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:7\n",
      "\t          Convolution (NHWC, QC8) DWConv\t    0.031\t    0.022\t  4.562%\t 58.019%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) DWConv:4\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.025\t    0.017\t  3.582%\t 61.600%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:2\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.026\t    0.013\t  2.668%\t 64.268%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:10\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.017\t    0.013\t  2.613%\t 66.881%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:6\n",
      "\t            Convolution (NHWC, QC8) GEMM\t    0.014\t    0.011\t  2.193%\t 69.074%\t     0.000\t        1\tDelegate/Convolution (NHWC, QC8) GEMM:61\n",
      "\n",
      "Number of nodes executed: 68\n",
      "============================== Summary by node type ==============================\n",
      "\t                             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\n",
      "\t            Convolution (NHWC, QC8) GEMM\t       34\t     0.156\t    34.061%\t    34.061%\t     0.000\t       34\n",
      "\t          Convolution (NHWC, QC8) DWConv\t       17\t     0.143\t    31.223%\t    65.284%\t     0.000\t       17\n",
      "\t                                QUANTIZE\t        2\t     0.107\t    23.362%\t    88.646%\t     0.000\t        2\n",
      "\t           Convolution (NHWC, QC8) IGEMM\t        1\t     0.048\t    10.480%\t    99.127%\t     0.000\t        1\n",
      "\t                         AVERAGE_POOL_2D\t        1\t     0.003\t     0.655%\t    99.782%\t     0.000\t        1\n",
      "\t                           Add (ND, QS8)\t       10\t     0.001\t     0.218%\t   100.000%\t     0.000\t       10\n",
      "\t                                 SOFTMAX\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t                                 RESHAPE\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\t          Fully Connected (NC, QS8) GEMM\t        1\t     0.000\t     0.000%\t   100.000%\t     0.000\t        1\n",
      "\n",
      "Timings (microseconds): count=1750 first=778 curr=598 min=404 max=1345 avg=483.398 std=127\n",
      "Memory (bytes): count=0\n",
      "68 nodes observed\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ./benchmarking/linux_x86-64_benchmark_model \\\n",
    "    --graph=$models_tflite_opt_path \\\n",
    "    --num_threads=1 \\\n",
    "    --enable_op_profiling=true \\\n",
    "    | tee $models_benchmark_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if automated == False:\n",
    "    ! code $models_benchmark_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the tensor arena size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/tiny_mlc/tflite-find-arena-size/build/find-arena-size')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_size_path = Path.cwd().parent.joinpath(\"tflite-find-arena-size\",\"build\",  \"find-arena-size\")\n",
    "arena_size_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture arena_size\n",
    "! $arena_size_path $models_tflite_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture optimal_runtime_INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edge-impulse-sdk/tensorflow/lite/micro/kernels/quantize.cc:68 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 || input->type == kTfLiteInt8 was not true.\\r\\r\\nNode QUANTIZE (number 0f) failed to prepare with status 1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_size_raw = arena_size.stdout.strip()\n",
    "arena_size_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ast\n",
    "    arena_size_dict = ast.literal_eval(arena_size_raw)\n",
    "    arena_size = arena_size_dict[\"arena_size\"]\n",
    "    arena_size\n",
    "except:\n",
    "    arena_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h2ee651d'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = get_model_DB_run_id_from_architecture(model_name)\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/tiny_mlc/tiny_cnn/wandb/run-20230317_164128-h2ee651d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/susbrock/model_DB/runs/h2ee651d\" target=\"_blank\">mobilenetv2_0.25_96_c3_o2_t5l512.MV1</a></strong> to <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">https://wandb.ai/susbrock/model_DB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/susbrock/model_DB/runs/h2ee651d\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/h2ee651d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>arena_size</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>allocate_tensors_ms_%</td><td>0.491</td></tr><tr><td>allocate_tensors_ms_avg</td><td>0.033</td></tr><tr><td>allocate_tensors_ms_first</td><td>0.033</td></tr><tr><td>arena_size</td><td>285664</td></tr><tr><td>first_inference_us</td><td>3787</td></tr><tr><td>inference_avg_us</td><td>486.023</td></tr><tr><td>init_us</td><td>133940</td></tr><tr><td>initialization_ms</td><td>133.94</td></tr><tr><td>model_size_MB</td><td>0.28214</td></tr><tr><td>modify_graph_with_delegate_mem_KB</td><td>1164</td></tr><tr><td>modify_graph_with_delegate_ms_%</td><td>99.509</td></tr><tr><td>modify_graph_with_delegate_ms_avg</td><td>6.688</td></tr><tr><td>modify_graph_with_delegate_ms_first</td><td>6.688</td></tr><tr><td>warmup_avg_us</td><td>536.022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mobilenetv2_0.25_96_c3_o2_t5l512.MV1</strong> at: <a href=\"https://wandb.ai/susbrock/model_DB/runs/h2ee651d\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/h2ee651d</a><br/>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_164128-h2ee651d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(run_id) > 1:\n",
    "\n",
    "        PROJECT = \"model_DB\"\n",
    "\n",
    "        run = wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=PROJECT, \n",
    "                id = run_id, \n",
    "                resume=\"allow\",\n",
    "                )\n",
    "\n",
    "        run.log({\"arena_size\" : arena_size})\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "else:\n",
    "        print(f\"Could not find run_id {run_id}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from contextlib import redirect_stdout\n",
    "\n",
    "# with open(\"runtime.txt\", \"w\", encoding='utf-8') as f:\n",
    "#     with redirect_stdout(f):\n",
    "#         print(profile_model(str(models_tflite_opt_path), accelerator=None, build=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faa6c31b20b8f809b81d6d7d22a84ccd9f354666f54133d1793fa4c65539801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
