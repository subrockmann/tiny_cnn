{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, datetime, signal\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,DepthwiseConv2D, MaxPooling2D, AvgPool2D, GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "# from tensorflow.keras.layers import ReLU\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    " \n",
    "# Import the necessary MLTK APIs\n",
    "from mltk.core import view_model, summarize_model, profile_model\n",
    "\n",
    "# import workbench.config.config\n",
    "from workbench.config.config import initialize\n",
    "from workbench.utils.utils import create_filepaths, get_file_size\n",
    "from workbench.utils.utils import parse_model_name, parse_mltk_model_summary\n",
    "from workbench.data.data import get_lemon_quality_dataset\n",
    "from workbench.tflite_profiling import get_peak_memory_df, get_tensor_details_df\n",
    "from workbench.tensorflow import get_layer_details_df\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "#import deeplake\n",
    "\n",
    "%load_ext autoreload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "automated = False\n",
    "\n",
    "global model_name\n",
    "\n",
    "model_name = \"mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name, alpha, resolution, channels, classes, variation = model_name.split(\"_\")\n",
    "alpha = float(alpha)\n",
    "resolution = int(resolution)\n",
    "classes = int(classes.strip(\"o\"))\n",
    "channels = int(channels.strip(\"c\"))\n",
    "PROJECT = \"model_DB\"\n",
    "\n",
    "# just needed for INT 8 quantization:\n",
    "BATCH_SIZE = 32\n",
    "shuffle_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\tiny_mlc\\tiny_cnn\\models\n"
     ]
    }
   ],
   "source": [
    "models_path, models_summary_path, models_image_path, models_layer_df_path, models_tf_path, models_tflite_path, models_tflite_opt_path = create_filepaths(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(models_tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_model(model, tflite=True, build=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse model parameters from MLTK summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, trainable_params, non_trainable_params, MACs, FLOPs = parse_mltk_model_summary(models_summary_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltk_model_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltk_model_stats[\"MACs\"] = MACs\n",
    "mltk_model_stats[\"FLOPs\"] = FLOPs\n",
    "mltk_model_stats[\"total_params\"] = total_params\n",
    "mltk_model_stats[\"trainable_params\"] = trainable_params\n",
    "mltk_model_stats[\"non_trainable_params\"] = non_trainable_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating tflite Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Susanne\\AppData\\Local\\Temp\\tmps9qaapus\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Susanne\\AppData\\Local\\Temp\\tmps9qaapus\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "#converter = tf.lite.TFLiteConverter.from_saved_model(models_path)\n",
    "tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.Y\n",
    "with open(models_tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size in bytes is 746912\n",
      "File size in kilobytes is 729.40625\n",
      "File size in bytes is 287568\n",
      "File size in kilobytes is 280.828125\n"
     ]
    }
   ],
   "source": [
    "mltk_model_stats[\"model_size_kb\"] = get_file_size(models_tf_path)\n",
    "mltk_model_stats[\"tflite_model_size_kb\"] = get_file_size(models_tflite_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tflite with INT8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"lemon_dataset\")\n",
    "dataset_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color mode: rgb\n",
      "Preparing training dataset...\n",
      "Found 2021 files belonging to 3 classes.\n",
      "Preparing validation dataset...\n",
      "Found 252 files belonging to 3 classes.\n",
      "Preparing test dataset...\n",
      "Found 255 files belonging to 3 classes.\n",
      "Class names: ['bad_quality', 'empty_background', 'good_quality']\n",
      "Train: (TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "Normalize: True\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds, labels = get_lemon_quality_dataset(dataset_path, resolution, resolution, BATCH_SIZE, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Susanne\\AppData\\Local\\Temp\\tmpyd0nim55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Susanne\\AppData\\Local\\Temp\\tmpyd0nim55\\assets\n",
      "d:\\Miniconda\\envs\\tiny_cnn_6\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/tiny_mlc/tiny_cnn/models/mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1/mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1_INT8.tflite')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr_ds = test_ds.unbatch()\n",
    "\n",
    "def representative_data_gen():\n",
    "  for i_value, o_value in repr_ds.batch(1).take(48):\n",
    "    yield [i_value]\n",
    "    \n",
    "converter_opt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# set the optimization flag\n",
    "converter_opt.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# enforce integer only quantization\n",
    "converter_opt.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "\n",
    "# https://github.com/tensorflow/tensorflow/issues/53293: uint is no longer supported!\n",
    "#converter_opt.inference_input_type = tf.uint8\n",
    "#converter_opt.inference_output_type = tf.uint8\n",
    "converter_opt.inference_input_type = tf.int8\n",
    "converter_opt.inference_output_type = tf.int8\n",
    "\n",
    "# provide a representative dataset for quantization\n",
    "converter_opt.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_opt = converter_opt.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(models_tflite_opt_path, 'wb') as f:\n",
    "  f.write(tflite_model_opt)\n",
    "models_tflite_opt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size in bytes is 196664\n",
      "File size in kilobytes is 192.0546875\n"
     ]
    }
   ],
   "source": [
    "mltk_model_stats[\"tflite_model_INT8_size_kb\"] = get_file_size(models_tflite_opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size in bytes is 287568\n",
      "File size in kilobytes is 280.828125\n"
     ]
    }
   ],
   "source": [
    "mltk_model_stats[\"tflite_model_size_kb\"] = get_file_size(models_tflite_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Analytics from TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in c:\\tiny_mlc\\tiny_cnn\\models\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1_layers.csv\n"
     ]
    }
   ],
   "source": [
    "layer_details_csv_exists = True\n",
    "try:\n",
    "    layer_details_df = get_layer_details_df(models_layer_df_path)\n",
    "    layer_details_df\n",
    "except:\n",
    "    layer_details_csv_exists = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting peak memory infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_peak_memory_path = models_dir.joinpath(model_name, f\"{model_name}_peak_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model analysis to c:\\tiny_mlc\\tiny_cnn\\models\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1_peak_memory in CSV format\n"
     ]
    }
   ],
   "source": [
    "#! python i:\\tinyml\\tflite-tools\\tflite_tools.py -i $models_tflite_opt_path --csv $models_peak_memory_path\n",
    "! python c:\\tiny_mlc\\tflite-tools\\tflite_tools.py -i $models_tflite_opt_path --csv $models_peak_memory_path\n",
    "#! explorer $models_peak_memory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_peak_memory_schedule = models_dir.joinpath(model_name, f\"{model_name}_peak_memory\", \"execution_schedule_info.csv\")\n",
    "peak_memory_tensor_details = models_dir.joinpath(model_name, f\"{model_name}_peak_memory\", \"tensor_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in c:\\tiny_mlc\\tiny_cnn\\models\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1_peak_memory\\execution_schedule_info.csv\n",
      "Cleaning up the dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>tensor_IDs</th>\n",
       "      <th>RAM_b</th>\n",
       "      <th>operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>block_0_expand_conv2d</td>\n",
       "      <td>(0, 131)</td>\n",
       "      <td>64512</td>\n",
       "      <td>mobilenetv3smallSQ/block_0_expand_bn/FusedBatc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tf.math.multiply_27</td>\n",
       "      <td>(131, 132)</td>\n",
       "      <td>73728</td>\n",
       "      <td>mobilenetv3smallSQ/tf.math.multiply_27/Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tf.math.add_27</td>\n",
       "      <td>(131, 132, 133)</td>\n",
       "      <td>110592</td>\n",
       "      <td>mobilenetv3smallSQ/tf.math.add_27/Add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tf.clip_by_value_27</td>\n",
       "      <td>(131, 133, 134)</td>\n",
       "      <td>110592</td>\n",
       "      <td>mobilenetv3smallSQ/tf.clip_by_value_27/clip_by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tf.clip_by_value_27</td>\n",
       "      <td>(131, 134, 135)</td>\n",
       "      <td>110592</td>\n",
       "      <td>mobilenetv3smallSQ/tf.clip_by_value_27/clip_by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>multiply_27</td>\n",
       "      <td>(131, 135, 136)</td>\n",
       "      <td>110592</td>\n",
       "      <td>mobilenetv3smallSQ/multiply_27/mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>block_1_expand_conv2d</td>\n",
       "      <td>(136, 137)</td>\n",
       "      <td>73728</td>\n",
       "      <td>mobilenetv3smallSQ/tf.nn.relu6_6/Relu6;mobilen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>batch_normalization_366</td>\n",
       "      <td>(137, 138)</td>\n",
       "      <td>73728</td>\n",
       "      <td>mobilenetv3smallSQ/tf.nn.relu6_7/Relu6;mobilen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>conv2d_95</td>\n",
       "      <td>(138, 139)</td>\n",
       "      <td>55296</td>\n",
       "      <td>mobilenetv3smallSQ/batch_normalization_346/Fus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>block_2_expand_conv2d</td>\n",
       "      <td>(139, 140)</td>\n",
       "      <td>110592</td>\n",
       "      <td>mobilenetv3smallSQ/tf.nn.relu6_8/Relu6;mobilen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index               layer_name       tensor_IDs   RAM_b  \\\n",
       "0      0    block_0_expand_conv2d         (0, 131)   64512   \n",
       "1      1      tf.math.multiply_27       (131, 132)   73728   \n",
       "2      2           tf.math.add_27  (131, 132, 133)  110592   \n",
       "3      3      tf.clip_by_value_27  (131, 133, 134)  110592   \n",
       "4      4      tf.clip_by_value_27  (131, 134, 135)  110592   \n",
       "5      5              multiply_27  (131, 135, 136)  110592   \n",
       "6      6    block_1_expand_conv2d       (136, 137)   73728   \n",
       "7      7  batch_normalization_366       (137, 138)   73728   \n",
       "8      8                conv2d_95       (138, 139)   55296   \n",
       "9      9    block_2_expand_conv2d       (139, 140)  110592   \n",
       "\n",
       "                                            operator  \n",
       "0  mobilenetv3smallSQ/block_0_expand_bn/FusedBatc...  \n",
       "1         mobilenetv3smallSQ/tf.math.multiply_27/Mul  \n",
       "2              mobilenetv3smallSQ/tf.math.add_27/Add  \n",
       "3  mobilenetv3smallSQ/tf.clip_by_value_27/clip_by...  \n",
       "4  mobilenetv3smallSQ/tf.clip_by_value_27/clip_by...  \n",
       "5                 mobilenetv3smallSQ/multiply_27/mul  \n",
       "6  mobilenetv3smallSQ/tf.nn.relu6_6/Relu6;mobilen...  \n",
       "7  mobilenetv3smallSQ/tf.nn.relu6_7/Relu6;mobilen...  \n",
       "8  mobilenetv3smallSQ/batch_normalization_346/Fus...  \n",
       "9  mobilenetv3smallSQ/tf.nn.relu6_8/Relu6;mobilen...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_memory_df = get_peak_memory_df(model_peak_memory_schedule)\n",
    "peak_memory_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113320"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_memory = peak_memory_df[\"RAM_b\"].max()\n",
    "peak_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltk_model_stats[\"peak_memory_b\"] = peak_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_memory_df[\"RAM_b\"].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in c:\\tiny_mlc\\tiny_cnn\\models\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1\\mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1_peak_memory\\tensor_details.csv\n",
      "Cleaning up the dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>shape</th>\n",
       "      <th>size_b</th>\n",
       "      <th>name_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>serving_default_input_2:0</td>\n",
       "      <td>(1, 96, 96, 3)</td>\n",
       "      <td>27648</td>\n",
       "      <td>serving_default_input_2:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>mobilenetv3smallSQ/block_0_expand_conv2d/Conv2D</td>\n",
       "      <td>(1, 48, 48, 16)</td>\n",
       "      <td>36864</td>\n",
       "      <td>mobilenetv3smallSQ/block_0_expand_bn/FusedBatc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>mobilenetv3smallSQ/tf.math.multiply_27/Mul</td>\n",
       "      <td>(1, 48, 48, 16)</td>\n",
       "      <td>36864</td>\n",
       "      <td>tf.math.multiply_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>mobilenetv3smallSQ/tf.math.add_27/Add</td>\n",
       "      <td>(1, 48, 48, 16)</td>\n",
       "      <td>36864</td>\n",
       "      <td>tf.math.add_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>mobilenetv3smallSQ/tf.clip_by_value_27/clip_by...</td>\n",
       "      <td>(1, 48, 48, 16)</td>\n",
       "      <td>36864</td>\n",
       "      <td>tf.clip_by_value_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>496</td>\n",
       "      <td>mobilenetv3smallSQ/multiply_53/mul</td>\n",
       "      <td>(1, 3, 3, 576)</td>\n",
       "      <td>5184</td>\n",
       "      <td>multiply_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>497</td>\n",
       "      <td>mobilenetv3smallSQ/average_pooling2d_1/AvgPool</td>\n",
       "      <td>(1, 1, 1, 576)</td>\n",
       "      <td>576</td>\n",
       "      <td>average_pooling2d_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>368</td>\n",
       "      <td>498</td>\n",
       "      <td>mobilenetv3smallSQ/flatten_1/Reshape</td>\n",
       "      <td>(1, 576)</td>\n",
       "      <td>576</td>\n",
       "      <td>flatten_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>499</td>\n",
       "      <td>mobilenetv3smallSQ/dense_37/BiasAdd</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>2</td>\n",
       "      <td>mobilenetv3smallSQ/dense_37/MatMul;mobilenetv3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>370</td>\n",
       "      <td>500</td>\n",
       "      <td>StatefulPartitionedCall:0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>2</td>\n",
       "      <td>StatefulPartitionedCall:0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   id                                         layer_name  \\\n",
       "0        0    0                          serving_default_input_2:0   \n",
       "1        1  131    mobilenetv3smallSQ/block_0_expand_conv2d/Conv2D   \n",
       "2        2  132         mobilenetv3smallSQ/tf.math.multiply_27/Mul   \n",
       "3        3  133              mobilenetv3smallSQ/tf.math.add_27/Add   \n",
       "4        4  134  mobilenetv3smallSQ/tf.clip_by_value_27/clip_by...   \n",
       "..     ...  ...                                                ...   \n",
       "366    366  496                 mobilenetv3smallSQ/multiply_53/mul   \n",
       "367    367  497     mobilenetv3smallSQ/average_pooling2d_1/AvgPool   \n",
       "368    368  498               mobilenetv3smallSQ/flatten_1/Reshape   \n",
       "369    369  499                mobilenetv3smallSQ/dense_37/BiasAdd   \n",
       "370    370  500                          StatefulPartitionedCall:0   \n",
       "\n",
       "               shape  size_b  \\\n",
       "0     (1, 96, 96, 3)   27648   \n",
       "1    (1, 48, 48, 16)   36864   \n",
       "2    (1, 48, 48, 16)   36864   \n",
       "3    (1, 48, 48, 16)   36864   \n",
       "4    (1, 48, 48, 16)   36864   \n",
       "..               ...     ...   \n",
       "366   (1, 3, 3, 576)    5184   \n",
       "367   (1, 1, 1, 576)     576   \n",
       "368         (1, 576)     576   \n",
       "369           (1, 2)       2   \n",
       "370           (1, 2)       2   \n",
       "\n",
       "                                             name_long  \n",
       "0                            serving_default_input_2:0  \n",
       "1    mobilenetv3smallSQ/block_0_expand_bn/FusedBatc...  \n",
       "2                                  tf.math.multiply_27  \n",
       "3                                       tf.math.add_27  \n",
       "4                                  tf.clip_by_value_27  \n",
       "..                                                 ...  \n",
       "366                                        multiply_53  \n",
       "367                                average_pooling2d_1  \n",
       "368                                          flatten_1  \n",
       "369  mobilenetv3smallSQ/dense_37/MatMul;mobilenetv3...  \n",
       "370                          StatefulPartitionedCall:0  \n",
       "\n",
       "[371 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_df = get_tensor_details_df(peak_memory_tensor_details)\n",
    "tensor_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging to Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msusbrock\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\tiny_mlc\\tiny_cnn\\wandb\\run-20230318_080859-pmwiu34u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/susbrock/model_DB/runs/pmwiu34u\" target=\"_blank\">mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1</a></strong> to <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">https://wandb.ai/susbrock/model_DB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/susbrock/model_DB/runs/pmwiu34u\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/pmwiu34u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1</strong> at: <a href=\"https://wandb.ai/susbrock/model_DB/runs/pmwiu34u\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/pmwiu34u</a><br/>Synced 6 W&B file(s), 3 media file(s), 3 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230318_080859-pmwiu34u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "# Generate run ids\n",
    "run_id = wandb.sdk.lib.runid.generate_id()\n",
    "\n",
    "wandb.init(\n",
    "    project=PROJECT,\n",
    "    entity=\"susbrock\",\n",
    "    name = model_name,\n",
    "    id=run_id,\n",
    "    #resume=True\n",
    "    )\n",
    "\n",
    "config = wandb.config\n",
    "config.id = run_id\n",
    "config.update(mltk_model_stats)\n",
    "\n",
    "# try:\n",
    "#     layers_df_wandb = wandb.Table(dataframe=layers_df)\n",
    "#     wandb.log({\"tflite_layers_mltk\" : layers_df_wandb})\n",
    "#     layers_INT8_df_wandb = wandb.Table(dataframe=layers_INT8_df)\n",
    "#     wandb.log({\"tflite_INt8_layers_mltk\" : layers_INT8_df_wandb})\n",
    "# except:\n",
    "#     print(\"No analysis from mltk!\")\n",
    "\n",
    "peak_memory_df_wandb = wandb.Table(dataframe=peak_memory_df)\n",
    "wandb.log({\"peak_memory\" : peak_memory_df_wandb})\n",
    "\n",
    "tensor_df_wandb = wandb.Table(dataframe=tensor_df)\n",
    "wandb.log({\"tensor_info\" : tensor_df_wandb})\n",
    "\n",
    "if layer_details_csv_exists:\n",
    "    layer_details_df_wandb = wandb.Table(dataframe=layer_details_df)\n",
    "    wandb.log({\"tensorflow_layer_details\" : layer_details_df_wandb})\n",
    "else:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    wandb.log({\"tflite_INt8_layers_plt\" : wandb.plot.bar(layers_INT8_df_wandb, \"index\", \"macs\", title=model_name)})\n",
    "except:\n",
    "    pass\n",
    "wandb.finish()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling tflite models with MLTK profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltk_model_stats[\"architecture\"] = model_name\n",
    "mltk_model_stats[\"alpha\"] = alpha\n",
    "mltk_model_stats[\"img_res\"] = resolution\n",
    "mltk_model_stats[\"classes\"] = classes\n",
    "mltk_model_stats[\"channels\"] = channels\n",
    "mltk_model_stats[\"variation\"] = variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling model in simulator ...\n",
      "Using Tensorflow-Lite Micro version: b13b48c (2022-06-08)\n",
      "Searching for optimal runtime memory size ...\n",
      "Failed to allocate buffer for model (likely heap memory overflow)\n"
     ]
    }
   ],
   "source": [
    "# MLTK profile model reads the mode from a path!\n",
    "\n",
    "profiling = True\n",
    "\n",
    "try:\n",
    "    profiling_results = profile_model(str(models_tflite_path), accelerator=None, build=None)\n",
    "except:\n",
    "    profiling= False\n",
    "    with open(\"error_list.txt\", \"a\") as f:\n",
    "        f.write(f\"{model_name}, mltk_profiling_error\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if automated == False:\n",
    "    mltk_model_stats[\"opt_RAM_mltk\"] = int(input(\"Please copy the optimal runtime memory size from above: \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profiling:\n",
    "    profiling_results.get_summary(exclude_null=False, full_summary=True)\n",
    "    model_profile = profiling_results.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profiling:\n",
    "    mltk_model_stats[\"flash_model_size_b_mltk\"] = model_profile[\"summary\"][\"tflite_size\"]\n",
    "    mltk_model_stats[\"RAM_runtime_memory_size_b_mltk\"] = model_profile[\"summary\"][\"runtime_memory_size\"]\n",
    "    mltk_model_stats[\"OPS_mltk\"] = model_profile[\"summary\"][\"ops\"]\n",
    "    mltk_model_stats[\"macs_mltk\"] = model_profile[\"summary\"][\"macs\"]\n",
    "    mltk_model_stats[\"n_unsupported_layers_mltk\"] = model_profile[\"summary\"][\"n_unsupported_layers\"]\n",
    "    mltk_model_stats[\"energy_mltk\"] = model_profile[\"summary\"][\"energy\"]\n",
    "\n",
    "    layers_df = pd.DataFrame.from_dict(model_profile[\"layers\"])\n",
    "    layers_df[\"name\"] = layers_df[\"index\"].map(str) + \": \" + layers_df[\"opcode\"]\n",
    "    layers_df.insert(2,\"name\" , layers_df.pop(\"name\"))\n",
    "    layers_df\n",
    "\n",
    "    layers_df_path = pathlib.Path.joinpath(models_dir, \"layer_df_mltk.pkl\")\n",
    "    layers_df.to_pickle(layers_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MACs': '4.819 M',\n",
       " 'FLOPs': '9.791 M',\n",
       " 'total_params': 56874,\n",
       " 'trainable_params': 53450,\n",
       " 'non_trainable_params': 3424,\n",
       " 'model_size_kb': 729.40625,\n",
       " 'tflite_model_size_kb': 280.828125,\n",
       " 'tflite_model_INT8_size_kb': 192.0546875,\n",
       " 'peak_memory_b': 113320,\n",
       " 'architecture': 'mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1',\n",
       " 'alpha': 0.1,\n",
       " 'img_res': 96,\n",
       " 'classes': 2,\n",
       " 'channels': 3,\n",
       " 'variation': 'se4l64.MV1',\n",
       " 'opt_RAM_mltk': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mltk_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for interrupting indefinetly hanging functions - does not work on Windows!\n",
    "\n",
    "def handler(signum, frame):\n",
    "    signame = signal.Signals(signum).name\n",
    "    print(f'Signal handler called with signal {signame} ({signum})')\n",
    "    raise OSError(\"Couldn't open device!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_INT8 = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the signal handler and a 200-second alarm # TODO: this does not work on Windows!\n",
    "#signal.signal(signal.SIGALRM, handler)\n",
    "\n",
    "#signal.alarm(10)\n",
    "\n",
    "# This open() may hang indefinitely\n",
    "try:\n",
    "    # %%capture optimal_runtime_INT\n",
    "    profiling_results_INT8 = profile_model(str(models_tflite_opt_path), accelerator=None, build=False)\n",
    "except:\n",
    "    profiling_results_INT8 = False\n",
    "\n",
    "#signal.alarm(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiling_INT8 = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profiling_INT8:\n",
    "    if automated == False:    \n",
    "        mltk_model_stats[\"opt_RAM_INT8_mltk\"] = int(input(\"Please copy the optimal runtime memory size from above: \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from contextlib import redirect_stdout\n",
    "\n",
    "# with open(\"runtime.txt\", \"w\", encoding='utf-8') as f:\n",
    "#     with redirect_stdout(f):\n",
    "#         print(profile_model(str(models_tflite_opt_path), accelerator=None, build=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profiling_INT8:\n",
    "    profiling_results_INT8.get_summary()\n",
    "    model_profile_INT8 = profiling_results_INT8.to_dict()\n",
    "\n",
    "    mltk_model_stats[\"flash_model_size_b__INT8_mltk\"] = model_profile_INT8[\"summary\"][\"tflite_size\"]\n",
    "    mltk_model_stats[\"RAM_runtime_memory_size_b_INT8_mltk\"] = model_profile_INT8[\"summary\"][\"runtime_memory_size\"]\n",
    "    mltk_model_stats[\"OPS_INT8_mltk\"] = model_profile_INT8[\"summary\"][\"ops\"]\n",
    "    mltk_model_stats[\"macs_INT8_mltk\"] = model_profile_INT8[\"summary\"][\"macs\"]\n",
    "    mltk_model_stats[\"n_unsupported_layers_INT8_mltk\"] = model_profile_INT8[\"summary\"][\"n_unsupported_layers\"]\n",
    "    mltk_model_stats[\"energy_INT8_mltk\"] = model_profile_INT8[\"summary\"][\"energy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MACs': '4.819 M',\n",
       " 'FLOPs': '9.791 M',\n",
       " 'total_params': 56874,\n",
       " 'trainable_params': 53450,\n",
       " 'non_trainable_params': 3424,\n",
       " 'model_size_kb': 729.40625,\n",
       " 'tflite_model_size_kb': 280.828125,\n",
       " 'tflite_model_INT8_size_kb': 192.0546875,\n",
       " 'peak_memory_b': 113320,\n",
       " 'architecture': 'mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1',\n",
       " 'alpha': 0.1,\n",
       " 'img_res': 96,\n",
       " 'classes': 2,\n",
       " 'channels': 3,\n",
       " 'variation': 'se4l64.MV1',\n",
       " 'opt_RAM_mltk': 0,\n",
       " 'opt_RAM_INT8_mltk': 0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mltk_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profiling_INT8:\n",
    "    layers_INT8_df = pd.DataFrame.from_dict(model_profile_INT8[\"layers\"])\n",
    "    layers_INT8_df[\"name\"] = layers_INT8_df[\"index\"].map(str) + \": \" + layers_INT8_df[\"opcode\"]\n",
    "    layers_INT8_df.insert(2,\"name\" , layers_INT8_df.pop(\"name\"))\n",
    "    layers_INT8_df\n",
    "\n",
    "    layers_df_INT8_path = pathlib.Path.joinpath(models_dir, \"layer_df_INT8_mltk.pkl\")\n",
    "    layers_INT8_df.to_pickle(layers_df_INT8_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging to Weights & Biases - part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\tiny_mlc\\tiny_cnn\\wandb\\run-20230318_082545-pmwiu34u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/susbrock/model_DB/runs/pmwiu34u\" target=\"_blank\">mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1</a></strong> to <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/susbrock/model_DB\" target=\"_blank\">https://wandb.ai/susbrock/model_DB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/susbrock/model_DB/runs/pmwiu34u\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/pmwiu34u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No analysis from mltk!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mobilenetv3smallSQ_0.1_96_c3_o2_se4l64.MV1</strong> at: <a href=\"https://wandb.ai/susbrock/model_DB/runs/pmwiu34u\" target=\"_blank\">https://wandb.ai/susbrock/model_DB/runs/pmwiu34u</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230318_082545-pmwiu34u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=PROJECT,\n",
    "    entity=\"susbrock\",\n",
    "    name = model_name,\n",
    "    id=run_id,\n",
    "    resume=\"allow\"\n",
    "    )\n",
    "\n",
    "# config = wandb.config\n",
    "# config.id = run_id\n",
    "config.update(mltk_model_stats)\n",
    "\n",
    "try:\n",
    "    layers_df_wandb = wandb.Table(dataframe=layers_df)\n",
    "    wandb.log({\"tflite_layers_mltk\" : layers_df_wandb})\n",
    "    layers_INT8_df_wandb = wandb.Table(dataframe=layers_INT8_df)\n",
    "    wandb.log({\"tflite_INt8_layers_mltk\" : layers_INT8_df_wandb})\n",
    "except:\n",
    "    print(\"No analysis from mltk!\")\n",
    "\n",
    "# peak_memory_df_wandb = wandb.Table(dataframe=peak_memory_df)\n",
    "# wandb.log({\"peak_memory\" : peak_memory_df_wandb})\n",
    "\n",
    "# tensor_df_wandb = wandb.Table(dataframe=tensor_df)\n",
    "# wandb.log({\"tensor_info\" : tensor_df_wandb})\n",
    "\n",
    "# if layer_details_csv_exists:\n",
    "#     layer_details_df_wandb = wandb.Table(dataframe=layer_details_df)\n",
    "#     wandb.log({\"tensorflow_layer_details\" : layer_details_df_wandb})\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     wandb.log({\"tflite_INt8_layers_plt\" : wandb.plot.bar(layers_INT8_df_wandb, \"index\", \"macs\", title=model_name)})\n",
    "# except:\n",
    "#     pass\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_cnn_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faa6c31b20b8f809b81d6d7d22a84ccd9f354666f54133d1793fa4c65539801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
